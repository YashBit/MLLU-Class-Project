{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CUSTOMBERT-BERT-UCI-10%-SMART.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"b1dcb670711247f394b8572a6ff09e85":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6711ff8af5c84ddc96a8e454dfc8b198","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ac201ca0d75c4fe1afa9f2b38b292b4f","IPY_MODEL_299b284917a94037a45cdd14fc4f3935"]}},"6711ff8af5c84ddc96a8e454dfc8b198":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ac201ca0d75c4fe1afa9f2b38b292b4f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_f25010c4daed456b8f206739c125d04e","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c443e0109dd9462ab6fc3ab307f4ffeb"}},"299b284917a94037a45cdd14fc4f3935":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_904503541a6d46fc92be8b7764b6c534","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:00&lt;00:00, 718kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1777b6f3c5c241b6971b0e85fbf8b6d9"}},"f25010c4daed456b8f206739c125d04e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c443e0109dd9462ab6fc3ab307f4ffeb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"904503541a6d46fc92be8b7764b6c534":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1777b6f3c5c241b6971b0e85fbf8b6d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"86acbd58c1c54932a1f201693c8d64d9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2511426048e2410089cec1a23d2b9d7f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_0a623852d4e24235938772e1e5a5e36f","IPY_MODEL_8f903e9ff7ca4d93aebe51e9daf5ca96"]}},"2511426048e2410089cec1a23d2b9d7f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0a623852d4e24235938772e1e5a5e36f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_1327749e96c14dc8b30bfd5b60e22c1f","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":28,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":28,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1b505cb7ea6043799ef398d003f2614a"}},"8f903e9ff7ca4d93aebe51e9daf5ca96":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4af4002030d1456bb0955ccb839847a2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 28.0/28.0 [00:00&lt;00:00, 146B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_905377d5b3ce427b8ccc6d9eadca42b6"}},"1327749e96c14dc8b30bfd5b60e22c1f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1b505cb7ea6043799ef398d003f2614a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4af4002030d1456bb0955ccb839847a2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"905377d5b3ce427b8ccc6d9eadca42b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"73fc36f850994fe780525ab9bac08582":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_567cf591949a484388065dfea5f6ae34","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_333cfe03d58a436c902c7d20d80b217c","IPY_MODEL_8c664a67283546e7bc76998891d5e3df"]}},"567cf591949a484388065dfea5f6ae34":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"333cfe03d58a436c902c7d20d80b217c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e203dbdbb2bb4c2ca1c67c9a1d2a524e","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":466062,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":466062,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0b2238a4874c40b290cfa06ffc295f00"}},"8c664a67283546e7bc76998891d5e3df":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a195f3389aef48af8bdf3ea1ebbaa8e3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 466k/466k [00:00&lt;00:00, 4.85MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b693964f9fcf40aea977c5fbf01def04"}},"e203dbdbb2bb4c2ca1c67c9a1d2a524e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0b2238a4874c40b290cfa06ffc295f00":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a195f3389aef48af8bdf3ea1ebbaa8e3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b693964f9fcf40aea977c5fbf01def04":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"910d1bf4303345eb9f82c70717bc8756":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_db7a540a67ab409b9407ec99d81234b1","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_72d33a9622f347678fc8f933bf2c5be1","IPY_MODEL_bc57ea71b47449bcb8a11e4c770490ba"]}},"db7a540a67ab409b9407ec99d81234b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"72d33a9622f347678fc8f933bf2c5be1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_034447615019400fbf0c8ac89b291420","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":570,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":570,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_87822fe0b1be46dfb68ec9a9ba6a463d"}},"bc57ea71b47449bcb8a11e4c770490ba":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e531733039a34092b218d435d1b221ea","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 570/570 [05:05&lt;00:00, 1.87B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a4e1f588d9d04aa38699a6b45c679bc7"}},"034447615019400fbf0c8ac89b291420":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"87822fe0b1be46dfb68ec9a9ba6a463d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e531733039a34092b218d435d1b221ea":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a4e1f588d9d04aa38699a6b45c679bc7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a059e17ab22d49f69d6a71cf3543299c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_610741ea5a624e9bb2b5c64622d1db36","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_06f7798ef4574748b7028090baa0756f","IPY_MODEL_31d6953669e7417b9d772e588bbfd24a"]}},"610741ea5a624e9bb2b5c64622d1db36":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"06f7798ef4574748b7028090baa0756f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ba1a1120bfc24d8d8309cee16b6a208e","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":440473133,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":440473133,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f018a1db60804fd7931220714a9fe228"}},"31d6953669e7417b9d772e588bbfd24a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_931098124b714cad916c84622218b6bb","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 440M/440M [00:09&lt;00:00, 47.9MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_57522d0c868f4f08862f455c21cb246e"}},"ba1a1120bfc24d8d8309cee16b6a208e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f018a1db60804fd7931220714a9fe228":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"931098124b714cad916c84622218b6bb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"57522d0c868f4f08862f455c21cb246e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"EKOTlwcmxmej"},"source":["# BERT Fine-Tuning on CoLA with UCI and SiFT\n","\n","\n","\n","This notebook is orginally created by Chris McCormick and Nick Ryan. We made changes for SiFT and SMART, as well as our custom BERT class."]},{"cell_type":"markdown","metadata":{"id":"jJKaoairpdRa"},"source":["##Data and Importing Modules "]},{"cell_type":"code","metadata":{"id":"DEfSbAA4QHas","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621101558166,"user_tz":-330,"elapsed":1055,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"dae8d507-d794-4919-84c5-55dc9463ffdc"},"source":["import tensorflow as tf\n","\n","# Get the GPU device name.\n","device_name = tf.test.gpu_device_name()\n","\n","# The device name should look like the following:\n","if device_name == '/device:GPU:0':\n","    print('Found GPU at: {}'.format(device_name))\n","else:\n","    raise SystemError('GPU device not found')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oYsV4H8fCpZ-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621101564610,"user_tz":-330,"elapsed":5176,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"ff657b41-1a4c-4608-c84d-8abcc63d2bc5"},"source":["import torch\n","\n","# If there's a GPU available...\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"execution_count":3,"outputs":[{"output_type":"stream","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla T4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0NmMdkZO8R6q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621101572440,"user_tz":-330,"elapsed":7083,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"c88d23f1-91c1-4405-f521-2aebb1c5039b"},"source":["!pip install transformers"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/9e/5b80becd952d5f7250eaf8fc64b957077b12ccfe73e9c03d37146ab29712/transformers-4.6.0-py3-none-any.whl (2.3MB)\n","\u001b[K     |████████████████████████████████| 2.3MB 30.1MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n","\u001b[K     |████████████████████████████████| 901kB 38.4MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Collecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n","\u001b[K     |████████████████████████████████| 3.3MB 38.9MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Collecting huggingface-hub==0.0.8\n","  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (8.0.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Installing collected packages: sacremoses, tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.6.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5m6AnuFv0QXQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621101577409,"user_tz":-330,"elapsed":4951,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"e7398228-8c75-4c76-ad53-6fcb4495038c"},"source":["!pip install wget"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Collecting wget\n","  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n","Building wheels for collected packages: wget\n","  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wget: filename=wget-3.2-cp37-none-any.whl size=9681 sha256=ea154f89435dd44a5821388a8d9c569c7b235e5cbebbcdc043a81f0f82817ac9\n","  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n","Successfully built wget\n","Installing collected packages: wget\n","Successfully installed wget-3.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pMtmPMkBzrvs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621101643265,"user_tz":-330,"elapsed":63917,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"51bdad2e-68e1-4e09-c0e7-75dc4287f661"},"source":["#Adding the datasets to the collab file\n","\n","#First we mount the google drive\n","\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0Yv-tNv20dnH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621101644389,"user_tz":-330,"elapsed":64103,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"a6100b77-fcc5-435f-dda4-dfb942460138"},"source":["# with open('/content/drive/My Drive/Undergraduate/Courses/MLLU Project/Code/Baseline - Draft Proposal/yelp_labelled.txt', 'r') as f:\n","#   f.write('Successfully opened Yelp Labelled')\n","\n","with open('/content/drive/MyDrive/Undergraduate /Courses /MLLU Project/Code/MLLU : Final Paper Submission Code/yelp_labelled.txt', 'r') as y:\n","  print(\"Successfully Opened Yelp\")\n","\n","\n","with open('/content/drive/MyDrive/Undergraduate /Courses /MLLU Project/Code/MLLU : Final Paper Submission Code/amazon_cells_labelled.txt', 'r') as a:\n","  print(\"Successfully Opened Amazon Labelled\")\n","\n","\n","\n","with open('/content/drive/MyDrive/Undergraduate /Courses /MLLU Project/Code/MLLU : Final Paper Submission Code/imdb_labelled.txt', 'r') as i:\n","  print(\"Successfully Opened IMDB Labelled\")"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Successfully Opened Yelp\n","Successfully Opened Amazon Labelled\n","Successfully Opened IMDB Labelled\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_UkeC7SG2krJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621101646766,"user_tz":-330,"elapsed":2353,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"82cd57c6-8043-4b63-a518-3ecd30938b66"},"source":["#Checking on the Yelp Dataframe\n","import pandas as pd\n","df1_yelp = pd.read_csv('/content/drive/MyDrive/Undergraduate /Courses /MLLU Project/Code/MLLU : Final Paper Submission Code/yelp_labelled.txt', delimiter = '\\t', delim_whitespace= False, names = ('Sentence', 'Label'))\n","df1_yelp.head()\n","\n","print(df1_yelp.info())"],"execution_count":8,"outputs":[{"output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 1000 entries, 0 to 999\n","Data columns (total 2 columns):\n"," #   Column    Non-Null Count  Dtype \n","---  ------    --------------  ----- \n"," 0   Sentence  1000 non-null   object\n"," 1   Label     1000 non-null   int64 \n","dtypes: int64(1), object(1)\n","memory usage: 15.8+ KB\n","None\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j-0v9aKSCWVg","executionInfo":{"status":"ok","timestamp":1621101652040,"user_tz":-330,"elapsed":1300,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"13d27c91-fdc6-40bc-8a35-0075de1c8f5c"},"source":["\n","#Similarly for the dataframes for Amazon and IMDB\n","df1_amazon = pd.read_csv('/content/drive/MyDrive/Undergraduate /Courses /MLLU Project/Code/MLLU : Final Paper Submission Code/amazon_cells_labelled.txt', delimiter = '\\t', delim_whitespace= False, names = ('Sentence', 'Label'))\n","df1_amazon.head()\n","print(df1_amazon.info())"],"execution_count":10,"outputs":[{"output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 1000 entries, 0 to 999\n","Data columns (total 2 columns):\n"," #   Column    Non-Null Count  Dtype \n","---  ------    --------------  ----- \n"," 0   Sentence  1000 non-null   object\n"," 1   Label     1000 non-null   int64 \n","dtypes: int64(1), object(1)\n","memory usage: 15.8+ KB\n","None\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_wPamOpWCYhk","executionInfo":{"status":"ok","timestamp":1621101654402,"user_tz":-330,"elapsed":1311,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"0db4ed85-e81c-4032-97f1-2747cbe81ab8"},"source":["df1_imdb = pd.read_csv('/content/drive/MyDrive/Undergraduate /Courses /MLLU Project/Code/MLLU : Final Paper Submission Code/imdb_labelled.txt', delimiter = '\\t', delim_whitespace= False, names = ('Sentence', 'Label'))\n","df1_imdb.head()\n","print(df1_imdb.info())"],"execution_count":11,"outputs":[{"output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 748 entries, 0 to 747\n","Data columns (total 2 columns):\n"," #   Column    Non-Null Count  Dtype \n","---  ------    --------------  ----- \n"," 0   Sentence  748 non-null    object\n"," 1   Label     748 non-null    int64 \n","dtypes: int64(1), object(1)\n","memory usage: 11.8+ KB\n","None\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"blqIvQaQncdJ","colab":{"base_uri":"https://localhost:8080/","height":512},"executionInfo":{"status":"ok","timestamp":1621101661644,"user_tz":-330,"elapsed":1070,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"b016fe73-30a4-4e4f-a665-f9181c811d7c"},"source":["\n","combinedDF = pd.concat([df1_imdb, df1_amazon, df1_yelp], axis = 0, join = 'inner')\n","combinedDF.head()\n","combinedDF.info()\n","combinedDF.head(10)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 2748 entries, 0 to 999\n","Data columns (total 2 columns):\n"," #   Column    Non-Null Count  Dtype \n","---  ------    --------------  ----- \n"," 0   Sentence  2748 non-null   object\n"," 1   Label     2748 non-null   int64 \n","dtypes: int64(1), object(1)\n","memory usage: 64.4+ KB\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sentence</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>A very, very, very slow-moving, aimless movie ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Not sure who was more lost - the flat characte...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Attempting artiness with black &amp; white and cle...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Very little music or anything to speak of.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>The best scene in the movie was when Gerardo i...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>The rest of the movie lacks art, charm, meanin...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Wasted two hours.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Saw the movie today and thought it was a good ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>A bit predictable.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Loved the casting of Jimmy Buffet as the scien...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            Sentence  Label\n","0  A very, very, very slow-moving, aimless movie ...      0\n","1  Not sure who was more lost - the flat characte...      0\n","2  Attempting artiness with black & white and cle...      0\n","3       Very little music or anything to speak of.        0\n","4  The best scene in the movie was when Gerardo i...      1\n","5  The rest of the movie lacks art, charm, meanin...      0\n","6                                Wasted two hours.        0\n","7  Saw the movie today and thought it was a good ...      1\n","8                               A bit predictable.        0\n","9  Loved the casting of Jimmy Buffet as the scien...      1"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":512},"id":"qaDK92pbCfZZ","executionInfo":{"status":"ok","timestamp":1621101665512,"user_tz":-330,"elapsed":1064,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"7ee4b486-3692-4dfb-c8b9-82321849c633"},"source":["combinedDF = combinedDF.sample(frac = 1).reset_index(drop = True)\n","combinedDF = combinedDF.dropna()\n","combinedDF.info()\n","combinedDF.head(10)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 2748 entries, 0 to 2747\n","Data columns (total 2 columns):\n"," #   Column    Non-Null Count  Dtype \n","---  ------    --------------  ----- \n"," 0   Sentence  2748 non-null   object\n"," 1   Label     2748 non-null   int64 \n","dtypes: int64(1), object(1)\n","memory usage: 64.4+ KB\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sentence</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Not much flavor to them, and very poorly const...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Damian is so talented and versatile in so many...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Unfortunately, inexperience of direction meant...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>We aren't ones to make a scene at restaurants ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>The Veggitarian platter is out of this world!</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>poor voice clarity.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Restored my phone to like new performance.</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>He was terrible!</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>I was looking for this headset for a long time...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Not much dialogue, not much music, the whole f...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            Sentence  Label\n","0  Not much flavor to them, and very poorly const...      0\n","1  Damian is so talented and versatile in so many...      1\n","2  Unfortunately, inexperience of direction meant...      0\n","3  We aren't ones to make a scene at restaurants ...      0\n","4      The Veggitarian platter is out of this world!      1\n","5                                poor voice clarity.      0\n","6         Restored my phone to like new performance.      1\n","7                                   He was terrible!      0\n","8  I was looking for this headset for a long time...      1\n","9  Not much dialogue, not much music, the whole f...      1"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"GuE5BqICAne2","executionInfo":{"status":"ok","timestamp":1621101671265,"user_tz":-330,"elapsed":1646,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}}},"source":["df1_twitter = pd.read_csv('/content/drive/MyDrive/Undergraduate /Courses /MLLU Project/Code/MLLU : Final Paper Submission Code/train.csv', names = ('Label', 'Sentence'))\n","df1_twitter = df1_twitter.iloc[1:4000]\n","\n","df1_twitter['Label'] = df1_twitter['Label'].astype(int, errors = 'raise')"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_XcD3h68Ck7v","executionInfo":{"status":"ok","timestamp":1621101672188,"user_tz":-330,"elapsed":708,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"f3b862bf-31d3-43ee-bcee-362890b160b8"},"source":["df1_twitter.head()\n","df1_twitter.info()"],"execution_count":15,"outputs":[{"output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","Index: 3999 entries, 1 to 3999\n","Data columns (total 2 columns):\n"," #   Column    Non-Null Count  Dtype \n","---  ------    --------------  ----- \n"," 0   Label     3999 non-null   int64 \n"," 1   Sentence  3999 non-null   object\n","dtypes: int64(1), object(1)\n","memory usage: 93.7+ KB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ykLveVUNCneG","executionInfo":{"status":"ok","timestamp":1621101675669,"user_tz":-330,"elapsed":1716,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"fa7486d6-561c-41a8-fcfa-68a1d2ef1cf3"},"source":["df1_twitter.head(10)\n","sentences = df1_twitter.Sentence.values\n","labels = df1_twitter.Label.values\n","\n","print(type(labels[0]))"],"execution_count":16,"outputs":[{"output_type":"stream","text":["<class 'numpy.int64'>\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EFSJzwI5pujc"},"source":["## Tokenization and DataLoader"]},{"cell_type":"code","metadata":{"id":"Z474sSC6oe7A","colab":{"base_uri":"https://localhost:8080/","height":181,"referenced_widgets":["b1dcb670711247f394b8572a6ff09e85","6711ff8af5c84ddc96a8e454dfc8b198","ac201ca0d75c4fe1afa9f2b38b292b4f","299b284917a94037a45cdd14fc4f3935","f25010c4daed456b8f206739c125d04e","c443e0109dd9462ab6fc3ab307f4ffeb","904503541a6d46fc92be8b7764b6c534","1777b6f3c5c241b6971b0e85fbf8b6d9","86acbd58c1c54932a1f201693c8d64d9","2511426048e2410089cec1a23d2b9d7f","0a623852d4e24235938772e1e5a5e36f","8f903e9ff7ca4d93aebe51e9daf5ca96","1327749e96c14dc8b30bfd5b60e22c1f","1b505cb7ea6043799ef398d003f2614a","4af4002030d1456bb0955ccb839847a2","905377d5b3ce427b8ccc6d9eadca42b6","73fc36f850994fe780525ab9bac08582","567cf591949a484388065dfea5f6ae34","333cfe03d58a436c902c7d20d80b217c","8c664a67283546e7bc76998891d5e3df","e203dbdbb2bb4c2ca1c67c9a1d2a524e","0b2238a4874c40b290cfa06ffc295f00","a195f3389aef48af8bdf3ea1ebbaa8e3","b693964f9fcf40aea977c5fbf01def04"]},"executionInfo":{"status":"ok","timestamp":1621101678039,"user_tz":-330,"elapsed":1795,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"e57e5d0f-87a8-4e6f-bb42-1ca111c6502e"},"source":["from transformers import BertTokenizer\n","print('Loading BERT tokenizer...')\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Loading BERT tokenizer...\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b1dcb670711247f394b8572a6ff09e85","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"86acbd58c1c54932a1f201693c8d64d9","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"73fc36f850994fe780525ab9bac08582","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dLIbudgfh6F0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621101690737,"user_tz":-330,"elapsed":1137,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"3baf376d-877d-4c41-8622-d66fcfada33d"},"source":["print(' Original: ', sentences[0])\n","print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n","print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"],"execution_count":19,"outputs":[{"output_type":"stream","text":[" Original:   @user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run\n","Tokenized:  ['@', 'user', 'when', 'a', 'father', 'is', 'dysfunction', '##al', 'and', 'is', 'so', 'selfish', 'he', 'drag', '##s', 'his', 'kids', 'into', 'his', 'dysfunction', '.', '#', 'run']\n","Token IDs:  [1030, 5310, 2043, 1037, 2269, 2003, 28466, 2389, 1998, 2003, 2061, 14337, 2002, 8011, 2015, 2010, 4268, 2046, 2010, 28466, 1012, 1001, 2448]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cKsH2sU0OCQA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621101694424,"user_tz":-330,"elapsed":2917,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"1632d576-178d-4456-f148-b1afc1cd7da6"},"source":["max_len = 0\n","\n","# For every sentence...\n","for sent in sentences:\n","\n","    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n","    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n","\n","    # Update the maximum sentence length.\n","    max_len = max(max_len, len(input_ids))\n","\n","\n","print(len(sentences))\n","print('Max sentence length: ', max_len)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["3999\n","Max sentence length:  76\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2bBdb3pt8LuQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621101703217,"user_tz":-330,"elapsed":2854,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"ea04d1a4-7b0c-4ef3-cf2e-0f7cf024e803"},"source":["# Tokenize all of the sentences and map the tokens to thier word IDs.\n","input_ids = []\n","attention_masks = []\n","\n","# For every sentence...\n","for sent in sentences:\n","    # `encode_plus` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    #   (5) Pad or truncate the sentence to `max_length`\n","    #   (6) Create attention masks for [PAD] tokens.\n","    encoded_dict = tokenizer.encode_plus(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = 32,           # Pad & truncate all sentences.\n","                        pad_to_max_length = True,\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","    \n","    # Add the encoded sentence to the list.    \n","    input_ids.append(encoded_dict['input_ids'])\n","    \n","    # And its attention mask (simply differentiates padding from non-padding).\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","# Convert the lists into tensors.\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","labels = torch.tensor(labels)\n","\n","# Print sentence 0, now as a list of IDs.\n","print('Original: ', sentences[0])\n","print('Token IDs:', input_ids[0])"],"execution_count":22,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Original:   @user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run\n","Token IDs: tensor([  101,  1030,  5310,  2043,  1037,  2269,  2003, 28466,  2389,  1998,\n","         2003,  2061, 14337,  2002,  8011,  2015,  2010,  4268,  2046,  2010,\n","        28466,  1012,  1001,  2448,   102,     0,     0,     0,     0,     0,\n","            0,     0])\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"GEgLpFVlo1Z-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621101704346,"user_tz":-330,"elapsed":1118,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"5b8ec89a-b57f-428b-de6b-bbc70eab44dd"},"source":["from torch.utils.data import TensorDataset, random_split\n","\n","# Combine the training inputs into a TensorDataset.\n","dataset = TensorDataset(input_ids, attention_masks, labels)\n","print(type(input_ids))\n","print(type(attention_masks))\n","print(type(labels))\n","# Create a 90-10 train-validation split.\n","\n","# Calculate the number of samples to include in each set.\n","train_size = int(0.9 * len(dataset))\n","val_size = len(dataset) - train_size\n","\n","# Divide the dataset by randomly selecting samples.\n","train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n","\n","print('{:>5,} training samples'.format(train_size))\n","print('{:>5,} validation samples'.format(val_size))"],"execution_count":23,"outputs":[{"output_type":"stream","text":["<class 'torch.Tensor'>\n","<class 'torch.Tensor'>\n","<class 'torch.Tensor'>\n","3,599 training samples\n","  400 validation samples\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XGUqOCtgqGhP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621101707351,"user_tz":-330,"elapsed":790,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"ee5e91d7-b69d-44f7-8d35-501b69b609ab"},"source":["from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","\n","# The DataLoader needs to know our batch size for training, so we specify it \n","# here. \n","batch_size = 32\n","\n","# Create the DataLoaders for our training and validation sets.\n","# We'll take training samples in random order. \n","train_dataloader = DataLoader(\n","            train_dataset,  # The training samples.\n","            sampler = RandomSampler(train_dataset), # Select batches randomly\n","            batch_size = batch_size # Trains with this batch size.\n","        )\n","\n","# For validation the order doesn't matter, so we'll just read them sequentially.\n","validation_dataloader = DataLoader(\n","            val_dataset, # The validation samples.\n","            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n","            batch_size = batch_size # Evaluate with this batch size.\n","        )\n","\n","\n","print(\"hi\")"],"execution_count":24,"outputs":[{"output_type":"stream","text":["hi\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"73S4P4SMp6hX"},"source":["## Custom Bert Class and Initialization"]},{"cell_type":"code","metadata":{"id":"UOteWAT-Adqx","executionInfo":{"status":"ok","timestamp":1621101714637,"user_tz":-330,"elapsed":1303,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}}},"source":["from transformers import BertForSequenceClassification, AdamW, BertConfig, BertPreTrainedModel, BertModel\n","from transformers.models.bert.modeling_bert import BertEmbeddings,BertEncoder,BertPooler\n","from transformers.modeling_outputs import BaseModelOutputWithPoolingAndCrossAttentions\n","\n","import torch\n","import torch.utils.checkpoint\n","from torch import nn\n","from torch.nn import CrossEntropyLoss, MSELoss\n","\n","class CustomBertForClassification(BertForSequenceClassification):\n","    def __init__(self, config):\n","        super().__init__(config)\n","        #self.bert = BertForSequenceClassification(config).from_pretrained(\"bert-base-uncased\",num_labels = 2,output_attentions = False, output_hidden_states = False)\n","        self.embeddings = self.bert.embeddings\n","        self.encoder = self.bert.encoder\n","        self.pooler = self.bert.pooler\n","\n","    def embed(self, input_ids=None, \n","                    token_type_ids=None, \n","                    position_ids=None, \n","                    inputs_embeds=None, \n","                    past_key_values_length=0):\n","        # See: BERTModel.forward\n","        return self.embeddings(\n","            input_ids=input_ids,\n","            position_ids=position_ids,\n","            token_type_ids=token_type_ids,\n","            inputs_embeds=inputs_embeds,\n","            past_key_values_length=past_key_values_length\n","        )\n","    \n","    def predict(self,embedding_output,\n","                extended_attention_mask=None,\n","                head_mask=None,\n","                encoder_hidden_states=None,\n","                encoder_extended_attention_mask=None,\n","                past_key_values=None,\n","                use_cache=None,\n","                output_attentions=None,\n","                output_hidden_states=None,\n","                return_dict=True):\n","      # See: BERTModel.forward \n","        encoder_outputs = self.encoder(\n","            embedding_output,\n","            attention_mask=extended_attention_mask,\n","            head_mask=head_mask,\n","            encoder_hidden_states=encoder_hidden_states,\n","            encoder_attention_mask=encoder_extended_attention_mask,\n","            past_key_values=past_key_values,\n","            use_cache=use_cache,\n","            output_attentions=output_attentions,\n","            output_hidden_states=output_hidden_states,\n","            return_dict=return_dict,\n","        )\n","\n","        sequence_output = encoder_outputs[0]\n","        pooled_output = self.pooler(sequence_output) if self.pooler is not None else None\n","        \n","        bert_output = BaseModelOutputWithPoolingAndCrossAttentions(\n","                    last_hidden_state=sequence_output,\n","                    pooler_output=pooled_output,\n","                    past_key_values=encoder_outputs.past_key_values,\n","                    hidden_states=encoder_outputs.hidden_states,\n","                    attentions=encoder_outputs.attentions,\n","                    cross_attentions=encoder_outputs.cross_attentions,\n","                )\n","\n","        pooled_output = bert_output[1]\n","\n","        pooled_output = self.dropout(pooled_output)\n","        logits = self.classifier(pooled_output)\n","        \n","        return logits\n"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["910d1bf4303345eb9f82c70717bc8756","db7a540a67ab409b9407ec99d81234b1","72d33a9622f347678fc8f933bf2c5be1","bc57ea71b47449bcb8a11e4c770490ba","034447615019400fbf0c8ac89b291420","87822fe0b1be46dfb68ec9a9ba6a463d","e531733039a34092b218d435d1b221ea","a4e1f588d9d04aa38699a6b45c679bc7","a059e17ab22d49f69d6a71cf3543299c","610741ea5a624e9bb2b5c64622d1db36","06f7798ef4574748b7028090baa0756f","31d6953669e7417b9d772e588bbfd24a","ba1a1120bfc24d8d8309cee16b6a208e","f018a1db60804fd7931220714a9fe228","931098124b714cad916c84622218b6bb","57522d0c868f4f08862f455c21cb246e"]},"id":"IdNBO5qk2-i_","collapsed":true,"executionInfo":{"status":"ok","timestamp":1621101739759,"user_tz":-330,"elapsed":22263,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"8e78d26e-ac5a-4b2f-a936-6fd369a558f3"},"source":["#@title\n","model = CustomBertForClassification.from_pretrained(\n","    \"bert-base-uncased\",\n","    num_labels = 2,\n","    output_attentions = False, \n","    output_hidden_states = False, \n",")\n","\n","model.cuda()"],"execution_count":26,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"910d1bf4303345eb9f82c70717bc8756","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a059e17ab22d49f69d6a71cf3543299c","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing CustomBertForClassification: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing CustomBertForClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing CustomBertForClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of CustomBertForClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['encoder.layer.6.intermediate.dense.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'classifier.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.8.intermediate.dense.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'pooler.dense.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.6.attention.self.query.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.4.attention.output.dense.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.self.query.bias', 'classifier.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.7.attention.self.value.bias', 'pooler.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["CustomBertForClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n","  (embeddings): BertEmbeddings(\n","    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","    (position_embeddings): Embedding(512, 768)\n","    (token_type_embeddings): Embedding(2, 768)\n","    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (encoder): BertEncoder(\n","    (layer): ModuleList(\n","      (0): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (1): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (2): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (3): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (4): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (5): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (6): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (7): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (8): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (9): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (10): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (11): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","  )\n","  (pooler): BertPooler(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (activation): Tanh()\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"markdown","metadata":{"id":"hmSpMRD5qaqE"},"source":["##Noise Function"]},{"cell_type":"code","metadata":{"id":"pG5DszcpDAjw","executionInfo":{"status":"ok","timestamp":1621101741124,"user_tz":-330,"elapsed":1361,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}}},"source":["from torch.nn import LayerNorm\n","import torch.nn.functional as F\n","\n","def normalize_embed(embed):\n","    embed_mean = torch.mean(embed,dim=(1,2))\n","    embed_std = torch.std(embed, dim=(1,2))\n","\n","    embed_clone = torch.clone(embed)\n","\n","    for i in range(0,embed_clone.size()[0]):\n","        # embed_clone[i] = torch.div(torch.sub(embed_clone[i],embed_mean[i]),embed_std[i])\n","        embed_clone[i] = (embed_clone[i] - embed_mean[i]) / embed_std[i]\n","    return embed_clone, embed_mean, embed_std\n","\n","def denormalize_embed(embed, embed_mean, embed_std):\n","    for i in range(0,embed.size()[0]):\n","        # embed[i] = (embed[i] - embed_mean[i]) / embed_std[i]\n","        embed[i] = (embed[i] * embed_std[i]) + embed_mean[i]\n","    return embed \n","\n","def stable_kl(logit, target, epsilon=1e-6, reduce=True):\n","    logit = logit.view(-1, logit.size(-1)).float()\n","    target = target.view(-1, target.size(-1)).float()\n","    bs = logit.size(0)\n","    p = F.log_softmax(logit, 1).exp()\n","    y = F.log_softmax(target, 1).exp()\n","    rp = -(1.0/(p + epsilon) -1 + epsilon).detach().log()\n","    ry = -(1.0/(y + epsilon) -1 + epsilon).detach().log()\n","    if reduce:\n","        return (p* (rp- ry) * 2).sum() / bs\n","    else:\n","        return (p* (rp- ry) * 2).sum()\n","\n","def _norm_grad(grad, epsilon = 1e-6, eff_grad=None, sentence_level=False):\n","        if sentence_level:\n","            direction = grad / (grad.abs().max((-2, -1), keepdim=True)[0] + epsilon)\n","        else:\n","            direction = grad / (grad.abs().max(-1, keepdim=True)[0] + epsilon)\n","            eff_direction = eff_grad / (grad.abs().max(-1, keepdim=True)[0] + epsilon)\n","        return direction, eff_direction\n","\n","def noise(embed, model,step_size, normalize=False, k=1, mean=0, std=0.01):  ## Not including mask in the noise, so it means no mask as input for predict, should be a problem\n","    if normalize == True:\n","        logits = model.predict(embed)#,attention_mask)\n","        # LNorm = LayerNorm(embed.size(),elementwise_affine=False)\n","        # normalized_embed = LNorm(embed)\n","        normalized_embed, embed_mean, embed_std = normalize_embed(embed)\n","\n","        noise = torch.normal(mean=0, std=0.01,size=(normalized_embed.size()[0],normalized_embed.size()[1],normalized_embed.size()[2]))\n","        noise = noise.to(device)\n","        noise.requires_grad_()\n","        noised_normalized_embeddings = normalized_embed+noise\n","        adv_logits = model.predict(noised_normalized_embeddings)#,attention_mask)\n","        adv_loss = stable_kl(adv_logits, logits.detach(), reduce=False)\n","        delta_grad, = torch.autograd.grad(adv_loss, noise, only_inputs=True, retain_graph=False)\n","        norm = delta_grad.norm()\n","        # if (torch.isnan(norm) or torch.isinf(norm)):\n","        #     return 0\n","        eff_delta_grad = delta_grad * step_size\n","        delta_grad = noise + delta_grad * step_size\n","        noise, eff_noise = _norm_grad(delta_grad, eff_grad=eff_delta_grad, sentence_level=0)\n","        noise = noise.detach()\n","        noised_normalized_embeddings = normalized_embed+noise\n","        denormalize_noised_embed = denormalize_embed(noised_normalized_embeddings,embed_mean, embed_std) \n","        return denormalize_noised_embed\n","    else:\n","        logits = model.predict(embed)#,attention_mask)\n","        noise = torch.normal(mean=0, std=0.01,size=(embed.size()[0],embed.size()[1],embed.size()[2]))\n","        noise = noise.to(device)\n","        noise.requires_grad_()\n","        noised_embeddings = embed+noise\n","        adv_logits = model.predict(noised_embeddings)#,attention_mask)\n","        adv_loss = stable_kl(adv_logits, logits.detach(), reduce=False)\n","        delta_grad, = torch.autograd.grad(adv_loss, noise, only_inputs=True, retain_graph=False)\n","        norm = delta_grad.norm()\n","        # if (torch.isnan(norm) or torch.isinf(norm)):\n","        #     return 0\n","        eff_delta_grad = delta_grad * step_size\n","        delta_grad = noise + delta_grad * step_size\n","        noise, eff_noise = _norm_grad(delta_grad, eff_grad=eff_delta_grad, sentence_level=0)\n","        noise = noise.detach()\n","        noised_embeddings = embed+noise\n","        return noised_embeddings"],"execution_count":27,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bunW4qF4qSyZ"},"source":["## Optimizer, Scheduler, and Some Other Training Prep"]},{"cell_type":"code","metadata":{"id":"GLs72DuMODJO","executionInfo":{"status":"ok","timestamp":1621101755634,"user_tz":-330,"elapsed":1195,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}}},"source":["#@title\n","optimizer = AdamW(model.parameters(),\n","                  lr = 2e-5,\n","                  eps = 1e-8 \n","                )"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"-p0upAhhRiIx","executionInfo":{"status":"ok","timestamp":1621101756782,"user_tz":-330,"elapsed":1347,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}}},"source":["from transformers import get_linear_schedule_with_warmup\n","\n","# Number of training epochs. \n","# We chose to run for 4, but we'll see later that this may be over-fitting the\n","# training data.\n","epochs = 4\n","\n","# Total number of training steps is [number of batches] x [number of epochs]. \n","# (Note that this is not the same as the number of training samples).\n","total_steps = len(train_dataloader) * epochs\n","\n","# Create the learning rate scheduler.\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0, # Default value in run_glue.py\n","                                            num_training_steps = total_steps)"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"9cQNvaZ9bnyy","executionInfo":{"status":"ok","timestamp":1621101758308,"user_tz":-330,"elapsed":1080,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}}},"source":["#@title\n","import numpy as np\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"gpt6tR83keZD","executionInfo":{"status":"ok","timestamp":1621101761358,"user_tz":-330,"elapsed":1869,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}}},"source":["#@title\n","import time\n","import datetime\n","\n","def format_time(elapsed):\n","    elapsed_rounded = int(round((elapsed)))\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"ScjvBSBfHtBc","executionInfo":{"status":"ok","timestamp":1621101762139,"user_tz":-330,"elapsed":921,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}}},"source":["MODE = \"SMART-adv-only\""],"execution_count":32,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mCSpuOXLqor-"},"source":["##Training Loop with Validation"]},{"cell_type":"code","metadata":{"id":"6J-FYdx6nFE_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621102002663,"user_tz":-330,"elapsed":237359,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"79d564d3-4f6a-4d4f-d94b-84a65843af4f"},"source":["import random\n","import numpy as np\n","\n","seed_val = 42\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","training_stats = []\n","total_t0 = time.time()\n","\n","# For each epoch...\n","for epoch_i in range(0, epochs):\n","    \n","    # ========================================\n","    #               Training\n","    # ========================================\n","    \n","    # Perform one full pass over the training set.\n","\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    # Measure how long the training epoch takes.\n","    t0 = time.time()\n","    total_train_loss = 0\n","    model.train()\n","\n","    # For each batch of training data...\n","    for step, batch in enumerate(train_dataloader):\n","        # Progress update every 40 batches.\n","        if step % 40 == 0 and not step == 0:\n","            elapsed = format_time(time.time() - t0)\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","\n","        model.zero_grad()        \n","\n","        embed = model.embed(input_ids = b_input_ids)\n","        preds = model.predict(embedding_output = embed)#,extended_attention_mask=b_input_mask)   <- Didn't use mask at all, which should be a problem\n","        loss_fct = CrossEntropyLoss()\n","        regular_loss = loss_fct(preds.view(-1,2), b_labels.view(-1))\n","        loss_list = [regular_loss]\n","        if MODE in [\"SMART-adv-only\", \"SIFT\"]:\n","          normalise = True if MODE == \"SIFT\" else False\n","          noised_embeddings = noise(embed, model, 1e-3, normalize=normalise, k=1)\n","          adv_logits = model.predict(embedding_output = noised_embeddings)#,extended_attention_mask = b_input_mask)   <- Didn't use mask at all, which should be a problem\n","\n","          adv_loss = stable_kl(preds.view(-1,2), adv_logits.view(-1,2))\n","          loss_list.append(adv_loss)\n","        loss = sum(loss_list)\n","        # END MODEL\n","        total_train_loss += loss.item()\n","        loss.backward()\n","\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","        optimizer.step()\n","        scheduler.step()\n","\n","    avg_train_loss = total_train_loss / len(train_dataloader)            \n","\n","    training_time = format_time(time.time() - t0)\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epcoh took: {:}\".format(training_time))\n","        \n","    # ========================================\n","    #               Validation\n","    # ========================================\n","    # After the completion of each training epoch, measure our performance on\n","    # our validation set.\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    t0 = time.time()\n","    model.eval()\n","    total_eval_accuracy = 0\n","    total_eval_loss = 0\n","    nb_eval_steps = 0\n","\n","    # Evaluate data for one epoch\n","    for batch in validation_dataloader:\n","        \n","\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","\n","        with torch.no_grad():        \n","\n","            result = model(b_input_ids, \n","                           token_type_ids=None, \n","                           attention_mask=b_input_mask,\n","                           labels=b_labels,\n","                           return_dict=True)\n","\n","\n","        loss = result.loss\n","        logits = result.logits\n","\n","        total_eval_loss += loss.item()\n","\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","        total_eval_accuracy += flat_accuracy(logits, label_ids)   \n","\n","    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n","    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n","    avg_val_loss = total_eval_loss / len(validation_dataloader)\n","    validation_time = format_time(time.time() - t0)\n","    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n","    print(\"  Validation took: {:}\".format(validation_time))\n","    training_stats.append(\n","        {\n","            'epoch': epoch_i + 1,\n","            'Training Loss': avg_train_loss,\n","            'Valid. Loss': avg_val_loss,\n","            'Valid. Accur.': avg_val_accuracy,\n","            'Training Time': training_time,\n","            'Validation Time': validation_time\n","        }\n","    )\n","\n","print(\"\")\n","print(\"Training complete!\")\n","\n","print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"],"execution_count":33,"outputs":[{"output_type":"stream","text":["\n","======== Epoch 1 / 4 ========\n","Training...\n","  Batch    40  of    113.    Elapsed: 0:00:20.\n","  Batch    80  of    113.    Elapsed: 0:00:40.\n","\n","  Average training loss: 0.25\n","  Training epcoh took: 0:00:57\n","\n","Running Validation...\n","  Accuracy: 0.93\n","  Validation Loss: 0.18\n","  Validation took: 0:00:01\n","\n","======== Epoch 2 / 4 ========\n","Training...\n","  Batch    40  of    113.    Elapsed: 0:00:21.\n","  Batch    80  of    113.    Elapsed: 0:00:42.\n","\n","  Average training loss: 0.14\n","  Training epcoh took: 0:00:59\n","\n","Running Validation...\n","  Accuracy: 0.95\n","  Validation Loss: 0.15\n","  Validation took: 0:00:01\n","\n","======== Epoch 3 / 4 ========\n","Training...\n","  Batch    40  of    113.    Elapsed: 0:00:21.\n","  Batch    80  of    113.    Elapsed: 0:00:42.\n","\n","  Average training loss: 0.09\n","  Training epcoh took: 0:00:59\n","\n","Running Validation...\n","  Accuracy: 0.95\n","  Validation Loss: 0.14\n","  Validation took: 0:00:01\n","\n","======== Epoch 4 / 4 ========\n","Training...\n","  Batch    40  of    113.    Elapsed: 0:00:21.\n","  Batch    80  of    113.    Elapsed: 0:00:41.\n","\n","  Average training loss: 0.09\n","  Training epcoh took: 0:00:58\n","\n","Running Validation...\n","  Accuracy: 0.95\n","  Validation Loss: 0.16\n","  Validation took: 0:00:01\n","\n","Training complete!\n","Total training took 0:03:56 (h:mm:ss)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VQTvJ1vRP7u4"},"source":["Let's view the summary of the training process."]},{"cell_type":"code","metadata":{"id":"6O_NbXFGMukX","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1621102021381,"user_tz":-330,"elapsed":1042,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"5f9c555a-c6ac-4dd8-c767-617dfe9b9d17"},"source":["\n","import pandas as pd\n","\n","# Display floats with two decimal places.\n","pd.set_option('precision', 2)\n","\n","# Create a DataFrame from our training statistics.\n","df_stats = pd.DataFrame(data=training_stats)\n","\n","# Use the 'epoch' as the row index.\n","df_stats = df_stats.set_index('epoch')\n","\n","# A hack to force the column headers to wrap.\n","#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n","\n","# Display the table.\n","df_stats"],"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Training Loss</th>\n","      <th>Valid. Loss</th>\n","      <th>Valid. Accur.</th>\n","      <th>Training Time</th>\n","      <th>Validation Time</th>\n","    </tr>\n","    <tr>\n","      <th>epoch</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>0.25</td>\n","      <td>0.18</td>\n","      <td>0.93</td>\n","      <td>0:00:57</td>\n","      <td>0:00:01</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.14</td>\n","      <td>0.15</td>\n","      <td>0.95</td>\n","      <td>0:00:59</td>\n","      <td>0:00:01</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.09</td>\n","      <td>0.14</td>\n","      <td>0.95</td>\n","      <td>0:00:59</td>\n","      <td>0:00:01</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.09</td>\n","      <td>0.16</td>\n","      <td>0.95</td>\n","      <td>0:00:58</td>\n","      <td>0:00:01</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n","epoch                                                                         \n","1               0.25         0.18           0.93       0:00:57         0:00:01\n","2               0.14         0.15           0.95       0:00:59         0:00:01\n","3               0.09         0.14           0.95       0:00:59         0:00:01\n","4               0.09         0.16           0.95       0:00:58         0:00:01"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"68xreA9JAmG5","colab":{"base_uri":"https://localhost:8080/","height":427},"executionInfo":{"status":"ok","timestamp":1621102024459,"user_tz":-330,"elapsed":2362,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"6fb0271c-d512-469f-ece7-f478b7cf672f"},"source":["import matplotlib.pyplot as plt\n","% matplotlib inline\n","\n","import seaborn as sns\n","\n","# Use plot styling from seaborn.\n","sns.set(style='darkgrid')\n","\n","# Increase the plot size and font size.\n","sns.set(font_scale=1.5)\n","plt.rcParams[\"figure.figsize\"] = (12,6)\n","\n","# Plot the learning curve.\n","plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n","plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n","\n","# Label the plot.\n","plt.title(\"Training & Validation Loss\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.xticks([1, 2, 3, 4])\n","\n","plt.show()"],"execution_count":35,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAvAAAAGaCAYAAABpIXfbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeUBU5f4G8GcGGPZdtgRcA5RdUzMpd8QtRVFE08zc1yzXn9q1bmaihqnpdc9McEFwRVNxyzJNRXABNEwFUUGUVYGBOb8/iMlpQId1Bnw+f915z/adkdN95sz3vEckCIIAIiIiIiKqE8TqLoCIiIiIiFTHAE9EREREVIcwwBMRERER1SEM8EREREREdQgDPBERERFRHcIAT0RERERUhzDAE9FrLyUlBc7Ozli1alWl9zFnzhw4OztXY1X1V3mft7OzM+bMmaPSPlatWgVnZ2ekpKRUe30RERFwdnbG+fPnq33fRETVQVvdBRAR/VtFgnB0dDTs7e1rsJq659mzZ/jf//6HqKgopKWlwcLCAq1bt8bEiRPRrFkzlfYxdepU/Pzzz9i7dy9atGhR5jqCIKBr167Izs7G2bNnoaenV51vo0adP38eFy5cwIcffggTExN1l6MkJSUFXbt2xbBhw/D555+ruxwi0jAM8ESkcYKDgxVeX7p0CTt37kRgYCBat26tsMzCwqLKx2vYsCHi4uKgpaVV6X3897//xRdffFHlWqrD/PnzcejQIfTp0wdt27ZFeno6Tpw4gdjYWJUDfEBAAH7++Wfs2bMH8+fPL3Od33//Hffv30dgYGC1hPe4uDiIxbXzw/CFCxewevVq+Pv7KwX4fv36oXfv3tDR0amVWoiIKooBnog0Tr9+/RReFxcXY+fOnfDy8lJa9m+5ubkwMjKq0PFEIhF0dXUrXOeLNCXsPX/+HEeOHIGPjw+WL18uH588eTIKCwtV3o+Pjw/s7Oxw4MABzJo1CxKJRGmdiIgIACVhvzpU9d+gumhpaVXpyxwRUU1jDzwR1VldunTB8OHDcePGDXz88cdo3bo13n//fQAlQT4kJASDBg1Cu3bt4Obmhu7du2PZsmV4/vy5wn7K6sl+cezkyZMYOHAg3N3d4ePjgyVLlqCoqEhhH2X1wJeO5eTk4D//+Q/at28Pd3d3DBkyBLGxsUrv5+nTp5g7dy7atWsHb29vjBgxAjdu3MDw4cPRpUsXlT4TkUgEkUhU5heKskJ4ecRiMfz9/ZGZmYkTJ04oLc/NzcXRo0fh5OQEDw+PCn3e5SmrB14mk2HdunXo0qUL3N3d0adPH+zfv7/M7ZOSkrBw4UL07t0b3t7e8PT0xIABA7B7926F9ebMmYPVq1cDALp27QpnZ2eFf//yeuCfPHmCL774Ah07doSbmxs6duyIL774Ak+fPlVYr3T7c+fOYdOmTejWrRvc3NzQo0cPREZGqvRZVERCQgImTZqEdu3awd3dHb169cKGDRtQXFyssN6DBw8wd+5cdO7cGW5ubmjfvj2GDBmiUJNMJsMPP/yAvn37wtvbG61atUKPHj3wf//3f5BKpdVeOxFVDq/AE1Gdlpqaig8//BB+fn7w9fXFs2fPAACPHj1CeHg4fH190adPH2hra+PChQvYuHEj4uPjsWnTJpX2f/r0aYSGhmLIkCEYOHAgoqOjsXnzZpiammL8+PEq7ePjjz+GhYUFJk2ahMzMTGzZsgVjx45FdHS0/NeCwsJCfPTRR4iPj8eAAQPg7u6OxMREfPTRRzA1NVX589DT00P//v2xZ88eHDx4EH369FF5238bMGAA1q5di4iICPj5+SksO3ToEPLz8zFw4EAA1fd5/9vixYvx448/ok2bNhg5ciQyMjLw5ZdfwsHBQWndCxcu4OLFi+jUqRPs7e3lv0bMnz8fT548wbhx4wAAgYGByM3NxbFjxzB37lyYm5sDePm9Fzk5OQgKCsLdu3cxcOBAtGzZEvHx8QgLC8Pvv/+O3bt3K/3yExISgvz8fAQGBkIikSAsLAxz5syBo6OjUitYZV29ehXDhw+HtrY2hg0bhgYNGuDkyZNYtmwZEhIS5L/CFBUV4aOPPsKjR48wdOhQNG7cGLm5uUhMTMTFixfh7+8PAFi7di1WrlyJzp07Y8iQIdDS0kJKSgpOnDiBwsJCjfmliei1JxARabg9e/YITk5Owp49exTGO3fuLDg5OQm7du1S2qagoEAoLCxUGg8JCRGcnJyE2NhY+VhycrLg5OQkrFy5UmnM09NTSE5Olo/LZDKhd+/eQocOHRT2O3v2bMHJyanMsf/85z8K41FRUYKTk5MQFhYmH/vpp58EJycnYc2aNQrrlo537txZ6b2UJScnRxgzZozg5uYmtGzZUjh06JBK25VnxIgRQosWLYRHjx4pjA8ePFhwdXUVMjIyBEGo+uctCILg5OQkzJ49W/46KSlJcHZ2FkaMGCEUFRXJx69duyY4OzsLTk5OCv82eXl5SscvLi4WPvjgA6FVq1YK9a1cuVJp+1Klf2+///67fOzbb78VnJychJ9++klh3dJ/n5CQEKXt+/XrJxQUFMjHHz58KLi6ugrTp09XOua/lX5GX3zxxUvXCwwMFFq0aCHEx8fLx2QymTB16lTByclJ+O233wRBEIT4+HjByclJWL9+/Uv3179/f6Fnz56vrI+I1IstNERUp5mZmWHAgAFK4xKJRH61sKioCFlZWXjy5AneeecdACizhaUsXbt2VZjlRiQSoV27dkhPT0deXp5K+xg5cqTC67fffhsAcPfuXfnYyZMnoaWlhREjRiisO2jQIBgbG6t0HJlMhmnTpiEhIQGHDx/Ge++9hxkzZuDAgQMK6y1YsACurq4q9cQHBASguLgYe/fulY8lJSXhypUr6NKli/wm4ur6vF8UHR0NQRDw0UcfKfSku7q6okOHDkrrGxgYyP93QUEBnj59iszMTHTo0AG5ubm4fft2hWsodezYMVhYWCAwMFBhPDAwEBYWFjh+/LjSNkOHDlVoW7KxsUGTJk1w586dStfxooyMDMTExKBLly5wcXGRj4tEIkyYMEFeNwD539D58+eRkZFR7j6NjIzw6NEjXLx4sVpqJKKawRYaIqrTHBwcyr3hcPv27dixYwf+/PNPyGQyhWVZWVkq7//fzMzMAACZmZkwNDSs8D5KWzYyMzPlYykpKbC2tlban0Qigb29PbKzs195nOjoaJw9exZLly6Fvb09vvvuO0yePBmzZs1CUVGRvE0iMTER7u7uKvXE+/r6wsTEBBERERg7diwAYM+ePQAgb58pVR2f94uSk5MBAE2bNlVa1qxZM5w9e1ZhLC8vD6tXr8bhw4fx4MEDpW1U+QzLk5KSAjc3N2hrK/7fpra2Nho3bowbN24obVPe3879+/crXce/awKA5s2bKy1r2rQpxGKx/DNs2LAhxo8fj/Xr18PHxwctWrTA22+/DT8/P3h4eMi3+/TTTzFp0iQMGzYM1tbWaNu2LTp16oQePXpU6B4KIqpZDPBEVKfp6+uXOb5lyxZ888038PHxwYgRI2BtbQ0dHR08evQIc+bMgSAIKu3/ZbORVHUfqm6vqtKbLtu0aQOgJPyvXr0aEyZMwNy5c1FUVAQXFxfExsZi0aJFKu1TV1cXffr0QWhoKC5fvgxPT0/s378ftra2ePfdd+XrVdfnXRWfffYZTp06hcGDB6NNmzYwMzODlpYWTp8+jR9++EHpS0VNq60pMVU1ffp0BAQE4NSpU7h48SLCw8OxadMmjB49GjNnzgQAeHt749ixYzh79izOnz+P8+fP4+DBg1i7di1CQ0PlX16JSL0Y4ImoXtq3bx8aNmyIDRs2KASpM2fOqLGq8jVs2BDnzp1DXl6ewlV4qVSKlJQUlR42VPo+79+/Dzs7OwAlIX7NmjUYP348FixYgIYNG8LJyQn9+/dXubaAgACEhoYiIiICWVlZSE9Px/jx4xU+15r4vEuvYN++fRuOjo4Ky5KSkhReZ2dn49SpU+jXrx++/PJLhWW//fab0r5FIlGFa/nrr79QVFSkcBW+qKgId+7cKfNqe00rbe36888/lZbdvn0bMplMqS4HBwcMHz4cw4cPR0FBAT7++GNs3LgRo0aNgqWlJQDA0NAQPXr0QI8ePQCU/LLy5ZdfIjw8HKNHj67hd0VEqtCsywNERNVELBZDJBIpXPktKirChg0b1FhV+bp06YLi4mL8+OOPCuO7du1CTk6OSvvo2LEjgJLZT17sb9fV1cW3334LExMTpKSkoEePHkqtIC/j6uqKFi1aICoqCtu3b4dIJFKa+70mPu8uXbpAJBJhy5YtClMiXr9+XSmUl35p+PeV/rS0NKVpJIF/+uVVbe3p1q0bnjx5orSvXbt24cmTJ+jWrZtK+6lOlpaW8Pb2xsmTJ3Hz5k35uCAIWL9+PQCge/fuAEpm0fn3NJC6urry9qTSz+HJkydKx3F1dVVYh4jUj1fgiahe8vPzw/LlyzFmzBh0794dubm5OHjwYIWCa20aNGgQduzYgRUrVuDevXvyaSSPHDmCRo0aKc07X5YOHTogICAA4eHh6N27N/r16wdbW1skJydj3759AErC2Pfff49mzZqhZ8+eKtcXEBCA//73v/jll1/Qtm1bpSu7NfF5N2vWDMOGDcNPP/2EDz/8EL6+vsjIyMD27dvh4uKi0HduZGSEDh06YP/+/dDT04O7uzvu37+PnTt3wt7eXuF+AwDw9PQEACxbtgx9+/aFrq4u3nzzTTg5OZVZy+jRo3HkyBF8+eWXuHHjBlq0aIH4+HiEh4ejSZMmNXZl+tq1a1izZo3SuLa2NsaOHYt58+Zh+PDhGDZsGIYOHQorKyucPHkSZ8+eRZ8+fdC+fXsAJe1VCxYsgK+vL5o0aQJDQ0Ncu3YN4eHh8PT0lAf5Xr16wcvLCx4eHrC2tkZ6ejp27doFHR0d9O7du0beIxFVnGb+PxkRURV9/PHHEAQB4eHhWLRoEaysrNCzZ08MHDgQvXr1Und5SiQSCbZu3Yrg4GBER0fj8OHD8PDwwA8//IB58+YhPz9fpf0sWrQIbdu2xY4dO7Bp0yZIpVI0bNgQfn5+GDVqFCQSCQIDAzFz5kwYGxvDx8dHpf327dsXwcHBKCgoULp5Fai5z3vevHlo0KABdu3aheDgYDRu3Biff/457t69q3Tj6NKlS7F8+XKcOHECkZGRaNy4MaZPnw5tbW3MnTtXYd3WrVtjxowZ2LFjBxYsWICioiJMnjy53ABvbGyMsLAwrFy5EidOnEBERAQsLS0xZMgQTJkypcJP/1VVbGxsmTP4SCQSjB07Fu7u7tixYwdWrlyJsLAwPHv2DA4ODpgxYwZGjRolX9/Z2Rndu3fHhQsXcODAAchkMtjZ2WHcuHEK640aNQqnT5/Gtm3bkJOTA0tLS3h6emLcuHEKM90QkXqJhNq4s4iIiCqluLgYb7/9Njw8PCr9MCQiIqpf2ANPRKQhyrrKvmPHDmRnZ5c57zkREb2e2EJDRKQh5s+fj8LCQnh7e0MikSAmJgYHDx5Eo0aNMHjwYHWXR0REGoItNEREGmLv3r3Yvn077ty5g2fPnsHS0hIdO3bEtGnT0KBBA3WXR0REGoIBnoiIiIioDmEPPBERERFRHcIAT0RERERUh/Am1gp6+jQPMlntdx1ZWhohIyO31o9LVNfwXCFSDc8VItWo41wRi0UwNzcsdzkDfAXJZIJaAnzpsYno1XiuEKmG5wqRajTtXGELDRERERFRHcIAT0RERERUhzDAExERERHVIQzwRERERER1CAM8EREREVEdwlloiIiIiKrB8+d5yM3NQnGxVN2lUDVKSxNDJpNV2/60tHRgZGQKff3yp4l8FQZ4IiIioiqSSguRk/MUZmYNoKOjC5FIpO6SqJpoa4tRVFQ9AV4QBEilBcjMfAxtbR3o6EgqtR+20BARERFVUU5OJoyMTCGR6DG8U7lEIhEkEj0YGpoiNzez0vthgCciIiKqoqKiQujq6qu7DKoj9PT0IZUWVnp7ttBouHPXHyLidBKeZBfAwkQXAzo2Q3tXW3WXRURERC+QyYohFmupuwyqI8RiLchkxZXengFeg527/hBbDyeg8O++q4zsAmw9nAAADPFEREQahq0zpKqq/q2whUaDRZxOkof3UoVFMkScTlJTRURERESkbgzwGiwju6BC40RERER1zeTJYzF58tha37YuYwuNBrM00S0zrFua6KqhGiIiInqd+Pi8pdJ6u3fvh53dGzVcDb2IAV6DDejYTKEHvlTzhqZqqoiIiIheFwsWfKnweteuMDx69ABTpnyqMG5mZl6l44SEfK+WbesyBngNVnqjauksNOYmujA1lOB8fBqa2N2Db1tHNVdIRERE9VWPHr0UXp86FY2srEyl8X/Lz8+Hnp6eysfR0dGpVH1V3bYuY4DXcO1dbdHe1RZWVsZIT89BsUyGdfuuY8eJPyESidC9jYO6SyQiIqLX1OTJY5Gbm4tZs/4Pq1aFIDExAcOGjcDHH4/DL7+cwv79kbh5MxHZ2VmwsrJGr159MXz4R9DS0lLYBwCsXr0eAHD58kVMnToeixYF46+/bmPv3j3Izs6Cu7snZs78P9jbO1TLtgCwZ88u7NixHRkZj9GsWTNMnjwdGzasVdinJmKAr2O0xGKMfd8Vwr7rCIu+BZEI6PYWQzwREVF9U/osmIzsAlhq8LNgMjOfYtas6fD19YOfX2/Y2JTUGBV1EPr6BggMHAYDA31cunQRGzf+D3l5eZg0ador97t16yaIxVoYOnQEcnKyERa2DV98MR8bNmytlm0jI8MREhIML69WCAwMwoMHDzB37gwYGxvDysq68h9ILWCAr4O0tcQY188Va/deQ+jxWxCJROja2l7dZREREVE1qUvPgnn8OB1z5ixAnz79FMYXLvwKurr/tNL07x+ApUu/RmTkbowZMwESieSl+y0qKsLmzVuhrV0SV01MTPHdd8tw+/afaNq0eZW2lUql2LhxLVxd3bFixRr5es2bv4lFixYywFPN0NYSY0J/N6yJvIbtx25CLBahs3dDdZdFREREL/j16gOcjXtQ4e2SUrNQVCwojBUWybAlKh5nrqRWeH8+Hnbo4G5X4e1UoaenBz+/3krjL4b3Z8/yUFgohaenN/bti8Ddu3fw5ptOL91v797vy4M1AHh6egEAUlPvvzLAv2rbhIQbyMrKwsSJ/grrde/uh5Urv33pvjUBA3wdpq0lxkR/N3wfcRXbfk6ESAR08mKIJyIiquv+Hd5fNa5OVlbWCiG41O3bSdiwYS0uX/4DeXl5Csvy8nJfud/SVpxSxsYmAICcnJwqb/vwYcmXqn/3xGtra8POrma+6FQnBvg6riTEu+P7yKv48UgixCIR3vPkXKxERESaoIN75a58z1zza7nPgpk9rFV1lFZtXrzSXionJwdTpoyFgYERPv54PBo2tIdEIsHNmwlYu3YVZDJZGXtSJBZrlTkuCK/+ElOVbesCPom1HtDRFmOSvxvcm1pi6+EE/BJb8Z/WiIiISHMM6NgMEm3FmCbRFmNAx2ZqqqhiYmIuISsrC/Pm/QeDBwehQ4d30aZNO/mVcHWztS35UpWSkqwwXlRUhAcPKt7yVNvUGuALCwuxdOlS+Pj4wMPDA4MHD8a5c+deud3Ro0fxySefoEuXLvD09ISfnx+WLFnyyp9UYmNj4eLiAmdnZ2RnZ1fX29AIOtpamDzADa5NLPDD4YRK9dsRERGRZmjvaosPe7rIn75uaaKLD3u6aNwNrOURi0si5otXvKVSKSIjd6urJAUuLi1hamqK/fsjUVRUJB8/duwIcnI0PyOqtYVmzpw5OHr0KEaMGIFGjRohMjISY8aMwbZt2+Dt7V3udgsWLIC1tTX69euHN954A4mJidi2bRt++eUX7NmzB7q6ukrbCIKAr776Cvr6+nj27FlNvi21KQnx7li1Jw5bouIhEqHGblghIiKimlX6LJi6yN3dA8bGJli0aCECAgIhEonw889R0JQOFh0dHYwaNRYhIUvxyScT0blzVzx48ACHDx9Aw4b2EIlE6i7xpdR2BT4uLg6HDh3CjBkzMGvWLAQGBmLr1q2ws7PDsmXLXrrtypUrceDAAUybNg2DBg3C/Pnz8dVXX+HWrVs4dOhQmdtERkbi3r17GDhwYE28HY0h0dHClIEecGlkjs2H4nHu2kN1l0RERESvGVNTMwQHh8DSsgE2bFiLsLCf8NZb7TBx4lR1lyY3cGAgPvlkBh4+fIDvv/8OsbEx+Oabb2FkZAyJRPlisCYRCWrq5g8ODsaPP/6I8+fPw9DQUD6+bt06hISE4MyZM7C2Vn0OztzcXLRu3RqjR4/GzJkzlZb5+flh3LhxyMzMxOrVq/HHH3/AxKTifVgZGbmQyWr/Iyt9EquqCqTF+G53LBKTMzGmT0u8XUe/wRNVVEXPFaLXFc+V6vXw4V3Y2jZSdxlURTKZDH36dEfHjp0xe/Z8AIC2thhFRa++6baiXvY3IxaLYGlpVO62arsCHx8fjyZNmiiEdwDw8PCAIAiIj4+v0P4eP34MADA3N1datmbNGhgZGSEoKKjyBdcxujpamBbgCWcHM2w4eAMX4h+puyQiIiIijVFQoDzLz5Ejh5CdnQVv79ZqqEh1auuBT09Ph42NjdK4lZUVACAtLa1C+9uwYQO0tLTg6+urMH7nzh38+OOPWLVqVZlzlNZnupKSEB+yOxbr99+ASCRCGxfNfrIYERERUW2Ii7uCtWtXoVOnLjAxMcXNmwk4dGg/mjZths6du6m7vJdSW6LNz8+Hjo6O0njpDahlfSsqz4EDBxAeHo5x48bB0dFRYdnixYvRpk0bdO7cuWoF/+1lP2fUNCsr40pt99WEDli44RzW7b8OU1N9dPDgPPFUv1X2XCF63fBcqT5paWJoa3N27rrE0dEBVlZWCA/fiezsLJiYmKJXrz6YMGEK9PUVe+Br4t9WLBZX+hxUW4DX09ODVCpVGi8N7mXNJFOWixcvYt68eejUqROmTZumsOzMmTP45ZdfEBkZWfWC/1ZXeuD/bVJ/N4TsisXSbReR088NrZ2tqrE6Is3Bvl4i1fBcqV4ymaxG+qSp5tjYvIElS0LKXPbiv2VN9cDLZLJyz0GN7YG3srIqs00mPT0dAFS6gTUhIQETJkyAs7MzQkJCoKWl+NStpUuXokuXLjA0NERKSgpSUlLk87+npqZWuE2nLtPX1cb0wZ5obGeM/+27hpib6eouiYiIiIgqQW1X4F1cXLBt2zbk5eUp3MgaGxsrX/4y9+7dw+jRo2FhYYF169bBwMBAaZ0HDx7g5s2bOHbsmNKyfv36wdPTE7t27ariO6k79HW1MX2QF77ddQVr9l7DJH93eL3ZQN1lEREREVEFqC3A+/n5YfPmzdi9ezdGjhwJoOTJrBEREWjVqpX8BtfU1FQ8f/4czZr98+jg9PR0jBo1CiKRCJs2bYKFhUWZx1i2bJnC07UA4NChQ4iKisLSpUthZ/f6PeTIQE8bnw72wvKdMfg+8iomDXCHV3OGeCIiIqK6Qm0B3tPTE35+fli2bBnS09Ph6OiIyMhIpKamYvHixfL1Zs+ejQsXLiAxMVE+Nnr0aCQnJ2P06NG4dOkSLl26JF/m6Ogof4prp06dlI5bOj1lp06dKjUPfH1goKeNzwK9sGzHFayJvIrJA9zh0YwhnoiIiKguUOu8isHBwVixYgX27duHrKwsODs7Y/369Wjd+uVzbyYkJAAANm7cqLTM399fHuCpfAZ6OvhsiBeWhV3B6ohrmDLQHe5NLdVdFhERERG9gtqexFpX1dVZaMqT+1yKZWExSM14hqkB7nBrwhBPdRtn1iBSDc+V6sUnsdZffBIraRwjfR3MCPKGnaUBVu25iut3nqi7JCIiIiJ6CQZ4KgnxQ7xgY66PleFxuMEQT0RERNUsKuoAfHzewoMHqfKxgIC+WLRoYaW2rarLly/Cx+ctXL58sdr2WVsY4AkAYGwgwYwgb1j/HeLj7z5Vd0lERESkRrNmTUe3bj54/vx5uet8+ulk9OjRUf4gTk10/PjP2LUrVN1lVCsGeJIzMZBg5hBvNDDTx3fhsUi8xxBPRET0uurevQfy8/Nx9uzpMpc/ffoEly79gffe6wxdXd1KHSM0dA9mz55flTJfKTr6KHbtClMa9/JqhejoX+Hl1apGj18TGOBJgYmhBDODvGFpooeQ3bG4mZyp7pKIiIhIDd59txP09Q1w/PjPZS4/ceI4iouL4evrV+ljSCQSaGurZ1JEsVgMXV1diMV1Lw6rdRpJ0kymhhLMCvJGcFgMQnbFYvpgTzg5mKm7LCIiIqpFenp6ePfdjjh58jiys7OVnp9z/PjPsLS0hINDIyxb9g0uXbqAR48eQU9PD61avYVJk6bBzu6Nlx4jIKAvvL1bY968hfKx27eTsGLFUly7dhWmpqbo128AGjSwUtr2l19OYf/+SNy8mYjs7CxYWVmjV6++GD78I2hpaQEAJk8eiytXLgMAfHzeAgDY2tohPPwALl++iKlTx2Plyv+hVau35PuNjj6Kn376AXfv3oGBgSHeffc9jBs3BWZm/2ShyZPHIjc3F59//iW+/TYY8fHXYWxsgkGDhmDYsA8r9kFXAgM8lcnUSBczg7yxJDQGIbtj8dlgLzS3N1V3WURERK+NCw8vY3/SETwtyIS5rhneb+aHtra12+7Rvbsfjh49jFOnovH++/7y8YcPH+DatTgEBAxBfPx1XLsWh27desDKyhoPHqRi7949mDJlHH76aTf09PRUPl5GxmNMnToeMpkMH3zwIfT09LF/f2SZLTpRUQehr2+AwMBhMDDQx6VLF7Fx4/+Ql5eHSZOmAQA+/HAUnj9/jkePHmDKlE8BAPr6BuUePyrqAL7++gu4urpjwoSpSEt7hD17duL69WvYsOFHhTqys7Pw2WdT0blzV3Tt6ouTJ49j7dpVaNq0Odq376Dye64MBngql5mRbsmV+NDL+HbXFXwW6IVmDRniiYiIatqFh5cRmrAHUpkUAPC0IBOhCXsAoFZDfJs27WBmZo7jx39WCPDHj/8MQRDQvSEp74IAACAASURBVHsPNGvWHJ07d1PYrkOH9zB+/Ec4dSoafn69VT7e9u1bkZWViY0bt8HZ2QUA0LNnHwQF+Sutu3DhV9DV/efLQf/+AVi69GtERu7GmDETIJFI0KbN24iI2I2srEz06NHrpccuKirC2rWr0Ly5E1atWgeJRAIAaNmyJRYsmIsDByIREDBEvn5a2iP85z9foXv3khaiPn36ISCgDw4d2scAT+plbqyLWUNbYYk8xHuj6Rsmr96QiIiIcP7BJZx78EeFt/sr6x6KhCKFMalMiu3x4fgt9UKF99ferg3a2b38Sfdl0dbWRpcu3bB37x48fvwYDRo0AAAcP34U9vYOaNnSTWH9oqIi5OXlwt7eAUZGxrh5M6FCAf7cuV/h7u4pD+8AYG5uju7deyIycrfCui+G92fP8lBYKIWnpzf27YvA3bt38OabThV6rwkJN/D06RN5+C/VtWt3rFwZgt9++1UhwBsZGaFbtx7y1zo6OmjRwhWpqfcrdNzKYICnVzI3LrkSvyT0MpbvvIIZQ7zQxI4hnoiIqKb8O7y/arwmde/uh4iI3Thx4igGDx6KO3f+wp9/3sRHH40BABQU5GPbth8QFXUA6elpEIR/nlifm5tboWM9evQQ7u6eSuOOjspPLL19OwkbNqzF5ct/IC8vT2FZXl7FjguUtAWVdSyxWAx7ewc8evRAYdza2gYikUhhzNjYBElJf1b42BXFAE8qsTDRw6ygkivxy3dcwYwgLzS2ZYgnIiJ6mXZ2rSt15Xv+r1/jaYHyTHDmumb4pNX46ihNZe7unrCza4hjx45g8OChOHbsCADIW0dCQpYiKuoABg0KgpubO4yMjACIsHDh/ymE+eqUk5ODKVPGwsDACB9/PB4NG9pDIpHg5s0ErF27CjKZrEaO+yKxWKvM8Zp6zwrHrvEjUL1haaqHWUO9YaCnjeU7ruDuwxx1l0RERFQvvd/MDzpiHYUxHbEO3m9W+Skbq6JbN1/Ex99ASkoyoqOPwtm5hfxKdWmf+5Qp09G5cze0afM2PDy8Knz1HQBsbGyRkpKsNH7v3l2F1zExl5CVlYV58/6DwYOD0KHDu2jTph2Mjcu6uCgqY0yZra1dmccSBAEpKcmwsbFT7U3UAgZ4qpAGpvqYFeQNPYkWlu2Iwb1HDPFERETVra1tKwx1GQhz3ZKpC811zTDUZWCtz0JTyte3JwBg9eoQpKQkK8z9XtaV6D17dqK4uLjCx2nfvgOuXo1FYmKCfOzp06c4duywwnqlc7e/eLVbKpUq9ckDgL6+vkpfJlxcWsLc3AJ794ZDKpXKx0+cOI709DS8807N3phaEWyhoQprYKYvv7F1aVgMZgZ5w9HGWN1lERER1SttbVupLbD/W5MmTdG8uRPOnj0DsViMrl3/uXnznXd88PPPUTA0NELjxk1w/fpVXLx4AaamFZ+5bujQD/Hzz1H49NNJCAgYAl1dPezfHwkbGzvk5t6Sr+fu7gFjYxMsWrQQAQGBEIlE+PnnKJTVveLs7IKjRw9j1apv4eLSEvr6BvDxeU9pPW1tbUyYMAVff/0FpkwZh27dfJGW9gjh4TvRtGkz9O2rPBOOuvAKPFWKlVnJlXiJjhaW7biClLSK/0xGREREdUfpVXdv79by2WgAYNq0GejRoxeOHTuM1atX4PHjx1ix4vuXzrdengYNGmDlynVo0qQZtm37Abt3h8HPrxcGDRqisJ6pqRmCg0NgadkAGzasRVjYT3jrrXaYOHGq0j779RuIHj16IirqIL74Yj5WrFha7vF79eqLhQsXoaAgH99//x2iog6gR4+e+O67/5U5F726iITa6LSvRzIyciGT1f5HZmVljPR0zWtXefT0GYJDYyAtkmHWUG/YWxmpuyR6zWnquUKkaXiuVK+HD+/C1lZ5phSq+7S1xSgqqv6bYl/2NyMWi2BpWX6m4hV4qhIbcwPMCvKGlpYIS8NicD+dV+KJiIiIahIDPFWZjUVJiBeLS0J86uO8V29ERERERJXCAE/Vws7SELOCvAGRCMFhMXiQwRBPREREVBMY4KnayEO8ICA4LAYPnzxTd0lERERE9Q4DPFWrNxoYYubQVpDJBASHXsYjhngiIiKiasUAT9WuYQNDzAzyRlFxyZX4R08Z4omIiIiqCwM81Qh7KyPMCvKGtEiG4NAYpDHEExEREVULtQb4wsJCLF26FD4+PvDw8MDgwYNx7ty5V2539OhRfPLJJ+jSpQs8PT3h5+eHJUuWICdHcT7bBw8eYNWqVQgICECbNm3Qrl07DB8+XKVjUNXZWxthxhAvFEqLERwWg/TM5+ouiYiIqMbw0Tqkqqr+rag1wM+ZMwdbt27F+++/j3nz5kEsFmPMmDGIiYl56XYLFixAUlIS+vXrh/nz58PHxwfbtm1DUFAQCgoK5OtFR0dj48aNaNSoET755BNMnDgReXl5GDlyJPbu3VvTb48AONoYY2aQNwoKixEcGoPHDPFERFQPaWlpQyotVHcZVEdIpYXQ0tKu9PZqexJrXFwcBg0ahLlz52LkyJEAgIKCAvTp0wfW1tbYvn17udueP38e7dq1Uxjbu3cvZs+ejcWLF2PAgAEAgFu3bsHS0hIWFhby9QoLC9GvXz8UFBTgxIkTFa6bT2KtnLsPc7A0LAYGetqYNdQbDUz11V0S1VN1/Vwhqi08V6rX8+d5yMl5CjMzK+joSCASidRdElWT6nwSqyAIkEoLkZmZDmNjc+jrG5a53quexFr56F9FR44cgY6ODgYNGiQf09XVRUBAAEJCQpCWlgZra+syt/13eAeAbt26AQCSkpLkY2+++abSehKJBB07dsSWLVuQn58PPT29qr4VUkEjW2PMCPLC0rArCA6NwZxhrWBhws+eiIjqh9IglpX1GMXFRWquhqqTWCyGTFY9AR4o+bXmZeFdFWoL8PHx8WjSpAkMDRWL9/DwgCAIiI+PLzfAl+Xx48cAAHNz81eum56eDgMDA+jq6lasaKqSxrYmmDHEC8t2xGBJ6GXMHsoQT0RE9Ye+vmGVQhlpJk38tUptPfDp6ellBnQrKysAQFpaWoX2t2HDBmhpacHX1/el6929exfHjh2Dn58ff95SgyZ2Jvg00Au5z6UIDovB05yCV29ERERERHJquwKfn58PHR0dpfHSq+Iv3oz6KgcOHEB4eDjGjRsHR0fHctd7/vw5pk2bBn19fUyfPr3iRQMv7UeqaVZWxmo7dnWysjLGl6YG+Hz9OSzfeQVfT+wAS/bEUzWqL+cKUU3juUKkGk07V9QW4PX09CCVSpXGS4O7qu0tFy9exLx589CpUydMmzat3PWKi4sxffp0JCUlYdOmTRVqz3kRb2KtHpaGOpg+yBPLd13BnNVnMWuoN8yM2NJEVVffzhWimsJzhUg16jhXXnUTq9paaKysrMpsk0lPTwcAlQJ2QkICJkyYAGdnZ4SEhEBLS6vcdefPn4/Tp09jyZIlaNu2beULp2rT3N4U0wd54mlOAZaGxSArl+00RERERK+itgDv4uKCv/76C3l5eQrjsbGx8uUvc+/ePYwePRoWFhZYt24dDAwMyl13yZIliIiIwP/93/+hV69eVS+eqo2Tgxk+GeSBjOx8BIfFICuPc+gSERERvYzaAryfnx+kUil2794tHyssLERERARatWoFGxsbAEBqaqrC1JBAyVX6UaNGQSQSYdOmTQrzvP/bxo0bsXnzZowfPx7Dhw+vmTdDVeLsaI7pgzyRkZ2PZWExyGaIJyIiIiqX2h7kBADTpk1DdHQ0PvzwQzg6OiIyMhLXrl3D1q1b0bp1awDA8OHDceHCBSQmJsq369evHxISEjB69Gg4OTkp7NPR0RHe3t4AgGPHjmHy5Mlo3LgxJk6cqHT87t27v/TKfVnYA19z4u8+xXe7Y2Flro+ZQd4wMZCouySqg16Hc4WoOvBcIVKNJvbAq+0mVgAIDg7GihUrsG/fPmRlZcHZ2Rnr16+Xh/fyJCQkACi5uv5v/v7+8gBfut6dO3cwa9YspXWjo6MrHOCp5rRoZI6pAR74LjwOy8KuYGaQF4wZ4omIiIgUqPUKfF3EK/A17/qdJ1gZHgdbCwPMDPKGkb7ydKNE5XmdzhWiquC5QqQaTbwCr7YeeKLyuDa2wJSB7niQ8QzLdsQg97nydKNERERErysGeNJIbk0sMWWgO1If52H5jivIy2eIJyIiIgIY4EmDuTe1xOQB7rj/OBfLd1zBM4Z4IiIiIgZ40mwezRpgor87ktNysXznFTzLL1J3SURERERqxQBPGs+reQNM9HfDvUe5+HbXFTwvYIgnIiKi1xcDPNUJ3m9aYUJ/N9x9mMMQT0RERK81BniqM1o5WWF8P1f8lZqDkN2xDPFERET0WmKApzqltbM1xvdzxe372VixOxb5hQzxRERE9HphgKc65y0Xa4x9vyWS7mdjxe44FBQWq7skIiIiolrDAE91UtsWNhjTtyVupWTiu/BYhngiIiJ6bTDAU53VrqUNxvRpicTkv0O8lCGeiIiI6j8GeKrT3na1xejeLZF4LxMrw+NQyBBPRERE9RwDPNV57d1sMap3CyTcfYpVexjiiYiIqH5jgKd6oYO7HT7q1QI37jzF6oirkBYxxBMREVH9xABP9YaPhx1G9nTBtb+eYHXENUiLZOouiYiIiKjaMcBTvfKu5xsY2dMFV29n4PvIqwzxREREVO8wwFO9857nGxjh54y4pAys3XsNRcUM8URERFR/MMBTvdTJqyGG+zrhyp+PGeKJiIioXmGAp3qrcyt7DOvuhJhbj/G/fdcZ4omIiKheYICneq1ra3sM7fYmLt9Mx7r9DPFERERU9zHAU73X7S0HDOn6Ji4lpmP9gRsoljHEExERUd2lre4CiGqDbxsHCIKAnSf+hFgEjOnbElpifn8lIiKiuketAb6wsBDfffcd9u3bh+zsbLi4uGD69Olo3779S7c7evQooqKiEBcXh4yMDNjZ2aFz586YOHEijI2NldbfvXs3Nm/ejJSUFLzxxhsYMWIEhg0bVlNvizRUj7aOEARg18k/ATDEExERUd2ktXDhwoXqOvjMmTMRERGBwYMHo2/fvkhMTMSmTZvQvn172NnZlbvd0KFDUVhYiF69eqF3794wNDREaGgooqOjMXDgQGhr//O9ZMeOHfj888/Rrl07fPDBB5DJZFi/fj0MDQ3h7e1d4ZqfPy+EIFTq7VaJoaEunj0rrP0D1zPN7U2hoy3GsYspSH/6HN5vWkEkEqm7LKpGPFeIVMNzhUg16jhXRCIRDAwk5S8XBHXEUSAuLg6DBg3C3LlzMXLkSABAQUEB+vTpA2tra2zfvr3cbc+fP4927dopjO3duxezZ8/G4sWLMWDAAABAfn4+OnbsiNatW2PNmjXydWfMmIETJ07g9OnTZV6xf5mMjFzIZLX/kVlZGSM9PafWj1tfHTp3B3tO30Z7V1t83LsFxGKG+PqC5wqRaniuEKlGHeeKWCyCpaVR+ctrsRYFR44cgY6ODgYNGiQf09XVRUBAAC5duoS0tLRyt/13eAeAbt26AQCSkpLkY+fPn0dmZiaGDh2qsO6wYcOQl5eHM2fOVPVtUB3Vu31j+L/bBOeuP8SWqHi1fCkjIiIiqgy1Bfj4+Hg0adIEhoaGCuMeHh4QBAHx8fEV2t/jx48BAObm5vKxGzduAADc3NwU1nV1dYVYLJYvp9dT3w5N0N+nCX699hA/HE6ATD0/RhERERFViNpuYk1PT4eNjY3SuJWVFQC89Ap8WTZs2AAtLS34+voqHEMikcDMzExh3dKxih6D6p/3fZpAJgjY/+sdiETAhz1dIGZPPBEREWkwtQX4/Px86OjoKI3r6uoCKOmHV9WBAwcQHh6OcePGwdHR8ZXHKD1ORY5R6mX9SDXNyqpi/fqkmtH+HtDXl2Dn8ZswMJBg4kBP9sTXcTxXiFTDc4VINZp2rqgtwOvp6UEqlSqNl4bq0iD/KhcvXsS8efPQqVMnTJs2TekYhYVl3zVcUFCg8jFexJtY6yff1g2Rm1eAQ+fuoqCgCMN9nTg7TR3Fc4VINTxXiFSjiTexqi3AW1lZldnCkp6eDgCwtrZ+5T4SEhIwYcIEODs7IyQkBFpaWkrHkEqlyMzMVGijKSwsRGZmpkrHoNeDSCTCgPeaQiYIOPz7PYhEwAfdGeKJiIhI86jtJlYXFxf89ddfyMvLUxiPjY2VL3+Ze/fuYfTo0bCwsMC6detgYGCgtE6LFi0AANeuXVMYv3btGmQymXw5EVAS4gM6NoNfO0ecvHwfocduQU2zrBIRERGVS20B3s/PD1KpFLt375aPFRYWIiIiAq1atZLf4JqamqowNSRQcpV+1KhREIlE2LRpEywsLMo8xttvvw0zMzOEhoYqjIeFhcHAwADvvfdeNb8rqutEIhEGdWoG3zYOiL6cgrBohngiIiLSLGprofH09ISfnx+WLVuG9PR0ODo6IjIyEqmpqVi8eLF8vdmzZ+PChQtITEyUj40ePRrJyckYPXo0Ll26hEuXLsmXOTo6yp+wqqenh6lTp+LLL7/EtGnT4OPjg4sXL2L//v2YMWMGTExMau8NU50hEokQ2KU5BAE4djEZ4r9fs52GiIiINIHaAjwABAcHY8WKFdi3bx+ysrLg7OyM9evXo3Xr1i/dLiEhAQCwceNGpWX+/v7yAA+UPLRJR0cHmzdvRnR0NOzs7DBv3jyMGDGiet8M1SsikQhDujaHIAg4+kcyRCJgcGeGeCIiIlI/kcD+gArhLDSvF0EQsP3YTZy4fB892zkioFMzhngNx3OFSDU8V4hUw1loiOoYkUiEYd2dIAjA4fP3IBKJMLBjU4Z4IiIiUhsGeKJXEIlEGObrBEEQEPX7XYhEwID3GOKJiIhIPRjgiVQgFonwQQ9nyAQBh87dhVgkgv97TdVdFhEREb2GGOCJVCQWiTDCzwUyATjw2x2IxSL082mi7rKIiIjoNcMAT1QBYpEII3u6QBAE7Dv7F0Qi4P0ODPFERERUexjgiSpILBLho54tIAjA3l/+gkgkQt93Gqu7LCIiInpNMMATVYJYLMKoXi0gCAIiz9yGWAT0bt9Y3WURERHRa4ABnqiSxGIRPu7dEoIA7Dl9G2KRCD3fbqTusoiIiKieY4AnqgKxWISP+7SATBCw+1QSRCIR/No5qrssIiIiqscY4ImqSEssxpi+LSETgF0n/4RYBPi2ZYgnIiKimsEAT1QNtMRijO3bEhAE7DjxJ0QiEbq3cVB3WURERFQPidVdAFF9oa0lxtj3XdHayQph0bcQfSlF3SURERFRPcQAT1SNtLXEGNfPFd5vNsD2Yzdx4jJDPBEREVUvBniiaqatJcaE/m7wat4APx29iZMx99VdEhEREdUjDPBENaA0xHs2s8S2nxNx6gpDPBEREVUPBniiGqKjLcZEf3d4NLPEj0cScSY2Vd0lERERUT3AAE9Ug3S0xZjk7wa3phbYejgBvzDEExERURUxwBPVMB1tLUwZ4I6WTSzww+EE/Hr1gbpLIiIiojqMAZ6oFpSG+BaNzbH5UDx+u8YQT0RERJXDAE9USyQ6Wpgy0AMujcyx6WA8zl1/qO6SiIiIqA5igCeqRbo6Wpga4AFnRzNsPHgDv99giCciIqKKYYAnqmW6OlqYFuAJJ3szbDhwAxfiH6m7JCIiIqpDGOCJ1EBXooVpgzzwZkNTrN9/A38kpKm7JCIiIqojtNV58MLCQnz33XfYt28fsrOz4eLigunTp6N9+/Yv3S4uLg4RERGIi4vDzZs3IZVKkZiYWOa6aWlpWLlyJX777TdkZGTAxsYGvr6+GDt2LExMTGribRGpRE+ijU8Ge+LbXbFYt+86RADecrFWd1lERESk4dR6BX7OnDnYunUr3n//fcybNw9isRhjxoxBTEzMS7c7ffo0du/eDQBwcHAod71nz55hyJAhOH78OPz9/TF//nx06NABW7Zswfjx46v1vRBVhp5EG9MHeaLpGyZYt/86LiWmq7skIiIi0nBquwIfFxeHQ4cOYe7cuRg5ciQAoH///ujTpw+WLVuG7du3l7ttUFAQxowZAz09PSxatAi3b98uc71Tp07h/v37WLduHTp16iQf19PTw+bNm5GcnPzSLwBEtUFfVxvTB3vi251X8L991zCxvxu8nazUXRYRERFpKLVdgT9y5Ah0dHQwaNAg+Ziuri4CAgJw6dIlpKWV3xPcoEED6OnpvfIYubm5AABLS0ul7QGotA+i2lAS4r3gaGOMNXuv4cqtx+ouiYiIiDSU2gJ8fHw8mjRpAkNDQ4VxDw8PCIKA+Pj4Kh+jdevWEIvFWLRoEa5cuYKHDx/ixIkT2LJlCwYMGAArK17lJM1hoKeNzwI94WhjhO8jryL2T4Z4IiIiUqa2Fpr09HTY2NgojZeG6pddgVdVs2bN8OWXXyI4OBiBgYHy8cDAQCxcuLBS+7S0NKpyXZVlZWWstmNT7fl60rtY8L9f8X3kNcz7qC3eaqF8ntDL8VwhUg3PFSLVaNq5orYAn5+fDx0dHaVxXV1dAEBBQUG1HMfW1haenp5477338MYbb+DixYvYtm0bTE1N8dlnn1V4fxkZuZDJhGqprSKsrIyRnp5T68cl9ZgW4IFlYVewaMsFTB3oDremlq/eiADwXCFSFc8VItWo41wRi0UvvWistgCvp6cHqVSqNF4a3EuDfFVcunQJ48ePR3h4OFq0aAEA6NatG4yMjLB69Wr4+/ujadOmVT5OTbrw8DL2Jx1BZkEmzHTN8H4zP7S1baXusqiGGerp4LMhXlgWFoOVe65iaoA73JowxBMREZEae+CtrKzKbJNJTy+ZRs/auurzYe/cuRPW1tby8F6qS5cuEAQBV65cqfIxatKFh5cRmrAHTwsyIQB4WpCJ0IQ9uPDwsrpLo1pgpK+DGUHesLM0wKo9V3H9zhN1l0REREQaQG0B3sXFBX/99Rfy8vIUxmNjY+XLqyojIwPFxcVK40VFRQBQ5jJNsj/pCKQyxV8ppDIpdt/ch+ScVBTLNLt+qjojfR3MGOIFG3N9rAyPQzxDPBER0WtPbQHez88PUqlU/kAmoOTJrBEREWjVqpX8BtfU1FQkJSVV6hiNGzfGo0ePcPHiRYXxgwcPAoDSlXlN87Qgs8zxZ0XP8c0fKzDjzOf49tJaRPx5EJfT4vAk/ykEofb786lmGRtIMCPIG9bm+vguPA4Jd5+quyQiIiJSo2rpgS8qKkJ0dDSysrLQuXNnlaZn9PT0hJ+fH5YtW4b09HQ4OjoiMjISqampWLx4sXy92bNn48KFC0hMTJSP3b9/H/v27QMAXL16FQCwZs0aACVX7rt06QIAGDZsGCIiIjBu3Dh88MEHsLOzwx9//IGDBw/i3XffhZubW3W8/RpjrmtWZog3lZjAv3lv3Mm+hzvZyTid/CuihTMAABOJMRqbOKKxiQMamziikYk99LQ5331dZ2Igwcwh3ggOi8GK8FhMH+QJZ0dzdZdFREREaiASKnjJNjg4GOfPn8eePXsAAIIgYMSIEbh48SIEQYCZmRl27doFR0fHV+6roKAAK1aswIEDB5CVlQVnZ2d8+umneOedd+TrDB8+XCnAnz9/HiNGjChzn/7+/vjmm2/kr2/fvo0VK1YgLi4Ojx8/hrW1NXr27IkpU6ZU6kFOtTkLTWkP/IttNDpiHQx1GahwI6tUVoT7uam4k5WMO9nJuJt9D2nPS+YQF0EEW0NrhVBvZ2gDLbFWrbwHql5ZeYUIDr2MJ9kFmD7YE04OZuouSeNwZg0i1fBcIVKNJs5CU+EA37dvX7zzzjuYO3cuACA6OhqTJk3C6NGj0aJFC/z3v/9Ft27d8NVXX1Wtcg1V29NIVnYWmjzpM9zJTv77Kv093M1KRl7RMwCARKwDRxN7NPo70DcxcYSZrilEIlFNvx2qBlm5BVgSGoOnOQX4NNATb9ozxL+IoYRINTxXiFSjiQG+wi00Dx8+RKNGjeSvT548CXt7e8yYMQMAcOvWLRw4cKASpVJZ2tq2QlvbVhX+4zHUMYCrpTNcLZ0BlPxSkv48Q952cyf7nkLrjam89cYRjU0d4GjM1htNZWqki1lDvbEkNAbf7orFZ4O90NzeVN1lERERUS2pcICXSqXQ1v5ns/Pnzyu0vDg4OMingiTNIRKJYG3QANYGDeRX8BVbb0qu1Mc+vl6yPkSwM7R5oZfega03GsTMSBezgryxJPQyvt11BZ8FeqFZQ4Z4IiKi10GFA7ytrS1iYmIwePBg3Lp1C8nJyZg6dap8eUZGBgwMDKq1SKoZOmJt+VV3oAMAIFeah7vZybiTVXKlPjb9On578AcAQKIlgaNxw3+u1Js4wFyP7RvqYm5cEuKDQ2P+DvHeaPqGibrLIiIiohpW4QDfu3dvrFmzBk+ePMGtW7dgZGSEjh07ypfHx8erdAMraSYjHUO4WrrA1bJkHv6S1pvHf7fdlFypP5l8FsVCyRz0phITNDb95wbZktabqj9Fl1RjYaL3dzvNZSzfeQUzhnihiR1DPBERUX1W4QA/btw4PHjwANHR0TAyMsKSJUtgYlISGHJycnDixAmMHDmyuuskNSlpvbGCtYGVQutNSk6qvO2m5Er9tZL1/9V609i0ZNYbsUhtjxyo9yxM9DArqFVJiN9xBTOCvNDYliGeiIiovqrwLDQvI5PJkJeXBz09Pejo6FTXbjVKbc9CU0rTZwvILcyTh/m7f1+pf1b0HEBJ600jY/t/prI0LZn1hqrX46znWLI9BvmFRZgxxBuNbI3VXZJaaPq5QqQpeK4QqUYTZ6Gp1gBfWFgIiURSXbvTSAzwqlFsvbmHO1nJSMlNlbfemOmaKtwgy9ab6pGe+RzBoZeRX1iMmUHecLR5/UJ8XTtXiNSF5wqRaupFgD99+jTi4uIwZcoU+dj27duxfPlya2TS7gAAIABJREFU5Ofno2fPnvjmm294Bb6a1Yf/0EqLpUjJTX0h1N/D4/wnAF5svSmZxrL0gVNsvam4tL9DfKFUhplB3nCwLv8/APVRfThXiGoDzxUi1WhigK9wD/ymTZtgaWkpf52UlISvv/4aDg4OsLe3R1RUFNzd3dkHT0p0tHTQxLQRmpj+8xyBF1tv7mTfw5X0q/jtwQUAgK6WBI6lrTd/3yjL1ptXszbT/3uKyRgsDYvBrCBv2L9mIZ6IiKg+q3CAv337tsKsM1FRUdDV1UV4eDiMjIzw2WefYe/evQzwpBIjiSHcGrSAW4MWAEpab9KeP5ZPY3kn+x5OJP+C4nvKrTeNTRzgaOIAXa363bZVGdbmBiWz02y/jOCwGMwa6g17K4Z4IiKi+qDCAT4rKwvm5uby17/99hvefvttGBmVhIO2bdvi9OnT1VchvVZEIhFsDKxgY2CFdnatAZS03iTnpsrbbu5mJ+PKC7PevGFk+0Kod4StoTVbbwDYmBtg9tBW+Cb0csmV+KGt0LCBobrLIiIioiqqcIA3NzdHamoqACA3NxdXr17Fp59+Kl9eVFSE4uLi6quQXns6WjpoatoITU0bAQ4lYzmFufLZbu5kJ+Ny2lX8mvpP600jYwc0+nvGm9e59cbGwkD+sKfSdpo3GOKJiIjqtAoHeC8vL+zYsQPNmzfHmTNnUFxcjPfee0++/O7du7C2tq7WIon+zVhipNB6IxNkSH/2wqw32fcQnXwGsnsyAKWtNy88cMrE/rVpvbGzNPz7YU9/h/ih3rCzZIgnIiKqqyo8C82ff/6JESNG4MmTktlD/P39sXjxYgAl/ctdu3ZFu3bt5GP1DWehqTsK5bPe3JP31Gf8PeuNWCT+Z9abv4N9fW+9uf84D0tDL0MkFmH20FawtTBQd0k1gucKkWp4rhCpRhNnoanUPPCZmZm4fPkyjI3/v717j4uyzPsH/pmBYTgMZ4bzQYQEBUFQMNTK8MSaaXlY09K1dt02a7d027XWbZ/f87Q91cam1uZWVpv6dNQwzErRNC1PeEDwgJqIwjAcBpQzzAzM/P4ARkYODXK474HP+/XqldxzH66xLvjMxfe6LmckJCSYjldVVeHLL7/E+PHjERkZeXstFjkGeOtWo6u9uepNVQGu1RSioakRAGBvI29Z9cb15ki9q3xw7WhapKnFPz7Jgk1riPcZhCGefYXIMuwrRJYZNAF+KGOAH1wMRgPK6svb7SJbAFVtMQzGltIbd7mbaffYYS7BCHYOgJ2Vl96oylpCvMxWij8vjoOP++AK8ewrRJZhXyGyzKAK8AUFBfjuu+9QWFgIAAgKCsKUKVMQHBx8ey21Egzwg19L6U2R2VKWFY03ALSU3vg7tax6E2LFpTeFZbV4rTXEr344Ht5uDkI3qc+wrxBZhn2FyDKDJsCvW7cOGzdu7LDajFQqxeOPP46nn3665y21EgzwQ1O1rqZl1RtTqC9EY3O70huXILOlLF3lzgK3+OcVlNbgtU+yYG9ngz8vjodykIR49hUiy7CvEFlmUAT4bdu24a9//Svi4uLwm9/8BnfccQcA4KeffsL777+PrKwsvPTSS5g7d27vWi5SDPAEdCy9uVpdgKJbS2/a1dKLtfTmWkkNUj/Ngr2dLVYvjoPXIAjx7CtElmFfIepeZskp7MjbhUptJdzkbpgdloJE3/gBeXafB/i5c+dCJpPho48+gq2t+SqUTU1NePjhh6HX65GWlnZ7LRY5Bnjqiq5Zj8KaItMyllerC3G9k9KbYS7BGOYaDB9HpShKb66WVCP1k9NwtLfF6sXx8HS1F7pJvcK+QmQZ9hWirmWWnMLHF76A3qA3HZNJZVgcOW9AQvzPBfgerwOfl5eHVatWdQjvAGBra4uZM2fi9ddf7+ltiayenY0MYW7DEOY2zHSsWldj2j32anUhTpRm40f1MQCAvY09QlwCb65P7xoMF7uBL70Z5uuCPz40BqmfnsarH5/Ccw/Hw8PFukM8ERFRT9XoalFUWwxVrRpfX8kwC+8AoDfosSNv14CNwnenxwFeJpOhvr6+y9fr6uogk8l61SiiwcLFzhkxyijEKKMAtJXeaJDfWnZzraoAewq+N5XeeNi7t06QHdjSm1A/F/xx4Rj887Ms/OPjls2eGOKJiGgwajY0o7Reg6LaYlNgL6otRrXu538jdUNbOQAt/Hk9DvCjR4/GZ599hgULFsDLy8vstYqKCnz++eeIjY21+H46nQ7r169Heno6qqurERkZiZUrVyIpKanb63JycpCWloacnBxcunQJer0eFy9e7PL8/Px8rF+/HkePHkV9fT0CAgIwd+5cLF++3OK2EvWWVCKFr5MPfJ18kOQ3DgCga9ahwFR60zJSf6osx3R+gJMvQlqXsQx1CYJ3P5XeDPd3waqFY/DPT0/jH59kYfXieLg7y/v8OURERAOlTl+Polo1VK1hvai2GMV1pWgyNAEAbCQ28HXyxkiPEQhQ+Jn+efX4G52GdXe520C/hU71uAb++PHjWLZsGZycnDBv3jyEh4cDaNmhNS0tDXV1dfjwww8xbtw4i+63atUqZGRkYOnSpQgJCcH27dtx9uxZbNmyBXFxcV1e9+abb+Ltt99GREQEGhoacOXKlS4D/Llz57B06VIMHz4cM2fOhJOTEwoLC1FfX48XXnihJ2+fNfA0IKq0NbjWboLstWqVadUbB1t7hDgHmcpuQlyC+rT05nJRFf752Wm4KeT486I4qwvx7CtElmFfocHEYDRAU1/eLqi3hPZKbZXpHGeZoiWgO/shUOGPAIUffByVsJV2HM8Wew38bS0juW/fPrz44osoLi42O+7v74+//e1vmDx5skX3ycnJwYIFC/D8889j2bJlAACtVotZs2bB29sbH330UZfXlpeXQ6FQwN7eHi+99BI2b97caYBvbm7G7NmzERoaijfeeANSae9GLhngSQgGowGl9ZrWZSxbgr26rqRD6U3bMpZBzgGws7n9UrafVJV4/fNsuCvk+PPiOLgprCfEs68QWYZ9haxVQ1MDimpLWkpfaloCu7quxBS2pRIpfByVCFDcDOoBCv8eL/Es5lVoelxCAwDJycmYPHkyzp49C5VKBaBlI6eoqCh8/vnnmDlzJr755pufvc+uXbsgk8mwYMEC0zG5XI758+dj7dq1KCsrg7e3d6fX3lq+05Uff/wRly9fNoX3uro6ODg49DrIEw0kqUQKPycf+Dn5IMk/AUDH0pv8qgLz0huF380Jsi7B8Hb0srj05o5AN6xcEIu1n2fjtU+y8OdFcXC1ohBPRETWz2A0oLzhOtS1xWYj622bKwKAk60jAhR+mBQwHgEKfwQq/ODr6A1ZLwax2iT6xiPRN16UH3ZvK8ADLZs2xcTEICYmxuz4jRs3kJ+fb9E9cnNzERoaCicnJ7PjMTExMBqNyM3N7TLAW+rIkSNQKBQoLS3FihUrcPXqVTg4OGDWrFlYs2YNHBysf91rGprsbOwQ7haKcLdQ07EqbbWp7OZqdSGOl5zCD0VHAHQsvRnmEgxnu64/3Y8IcsMzC2Kwdms2Xvv0NP60KA6uTuJby56IiKxfY5MW6rqSm/XqNcVQ1xVD26wDAEgggbejEsNcgjHBfzwCW2vV3eSukEgkArd+4N12gO8LGo0GPj4+HY4rlUoAQFlZWa+fce3aNTQ3N2PFihWYN28e/vjHPyIrKwv/+c9/cP36dWzYsKHXzyASC1e5C2KVUYhtt+pNSV1Zu1r6QmS0W/XG097dbBnLQIV56U1EsDuemR+LdVuzkfpJFv60KA4uDPFERHSbjEYjrjfeaB1RV5smlpY3XIcRLSXKDrb28Hfyw51+40xlMH5OPqLcEFEoggb4xsbGTpeclMtbflWv1Wp7/Yz6+no0NDTgoYceMk1YnT59OiQSCd5//31cuHABkZGRFt+vu3qk/qZUDvwa4WT9fOCKWNxh+rqxSYv8GwX4qeIqLldcxU/X83GyLBsAYCORIsQtEOGew3CHRyjCPYdh4thAuLg64H/eP4Z123Lw999NEH05DfsKkWXYV6g/6Zp0KKhS41qlCtcqi3CtquXf9foG0zm+CiWGewbjXrcJGOYWgBC3QHg5eohuVF1sfUXQAG9vbw+9Xt/heFtwbwvyvX0GAMyaNcvs+OzZs/H+++/j5MmTPQrwnMRKg4EXfOHl6YskzzsBtJXetK56U1WAA/lHkXH5IADAwdYBIc6BGH+vEsdOlODPGxqweuF4ODuKcySEfYXIMuwr1FeMRiMqtVWta6rfHFkvqy83jarLbezg7+SHeO/Y1vIXf/g7+cLe9pasVw+U19cK8C66JkRf6ZdJrH1FqVR2Wiaj0WgAoNf1723PAABPT0+z421fV1dX9/oZRNaupfQmGrHKaAAdS2+uVhfgYu1l2IQbcQMn8Zcf9mG0bxjCPUJaVr1R+PfJhCEiIhI3fbMexfWlLau/1BWbVoGpa7q5yaenvTsCFP5mYd3Twb1f9jAZqiwK8P/5z38svuGpU6csPjcyMhJbtmxBXV2d2UTW7Oxs0+u9FRUVha1bt6K0tBTDhw83HS8pKQEAeHh49PoZRIONVCKFv8IX/gpfTGhd9UbbrENBtQpHr17A4SsXcKb0J2RX3Fz1JtC06k1LTb2yB6veEBGR+FRpa0yj6W27lZbWa0zzqGRSGfwVvhjjHQ1/05KNvnCw5QIh/c2iAP/qq6/26KaW1i2lpKTggw8+wNatW03rwOt0OqSlpSE+Pt40wVWtVqOhoQFhYWE9agfQsuTlSy+9hG3btpnt7rp161ZIJBLceeedPb4n0VAkt7HDHe7DcYf7cMS6jMe/0nLg62uD+5JdUNygxtXqAhwrOYmDplVvHFqXsGxZxjLEJajbVW+IiEgYTYYmlNZroKq5Oam0qLYYNfqbpSxuclcEKvwQ4xXVOrHUjwM1ArIowG/evLlfHh4bG4uUlBSkpqZCo9EgODgY27dvh1qtxssvv2w6b/Xq1cjMzDTbqKmoqAjp6ekAgDNnzgCAaUWZyMhIJCcnAwB8fHzw29/+Fm+99Rb0ej3uvPNOZGVlYceOHVi8eDFCQkL65b0RDWYxYZ548sHR+FfaGezeo8ezD02Do72sXenNzQ2ndl3dZ6qB9LL3MC1hGeISxNIbIqIBVqOrNQvpqlo1SurK0GxsBgDYSm3h5+SDKK/Idpsg+cFJ5ihwy6m929qJtS9ptVqsW7cOX331FaqqqhAREYFVq1ZhwoQJpnOWLFnSIcAfO3YMS5cu7fSeDz74IF555RXT10ajEZs2bcLHH38MtVoNb29vLFiwAI8//niPN3TiJFaim07/VI63tp9BsI8z/rhwDBztO44JNDZpUVijMlufvm1raxuJjfmGU67B8Hbw6tXqA+wrRJZhXxncmg3NKGsoR1GN2mwTpCrdzf/mrnbOCGgX0gMUfvBxVMJGaiNgy8VHjJNYBQ/w1oYBnshc1iUNNnx5FsN8nbFq4Rg4yH/+F3uV2irTijdXqwtwrUYFXetmHY62DghpLbtpK79R2Dn9zB1vYl8hsgz7yuBRr683hXRVrRrq2mIU15VCb2gC0DJY4uvkbQrpbSPrLGu0DAP8IMAAT9TRyYsavJ1+FsP8nLHql5aF+PYMRgOK60pbRuirWkbqi+tKb5beOHiawvwwlyAEOgdAJjV/RmbJKezI24VKbSXc5G6YHZaCRN/4PnuPRIMNf65YH4PRAE1DRctoeruR9RvaStM5CpmTWelLgMIPvk7esJUKuvCgVWOAHwQY4Ik6d+JCGd5OP4fhAS5YuSC2xyH+Vo1NWhTUqEw7yN5aehOo8Mcw15ZQX6OtwVf5GdAbbu4rIZPKsDhyHkM8URf4c0XcGpoa29Wqt4T14toS6Fq/z0klUng7KluXaWxZqjFQ4QcXO2fRbYJk7RjgBwEGeKKuHb9QhnfSzyE8wAXP/DIW9nZ9O+JTqa1qLbsp7FB60xmFzAkrYh+Di50znO0UHIEiaoc/V8TBYDSgouGGabnGts2QKhqvm85xtHUwK30JcPaDn6MPFwEYIAzwgwADPFH3MnNL8e6O8wgPdMXKBbGQ2/XfZKhmQzNK6svwv5lrLTrfydYRznJnuNg5w8VO0fpvZ1PAd7FzhovcGQqZE5dGo0GPP1cGnrZZB7Vpt9KWkXV1bQkam1t2oJdAAm9Hr9Y11W/Wq7vJXTmqLiAxBngORxFRn0oc6QOjEXj3q3NYvy0bTy+IhVzWPyHeRtqyio273M2sBrSNi50zHoqYi2pdDWp0NajW1Zr+fLWqANW6GtOvo9uTQAKFnZNZwG8L/c5tf5a3hH4nW0f+YCUiM0ajEdcbK9ttglQMdW0xNA0Vprk99jb2CFD4ItF3bEtYd/aDv5Mv7GzsBG49WQMGeCLqc+NH+cBoNGLjzvN4Y1sO/jA/pt9CPADMDkvBxxe+6FAD/2D4fYhVRnV5ndFohLZZawr2LeG+9c/aGtToa1CtrUVJXRmqdTWmdZLbs5HY3By9bzeq79wa8tsHf3sbOcM+0SCja9ajuK7EFNRbQnsJGpoaTOd4OXgiUOGHBN8407KNnvbu/H5At40Bnoj6xZ1RvjAagfd2nsebX+TgD/NiYNdPIb5tompPV6GRSCSwt7WHva09vB29uj3XaDSioanBFPSr2wf91j9XaqtRUFOEGl2taZStPZlUZhb0OyvnaRvht2NtK5GoGI1GVOmqzXYrVdUWo6xeY+rvdjZ2CHDyxVjvmJZJpa2j6va29gK3ngYb1sD3EGvgiXrm0JlifPB1LkYNc8fv+zHEtxFDXzEYDajT198M+9qajiP8rX+u1dd1eg97G/ubJTudBn0FJ+dSr4ihr4iV3tCEkrpSU+lL28h6nb7edI6HvXtrjbqfaVTdy8GD82cGIdbAE9GQM3G0HwxGIz785gL+lXYGv583GjLbwb3Ln1QihbOdAs52CgTAr9tzmw3NqNHXtgv6te1q9lv+UdcW44LuEhqaGju9h5PM8WZt/i2Tc01hn5NziTpVratBUU3LBkhtI+sl9WUwGA0AAJnUFv5Ofoj1ijZbW91R5iBwy2koY4Anon53V4w/jEbgw28v4F9pZ/HU3NGQ2TJIAi0Tcd3krnCTuwLO3Z+ra9abjeD35eTcW+v2HW0dWJ9Lg0rbqlVtu5UW1RSjqK4YNbpa0zluclcEKPwQ7TXSNLLu7ejFD74kOgzwRDQg7o71h9FoxKZdF/HW9jN48kGG+J6ys5HB08Edng7u3Z7X95NzO6vb5+RcEq9aXZ3ZBkhFtcUoqStFU+v/67YSG/g5+SDKIxIBzi1lMP4KPyhkTgK3nMgyDPBENGDuGRMAoxHYvPsi/v3lWax4MBq2Ngzxfa2vJue2Bf9KbRUKalQWTM5tDfVdrrXPybnUt5oNzdA0lJtCetvIepWu2nSOi50zAhR+iPS4w7Suuo+jEjbSwV3KR4MbAzwRDajJcQEwGI34v4xL+PeXZ/HEAwzxQpJIJHCUOcJR5ghfJ59uz7Vkcm5ZQznyqq52PzlXroCzrP3k3I4TdDk5l25Vr28wG1Evqi1GcV0J9IYmAC1zT3wdvTHCPRyBzjc3QXK263oiIJG14ndHIhpwyfGBMBqBj/Zcwtvp5/C7OVEM8Vbgtibnas1H9jk5l36OwWhAeUOF2W6lqppis83aFDInBCj8cFdAUuukUn/4OnlDxg99NETw/3QiEsSUsYEwGI34ZO9PeGfHOTw+myF+MDGbnPszWibn1txSs29eznO1qgBVuhqzzbraSCAxfbDobHJuy665nJwrRo1NjSiqLTEbWVfXFpsmYUsggY+jEsNdQxCoSEJA68i6q50L/zvSkMYAT0SCmTYuCEaDEZ/uu4x3vzqPx2ePgo2UIX6oaZmc6wFPB49uz/u5ybltX/fF5FwXO2fIOTm3zxiNRlQ0XjcrfymqUaO88brpHAdbBwQq/DDBP7FlEySFH3ydfDhvgqgTDPBEJKjpicEwGIHP91+GVAIsv58hnjrXq8m52hpUtyvp6fHkXLlzp8Gfk3M70jbroG4dVW/brVRdW4zGZi2AllF1paMnglwCcadfgqle3V3uxg9MRBZigCciwaWMD4YRRmzdnweJRILfzBrJEE+9ctuTc9tNzDWbnFuvQV5l/s9OzjWtp99Z7b7cGc4yxaBZ/cRoNOKGtrIlpNcUmwK7pqHC9IHI3kYOf4UfEn3jTbXq/gpfyG3sBG49kXVjgCciUfjF+BAYDEZ8ceAKJBLgN/eNglTK0Tjqf2aTcxW9n5xbVKvGBV1tt5Nzbwb9jpNz20b7xTQ5V9esR0ldaWsJzM0dS+ubGkzneNl7IMDZH+N841pXgPGDh727aN4D0WDCAE9EonFf0jAYjUDawSuQQIJf3zeSIZ5EZTBMzs0sOYUdebtQqa2Em9wNs8NSkOgbD6BlVL1KV91ao966rnptMcoaymEwGgAAdlIZ/BV+iPOOMe1W6q/whYOtfQ/+JomoNxjgiUhUZk0YBqPRiO0/5EMqAR6dyRBP1qk3k3NN5Ts9mJxrWlqz0021Wr7+6cYVbP1ph+kDww1tJf4vdyuOl2Sh2diMotpiszIhd7kbAp39MMZ7tGlU3cvBk6PqRAJjgCci0bl/YigMRiD9x3xIJBIsmxkJKSe30SA10JNzb9VsbMb56xcR7ByI0V6jTEE9QOEHR5ljX71NIupDggZ4nU6H9evXIz09HdXV1YiMjMTKlSuRlJTU7XU5OTlIS0tDTk4OLl26BL1ej4sXL/7s87755husXLkSzs7OOHHiRF+9DSLqB3MmhcJoNGLHoauQSoGlKQzxRL2dnLs597Muz1+d8Ie+bi4R9RNBfwf23HPPYdOmTZg9ezbWrFkDqVSK5cuXIysrq9vrDhw4gK1btwIAgoKCLHpWY2MjXnvtNTg6cjSByFrMmRSKWRNCcDC7GFt2X4TB+POjiUTUom1yboDCDyM9R2C831i4y906Pber40QkToIF+JycHHz99dd49tln8ec//xkLFy7Epk2b4Ofnh9TU1G6vXbRoEU6ePIm0tDRMmjTJoudt3LgRdnZ2SE5O7ovmE9EAkEgkePCu4bgvKQQHTqvxfxmXYGSIJ7pts8NSIJOar1kvk8owOyxFoBYR0e0QLMDv2rULMpkMCxYsMB2Ty+WYP38+Tp48ibKysi6v9fLygr295bPd1Wo13nvvPaxevRoyGTfbILImEokEc+8ejl+MD8b3WUX4vz0M8US3K9E3Hosj57VsmoSWkffFkfNMq9AQkXUQrAY+NzcXoaGhcHJyMjseExMDo9GI3NxceHt798mzXn31VcTFxSE5ORkZGRl9ck8iGjgSiQTzJ4fBaAR2ZRZAKpFg8dQ7uGsj0W1I9I1Hom88lEpnaDQ1QjeHiG6DYAFeo9HAx6fjBBylUgkA3Y7A90RmZib27NmDtLS0PrkfEQlDIpFgwb1hMBiNyDheCIkEWDSFIZ6IiIYewQJ8Y2Njp+UscrkcAKDVanv9jObmZvz973/H3LlzERkZ2ev7AYCnp6JP7nM7lEpnwZ5NJBZPLYyDvb0MO364AidHOX49O6pDiGdfIbIM+wqRZcTWVwQL8Pb29tDrO+481xbc24J8b3z22WdQqVT44IMPen2vNhUVtTAYBr7+lr/qJLppzoQQ1NXrkH4wD9pGPRbcG2YK8ewrRJZhXyGyjBB9RSqVdDtoLFiAVyqVnZbJaDQaAOh1/btOp8Mbb7yBuXPnorGxESqVCgBQX18Pg8EAlUoFR0dHeHh0v0MeEYmPpLUG3mA0YldmASQSYP7kMJbTEBHRkCBYgI+MjMSWLVtQV1dnNpE1Ozvb9HpvNDY24saNG9iyZQu2bNnS4fUpU6Zg5syZWLt2ba+eQ0TCkEgkeGTaCBiNwLfHCqAur4NKU4vr1Vp4uMgx954wJEX5Ct1MIiKiPidYgE9JScEHH3yArVu3YtmyZQBaRs3T0tIQHx9vmuCqVqvR0NCAsLCwHt3fwcEBb731VofjmzdvRk5ODlJTUzudREtE1kMikeCR6SNQUlGH7LwK0/GKai02fXsBABjiiYho0BEswMfGxiIlJQWpqanQaDQIDg7G9u3boVar8fLLL5vOW716NTIzM3Hx4kXTsaKiIqSnpwMAzpw5AwDYsGEDgJaR++TkZMhkMkydOrXDc/fu3Yvz5893+hoRWR+pRIKyyoYOx3VNBqQdyGOAJyKiQUewAA8A//jHP7Bu3Tqkp6ejqqoKERERePfddzF27Nhur1OpVFi/fr3ZsbavH3zwQe62SjTEXK/ufNWqimotDAYjpFLWxhMR0eAhMXJLwx7hKjRE4vOnDYdQ0UWI93ZzwLSEIEwc7Qt7O0HHLIhEhT9XiCwjxlVopAPYFiKifjH3njDY2Zp/O7OzlWLq2EA4O8rw0Z5LePatw9j2fR5u1PR+jwkiIiIhcTiKiKxeW5172oG8TlehuVxUhd2ZBfj22DXszixA4kgfzEgMQrCPuDbmICIisgRLaHqIJTRE4tZdXymrbMDeE4X4IbsYWn0zIoPdMCMxGKPDPCHlGvI0xPDnCpFlxFhCwwDfQwzwROJmSV+pb9TjQLYae0+ocKNGCz9PR0xLCMKEKF/YyWwGqKVEwuLPFSLLMMAPAgzwROLWk77S1GzAiQtl2J1ZiGulNVA4yJAcH4B74wPh6mTXzy0lEhZ/rhBZRowBnjXwRDRk2dpIcWeUL8aP8sGlwkrszizEjkNX8c3Ra7gzyhczEoIQoOz6GygREZEQGOCJaMiTSCSICHZHRLA7Sq7XI+N4IQ6fKcaPOcWIHu6BGQnBGDXMHRLWyRMRkQiwhKaHWEJDJG591Vdq6nX4/rQa351UobpOh0ClE6YnBGP8KB/IbLkCL1k//lwhsowYS2gY4HuIAZ5I3Pq6r+ibDDh2vhQZxwug0tTB1cnkWMt0AAAgAElEQVQOyWMDcW9cABQOsj57DtFA488VIsuIMcCzhIaIqBsyWykmxfhh4mhfnL96A7szC7D94BV8ffgqJo72w7SEIPh6OArdTCIiGkIY4ImILCCRSBAV6oGoUA+oNLXIOF6IH3LU+D6rCLHhXpiRGIQRQW6skycion7HEpoeYgkNkbgNZF+pqtNh30kV9mcVobZBjxBfZ8xICMK4SG/Y2rBOnsSNP1eILCPGEhoG+B5igCcSNyH6ik7fjMPnSpCRWYiS6/Vwd5Zj6rhA3BPrD0d71smTOPHnCpFlxBjgWUJDRNRLdjIbTB4TgLtj/XEmrwK7MwuwdX8edhy6irti/DBtXBCUbg5CN5OIiAYJBngioj4ilUgQG+6F2HAvXCupQcbxAuw/VYTvTqowdoQS0xODER7gKnQziYjIyjHAExH1gxBfZyy/PwrzJ4dj78lCHMhS48RFDcL8XTAjMRjxI5SQSjnhlYiIeo418D3EGngicRNrX2nUNeHHnGLsOVEITWUjvFztMW1cECbF+MFBzrEUGnhi7StEYiPGGngG+B5igCcSN7H3FYPBiKyfyrH7eAEuq6rgILfFPWP8MXVsIDxc7IVuHg0hYu8rRGIhxgDPYR8iogEklUowNkKJsRFK5KmrkJFZiN2ZBdhzvBAJkd6YnhiEYb4uQjeTiIhEjAGeiEggYf6ueOIBV5RXNmDvSRUOZqtx9HwpIoLcMD0xCLHhXpByYygiIroFS2h6iCU0ROJmzX2lvrEJB7PV2HuyENertfBxd8D0hCBMGO0HucxG6ObRIGPNfYVoIImxhIYBvocY4InEbTD0lWaDAScuaLA7swBXS2rgZG+Le+MDkBwfCDeFXOjm0SAxGPoK0UAQY4BnCQ0RkcjYSKUYP8oHiSO98ZOqCrszC/D14WvYdawA40f5YHpCMIK8u/7GTkREg5ugAV6n02H9+vVIT09HdXU1IiMjsXLlSiQlJXV7XU5ODtLS0pCTk4NLly5Br9fj4sWLHc7Ly8vDF198gUOHDqGgoABOTk6IiorCH/7wB0RFRfXX2yIi6hMSiQQjgtwwIsgNpTfqsed4IX48U4xDZ0oQNcwd0xODER3qAQnr5ImIhhSpkA9/7rnnsGnTJsyePRtr1qyBVCrF8uXLkZWV1e11Bw4cwNatWwEAQUFBXZ63bds2bN26FdHR0XjuueewbNkyXLlyBb/85S9x9OjRPn0vRET9ycfdEY9Mj0DqiomYd89wqMrrsPbzbLzwfiYOZquhb2oWuolERDRABKuBz8nJwYIFC/D8889j2bJlAACtVotZs2bB29sbH330UZfXlpeXQ6FQwN7eHi+99BI2b97c6Qj82bNnERoaCicnJ9OxGzduYObMmQgPD8eWLVt63G7WwBOJ21DpK03NBhw7X4qM44UoLKuFi6MMyfGBmBwfABdHO6GbR1ZgqPQVot5iDXw7u3btgkwmw4IFC0zH5HI55s+fj7Vr16KsrAze3t6dXuvl5WXRM6Kjozscc3d3x7hx43Dy5MnbazgRkQjY2kgxcbQfJkT74sK1G9h9vBBf/piPr49ew4RoX0xPCIKfp9PP34iIiKyOYAE+Nze3w+g4AMTExMBoNCI3N7fLAN9bGo0G7u7u/XJvIqKBJJFIMHKYB0YO84C6vA4Zxwtx6EwJDpxWIybMEzMSghAZ4s46eSKiQUSwAK/RaODj49PhuFKpBACUlZX1y3NPnDiB06dP46mnnuqX+xMRCcXfywnLfhGJuXcPx/6sIuw7pcJrn55GsLcC0xODkDjSB7Y2gk59IiKiPiBYgG9sbIRMJutwXC5vWeNYq9X2+TMrKirwxz/+EcHBwXjsscdu6x7d1SP1N6XSWbBnE1mTod5XlEogbJgnls6Kwv6TKqQfvIz3duYi7WA+Zk0KxS+ShkHBOnkC+wqRpcTWVwQL8Pb29tDr9R2OtwX3tiDfV+rr6/H444+joaEB77//PhwdHW/rPpzESiRu7Cvm4sM8MGZ4As5euY6M4wXY/E0uPt1zEXeN9se0hEB4u9/e90KyfuwrRJbhJNZ2lEplp2UyGo0GAPq0/l2n0+H3v/89Ll26hA8++ADh4eF9dm8iIrGTSiSICfNETJgnCstqkZFZgO9Pt5TYxI1QYnpCEO4IdGWdPBGRlRAswEdGRmLLli2oq6szm8ianZ1ter0vGAwGrF69GkeOHMEbb7yBcePG9cl9iYisUZC3Ar+eNQrzJofhu5MqfJ9VhFOXNAj1c8GMxCCMjVDCRso6eSIiMRPsu3RKSgr0er1pQyagZaQ8LS0N8fHxpgmuarUaeXl5t/2cF198Ed988w3+67/+C1OnTu11u4mIBgM3hRzz7glD6oqJeGT6CNQ16vF2+jk89/YR7M4sQIO2SegmEhFRFwQbgY+NjUVKSgpSU1Oh0WgQHByM7du3Q61W4+WXXzadt3r1amRmZppt1FRUVIT09HQAwJkzZwAAGzZsANAycp+cnAwA+PDDD/Hxxx8jLi4O9vb2pmvazJkzp1/fIxGR2MntbFo2gBoTgOzL5dh9vBCf7buM9B/zcXesP6aNC4Knq73QzSQionYEC/AA8I9//APr1q1Deno6qqqqEBERgXfffRdjx47t9jqVSoX169ebHWv7+sEHHzQF+AsXLgAAsrKykJWV1eE+DPBERC2kUgniRigRN0KJ/OJqZBwvxN4TKuw9ocK4SCVmJAYj1M9F6GYSEREAidFoHPglVawYV6EhEjf2lb5zvboRe0+ocCC7CA3aZtwR6IoZicEYE+4FqZQTXq0d+wqRZcS4Cg0DfA8xwBOJG/tK32vQNuGHnGLsOV6IiupGeLs7YNq4IEwa7Qe5nY3QzaPbxL5CZBkG+EGAAZ5I3NhX+k+zwYBTl8qxO7MAV9TVcLK3xT1jAjBlbCDcnft27w7qf+wrRJYRY4AXtAaeiIish41UioRIbyREeuOyqgq7jxfg22PXsDuzAIkjfTAjMQjBPuLarZCIaDBigCcioh4LD3RFeOBolFU2YO/xQvyQU4wj50owMsQdMxKDED3cE1JuDEVE1C9YQtNDLKEhEjf2FWHUN+px4LQae0+qcKNGCz9PR0xPCEJSlC/sZKyTFyP2FSLLiLGEhgG+hxjgicSNfUVYTc0GHL9Qht2ZBSgorYWzowz3xgUgOT4QLk52QjeP2mFfIbKMGAM8S2iIiKjP2NpIkRTliztH+eBiQSUyjhdix6Gr+OZoAZKifDA9MRgBXk5CN5OIyKoxwBMRUZ+TSCSIDHFHZIg7iivqsOeECofOFOOHnGJED/fAjMRgjApxh4R18kREPcYSmh5iCQ2RuLGviFdNvQ7fZxXhu1NFqK7TIVCpwIzEICSO9IHMVip084Yc9hUiy4ixhIYBvocY4InEjX1F/PRNBhw9X4KM44Uo0tTB1ckOyWMDcW9cABQOMqGbN2SwrxBZRowBniU0REQ0oGS2UtwV449Jo/1w7up1ZGQWYvvBK/j68FVMjPHD9HFB8PFwFLqZRESixQBPRESCkEgkiA71RHSoJ1SaWmQcL8QP2Wp8f6oIseFemJEYhBFBbqyTJyK6BQM8EREJLlCpwGMzR2Le3cOx71QR9mcV4fTH5QjxdcaMxCCMi/CGrQ3r5ImIANbA9xhr4InEjX1lcNDqm3HkbEudfMn1eni4yDF1bBDujvWDoz3r5PsC+wqRZVgDT0REZAG5zAaT4wJw9xh/5ORVICOzAJ/vv4z0Q/m4K8YP08YFQenmIHQziYgEwQBPRESiJZVIMCbcC2PCvXCtpAYZxwuw/1QRvjupwtgIb8xICEJYgKvQzSQiGlAM8EREZBVCfJ2x/P4ozLsnDN+dUuFAlhonLpQhLMAFMxKCET9CCamUE16JaPBjDXwPsQaeSNzYV4aORl0Tfswpxp4ThdBUNsLL1R7TEoIwabQfHOQcn/o57CtElhFjDTwDfA8xwBOJG/vK0GMwGJH1kwa7jxfisqoKDnJbTB7jjyljA+HhYi9080SLfYXIMmIM8ByiICIiqyaVSjA2whtjI7yRp65CRmYhdmUWION4IRIivTEjMRghvs5CN5OIqM8wwBMR0aAR5u+KJx5wRXllA/aeVOFgthpHz5ciMtgN0xOCERPuCSk3hiIiK8cSmh5iCQ2RuLGvUHv1jU04mK3G3pOFuF6thY+HI6YnBGFCtC/kMhuhmyco9hUiy4ixhEbQAK/T6bB+/Xqkp6ejuroakZGRWLlyJZKSkrq9LicnB2lpacjJycGlS5eg1+tx8eLFTs81GAx4//338cknn0Cj0WDYsGF44oknMHPmzNtqMwM8kbixr1BnmpoNOHlRg92ZBbhaUgOFgwyT4wIwJT4Argq50M0TBPsKkWXEGOAF3Zf6ueeew6ZNmzB79mysWbMGUqkUy5cvR1ZWVrfXHThwAFu3bgUABAUFdXvu2rVrkZqaikmTJuGFF16Av78/Vq5ciV27dvXZ+yAiInGztZFi/CgfvPCrcXju4XjcEeiKrw9fxZ/+fRgffJ0LVVmt0E0kIrKYYCPwOTk5WLBgAZ5//nksW7YMAKDVajFr1ix4e3vjo48+6vLa8vJyKBQK2Nvb46WXXsLmzZs7HYEvLS3FlClTsGjRIqxZswYAYDQa8cgjj6C4uBh79+6FVNqzzzAcgScSN/YVslTp9XrsOVGIH88UQ6c3IGqYO2YkBiMq1AOSIVAnz75CZBmOwLeza9cuyGQyLFiwwHRMLpdj/vz5OHnyJMrKyrq81svLC/b2P7802N69e6HX67F48WLTMYlEgkWLFqGoqAg5OTm9exNERGS1fDwc8cj0CKSumIh59wyHqrwOr3+ejb+9n4kfstXQNzUL3UQiok4JFuBzc3MRGhoKJycns+MxMTEwGo3Izc3tk2coFAqEhoZ2eAYAnD9/vtfPICIi66ZwkOG+pGF47YkJ+PV9IyGRSPCfby/gTxsOY8ehfNTU64RuIhGRGcGWkdRoNPDx8elwXKlUAkC3I/A9eYaXl1e/PoOIiAYHWxspJo72w4RoX+Reu4HdmYX48od8fH3kGiZG+2JaQhD8PJ1+/kZERP1MsADf2NgImUzW4bhc3rIagFar7ZNn2NnZ9ekzuqtH6m9KJTciIbIE+wr1lre3C+5JCEFBSTXSD17B/pOF+P60GgmjfPDAPWEYHeY1KOrk2VeILCO2viJYgLe3t4der+9wvC1Ut4Xs3j5Dp+v4q8/ePIOTWInEjX2F+pKDjQQP3RuGmYlB2J9VhH2nVFhzvhTBPgrMSAhGwkhv2NoIuqDbbWNfIbIMJ7G2o1QqOy1h0Wg0AABvb+8+eUZ5eXm/PoOIiAY/Fyc7zJkUiteemIBlv4iEvsmAjTvPY/XbR/DN0Wuoa+w4IEVE1F8EC/CRkZHIz89HXV2d2fHs7GzT6701cuRI1NbWIj8/v9NnjBw5stfPICKiocNOZoO7Y/3x4m/G45kFsfD1cMS27/Pw7FuH8dGeSyi7US90E4loCBAswKekpECv15s2ZAJadmZNS0tDfHy8aYKrWq1GXl7ebT1jypQpkMlk+Pjjj03HjEYjPv30U/j7+yM2NrZ3b4KIiIYkqUSCmDBP/GlRHP7fowkYG6HE91lFeP6do3gr7Qx+UlVCwI3OiWiQE6wGPjY2FikpKUhNTYVGo0FwcDC2b98OtVqNl19+2XTe6tWrkZmZabZRU1FREdLT0wEAZ86cAQBs2LABQMvIfXJyMgDA19cXS5cuxQcffACtVovRo0dj7969OHHiBNauXdvjTZyIiIhuFezjjN/MGoV594Rh3ykVvs8qwslLGgz3d8H0hCCMjVDChj9viKgPCbYTK9AymXTdunX46quvUFVVhYiICKxatQoTJkwwnbNkyZIOAf7YsWNYunRpp/d88MEH8corr5i+NhgM2LhxIz777DOUlZUhNDQUjz/+OGbNmnVbbeYkViJxY18hoWl1zTh0thgZxwtRdqMBni72mDYuEHfF+sNBLti4WQfsK0SWEeMkVkEDvDVigCcSN/YVEguDwYjsy+XYnVmAS6oqOMhb6uenjg2Cp+vP7ybe39hXiCwjxgAvnqEAIiKiQUQqlSBuhBJxI5TIL67G7swC7Dmuwp7jKoyLVGJGYjBC/VyEbiYRWSEGeCIion4W6ueC382JRsXkRuw9WYiD2Wpk5pZhRKArpicGY0y4F6RS698YiogGBktoeoglNETixr5C1qBB24QfstXYc0KFiupGeLs7YNq4IEwa7Qe5nc2AtIF9hcgyYiyhYYDvIQZ4InFjXyFr0mww4NSlljr5K+pqONnbYnJcAJLjA+Hu3PsdybvDvkJkGTEGeJbQEBERCcRGKkVCpDfGRSiRV9RSJ//NkWvYdawA40f5YHpCEIJ9nIVuJhGJDAM8ERGRwCQSCcIDXREeOBplN+qx54QKP+YU4/DZEowMcceMxCBED/eEVMI6eSJiCU2PsYSGSNzYV2iwqGvU48BpNfaeKERlrQ5+no6YnhCEpChf2Ml6XyfPvkJkGTGW0DDA9xADPJG4sa/QYNPUbMDx3DLszixAQVktnB1luLe1Tt7Fye6278u+QmQZMQZ4ltAQERGJmK2NFEnRvrgzygcXCyqxO7MAOw5dxTdHCzAh2gfTEoIR4OUkdDOJaAAxwBMREVkBiUSCyBB3RIa4o7iiDnuOF+LQ2RIczC7G6OGemJEYhJEh7pCwTp5o0GMJTQ+xhIZI3NhXaCipqddhf1YR9p1Uobpej0ClAjMSgzB+lA9sbaTdXsu+QmQZMZbQMMD3EAM8kbixr9BQpG9qxtFzpcg4Xoii8jq4KuwwJT4Qk+MCoHCQdXoN+wqRZcQY4FlCQ0REZOVktja4K9Yfk2L8cC7/OnYfL0TawSvYeeQqJo72w/RxQfDxcBS6mUTURzgC30McgScSN/YVohaqslpkHC/E0fMlaG42YswdXpiRGIzyqgZsP3gF16u18HCRY+49YUiK8hW6uUSic+RcCdIO5AnSV1hC08cY4InEjX2FyFxVrRbfnSrC91lFqG3QQwKg/U8xmY0UcyYNQ+wdSkgASCQtE2YlACBB678lN1+DBG3zZNsmzHZ2jdlrZte0fN3+vO5eIxLCkXMl2PTtBeiaDKZjdrZS/OoXkQMS4hng+xgDPJG4sa8QdU6rb8azbx1CXWOT0E3pkZsfCsyDPiCBVHLztZuhv91ruPWDRMsfJJ1+yGi5ruXDiPk9zT7A3PrhBrfc75Z2dPpaJ/fs0MbWZ7Ttvntre4HW1zppY4fX2rWj/d/lrW289YMaurimu9daXzX7kGf6WtLVa12///Yf8rp8rYv/R7p+rX07Ov+7+eCbXNTU63ErTxc5XlsxscPxvsYaeCIiIoJcZtNteP/dnCgYjEbA2DpCbwSMMKJtmM9oBIxGo2n03vTn1vONxvbndvMajB2OG1sf0Nk1xrar2rej7R6dtfHW19rds+0Z5s/tpE23tKPD++/kNQAtf3+3tqP1gMHUxvbnAEaDEQbTue3b0fIgg7GzNpr+Jk3tan/PW98nurim87+bTu6Hm39fRmMn7eji/5HBqKJaK3QTADDAExERDRmeLvJOA4inixyJI30EaBENZuYfElo/BLQL/V2+BrT7UNDxQ1771wCYffC89cOgoYsPN7e+1vbktj+v35aD6jpdh/fk6SLvk7+b3mKAJyIiGiLm3hPWaV3v3HvCBGwVDVbtS1jainmsxcLkcFH3FQZ4IiKiIaJt8p1QK2sQWQux9xVOYu0hTmIlEjf2FSLLsK8QWUaMGzl1v88yERERERGJCgM8EREREZEVETTA63Q6vPbaa5g0aRJiYmLwy1/+EkeOHLHo2tLSUjz99NMYN24c4uPjsWLFChQWFnY4r6amBq+++iqmT5+OmJgYJCcn429/+xtKS0v7+u0QEREREfU7QWvgV61ahYyMDCxduhQhISHYvn07zp49iy1btiAuLq7L6+rq6jB37lzU1dVh2bJlsLW1xYcffgiJRIIvv/wSrq6uAACDwYCHHnoIP/30ExYtWoTQ0FDk5+fjk08+gVKpxM6dO2FnZ9ejNrMGnkjc2FeILMO+QmQZMdbAC7YKTU5ODr7++ms8//zzWLZsGQDggQcewKxZs5CamoqPPvqoy2s//vhjXLt2DWlpaRg1ahQA4K677sL999+PDz/8EE8//TQA4MyZM8jOzsbf/vY3PPzww6br/f398eKLL+LUqVO48847++9NEhERERH1McFKaHbt2gWZTIYFCxaYjsnlcsyfPx8nT55EWVlZl9fu3r0bY8aMMYV3AAgLC0NSUhK+/fZb07Ha2loAgKenp9n1Xl5eAAB7e/s+eS9ERERERANFsACfm5uL0NBQODk5mR2PiYmB0WhEbm5up9cZDAZcvHgR0dHRHV4bPXo0rl69ioaGBgBAVFQUHB0dsX79ehw5cgSlpaU4cuQI1q9fj/HjxyM2Nrbv3xgRERERUT8SrIRGo9HAx6fjts1KpRIAuhyBr6yshE6nM51367VGoxEajQbBwcFwc3PD2rVr8de//tVUpgMA9957L9atWweJpOe7gnVXj9TflEpnwZ5NZE3YV4gsw75CZBmx9RXBAnxjYyNkMlmH43K5HACg1Wo7va7teGeTT9uubWxsNB3z8PBAdHQ04uLiEBYWhgsXLuC9997DX/7yF7z++us9bjcnsRKJG/sKkWXYV4gsw0ms7djb20Ov13c43hbQ28L4rdqO63S6Lq9tq20vLCzE0qVLkZqaiqlTpwIApk6dioCAADz33HOYN28eJk6c2KN2S6U9H7XvK0I+m8iasK8QWYZ9hcgyA91Xfu55ggV4pVLZaZmMRqMBAHh7e3d6nZubG+zs7Ezn3XqtRCIxldekpaVBp9PhnnvuMTsvOTkZAHDq1KkeB3h3d6efP6mfCFm+Q2RN2FeILMO+QmQZsfUVwSaxRkZGIj8/H3V1dWbHs7OzTa93RiqVYsSIETh79myH13JychASEgIHBwcAQEVFBYxGI25d6r6pqcns30RERERE1kKwAJ+SkgK9Xo+tW7eajul0OqSlpSE+Pt40wVWtViMvL8/s2hkzZuD06dM4f/686diVK1dw9OhRpKSkmI4NGzYMBoPBbGlJANi5cycAmC1DSURERERkDQTdifXpp5/Gd999h1/96lcIDg427cS6adMmjB07FgCwZMkSZGZm4uLFi6bramtr8eCDD6KhoQGPPvoobGxs8OGHH8JoNOLLL7+Eu7s7AODGjRu4//77UVlZiUWLFiE8PBznzp3Dtm3bEB4eji+++KLTibRERERERGIlaIDXarVYt24dvvrqK1RVVSEiIgKrVq3ChAkTTOd0FuABoKSkBP/7v/+LQ4cOwWAwYPz48VizZg2CgoLMzistLcX69etx7NgxlJaWws3NDcnJyVi5cqUp6BMRERERWQtBAzwREREREfWMYDXwRERERETUcwzwRERERERWhAGeiIiIiMiKMMATEREREVkRBngiIiIiIitiK3QDqHNlZWXYvHkzsrOzcfbsWdTX12Pz5s0YP3680E0jEpWcnBxs374dx44dg1qthpubG+Li4vDMM88gJCRE6OYRicaZM2fw9ttv4/z586ioqICzszMiIyPx5JNPIj4+XujmEYnWxo0bkZqaisjISKSnpwvdHAAM8KKVn5+PjRs3IiQkBBEREcjKyhK6SUSi9N577+HUqVNISUlBREQENBoNPvroIzzwwAPYtm0bwsLChG4ikSgUFhaiubkZCxYsgFKpRE1NDb766is88sgj2LhxIyZOnCh0E4lER6PR4N///jccHR2FbooZrgMvUrW1tdDr9XB3d8fevXvx5JNPcgSeqBOnTp1CdHQ07OzsTMeuXr2K+++/H/fddx9eeeUVAVtHJG4NDQ2YOnUqoqOj8c477wjdHCLRee6556BWq2E0GlFdXS2aEXjWwIuUQqHgTrFEFoiPjzcL7wAwbNgw3HHHHcjLyxOoVUTWwcHBAR4eHqiurha6KUSik5OTgx07duD5558XuikdMMAT0aBjNBpRXl7OD8FEnaitrcX169dx5coVvP7667h06RKSkpKEbhaRqBiNRrz44ot44IEHMHLkSKGb0wFr4Ilo0NmxYwdKS0uxcuVKoZtCJDp/+ctfsHv3bgCATCbDQw89hN/97ncCt4pIXL788ktcvnwZb731ltBN6RQDPBENKnl5efif//kfjB07FnPmzBG6OUSi8+STT2LhwoUoKSlBeno6dDod9Hp9h1I0oqGqtrYW//znP/Hb3/4W3t7eQjenUyyhIaJBQ6PR4PHHH4erqyvWr18PqZTf4ohuFRERgYkTJ2LevHl4//33ce7cOVHW+BIJ5d///jdkMhkeffRRoZvSJf50I6JBoaamBsuXL0dNTQ3ee+89KJVKoZtEJHoymQxTpkxBRkYGGhsbhW4OkeDKysqwadMmLF68GOXl5VCpVFCpVNBqtdDr9VCpVKiqqhK6mSyhISLrp9Vq8bvf/Q5Xr17Fhx9+iOHDhwvdJCKr0djYCKPRiLq6Otjb2wvdHCJBVVRUQK/XIzU1FampqR1enzJlCpYvX45nn31WgNbdxABPRFatubkZzzzzDE6fPo0NGzZgzJgxQjeJSJSuX78ODw8Ps2O1tbXYvXs3/Pz84OnpKVDLiMQjMDCw04mr69atQ319Pf7yl79g2LBhA9+wWzDAi9iGDRsAwLSWdXp6Ok6ePAkXFxc88sgjQjaNSDReeeUV7Nu3D/feey8qKyvNNtlwcnLC1KlTBWwdkXg888wzkMvliIuLg1KpRHFxMdLS0lBSUoLXX39d6OYRiYKzs3OnPzc2bdoEGxsb0fxM4U6sIhYREdHp8YCAAOzbt2+AW0MkTkuWLEFmZmanr7GvEN20bds2pKen4/Lly6iuroazszPGjBmDxx57DImJiUI3j+reanQAAAUaSURBVEjUlixZIqqdWBngiYiIiIisCFehISIiIiKyIgzwRERERERWhAGeiIiIiMiKMMATEREREVkRBngiIiIiIivCAE9EREREZEUY4ImIiIiIrAgDPBERid6SJUuQnJwsdDOIiETBVugGEBGRMI4dO4alS5d2+bqNjQ3Onz8/gC0iIiJLMMATEQ1xs2bNwt13393huFTKX9ISEYkRAzwR0RA3atQozJkzR+hmEBGRhTi8QkRE3VKpVIiIiMCbb76JnTt34v7778fo0aMxefJkvPnmm2hqaupwzYULF/Dkk09i/PjxGD16NGbOnImNGzeiubm5w7kajQZ///vfMWXKFERHRyMpKQmPPvooDh061OHc0tJSrFq1CgkJCYiNjcWvf/1r5Ofn98v7JiISK47AExENcQ0NDbh+/XqH43Z2dlAoFKav9+3bh8LCQjz88MPw8vLCvn378K9//QtqtRovv/yy6bwzZ85gyZIlsLW1NZ27f/9+pKam4sKFC/jnP/9pOlelUmHRokWoqKjAnDlzEB0djYaGBmRnZ+Pw4cOYOHGi6dz6+no88sgjiI2NxcqVK6FSqbB582asWLECO3fuhI2NTT/9DRERiQsDPBHREPfmm2/izTff7HB88uTJeOedd0xfX7hwAdu2bUNUVBQA4JFHHsFTTz2FtLQ0LFy4EGPGjAEAvPTSS9DpdPj0008RGRlpOveZZ57Bzp07MX/+fCQlJQEA/vu//xtlZWV47733cNddd5k932AwmH1948YN/PrXv8by5ctNxzw8PPDaa6/h8OHDHa4nIhqsGOCJiIa4hQsXIiUlpcNxDw8Ps68nTJhgCu8AIJFI8Jvf/AZ79+7Fnj17MGbMGFRUVCArKwvTpk0zhfe2c5944gns2rULe/bsQVJSEiorK/HDDz/grrvu6jR83zqJViqVdlg158477wQAXLt2jQGeiIYMBngioiEuJCQEEyZM+NnzwsLCOhwLDw8HABQWFgJoKYlpf7y94cOHQyqVms4tKCiA0WjEqFGjLGqnt7c35HK52TE3NzcAQGVlpUX3ICIaDDiJlYiIrEJ3Ne5Go3EAW0JEJCwGeCIiskheXl6HY5cvXwYABAUFAQACAwPNjrd35coVGAwG07nBwcGQSCTIzc3tryYTEQ1KDPBERGSRw4cP49y5c6avjUYj3nvvPQDA1KlTAQCenp6Ii4vD/v37cenSJbNz3333XQDAtGnTALSUv9x99904ePAgDh8+3OF5HFUnIuoca+CJiIa48+fPIz09vdPX2oI5AERGRuJXv/oVHn74YSiVSnz33Xc4fPgw5syZg7i4ONN5a9aswZIlS/Dwww9j8eLFUCqV2L9/P3788UfMmjXLtAINALzwwgs4f/48li9fjgceeABRUVHQarXIzs5GQEAA/vSnP/XfGycislIM8EREQ9zOnTuxc+fOTl/LyMgw1Z4nJycjNDQU77zzDvLz8+Hp6YkVK1ZgxYoVZteMHj0an376Kd544w188sknqK+vR1BQEJ599lk89thjZucGBQXhiy++wFtvvYWDBw8iPT0dLi4uiIyMxMKFC/vnDRMRWTmJkb+jJCKibqhUKkyZMgVPPfUUfv/73wvdHCKiIY818EREREREVoQBnoiIiIjIijDAExERERFZEdbAExERERFZEY7AExERERFZEQZ4IiIiIiIrwgBPRERERGRFGOCJiIiIiKwIAzwRERERkRVhgCciIiIisiL/H2OHTphkWupdAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 864x432 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zWeYo84kDYZM","executionInfo":{"status":"ok","timestamp":1621102025697,"user_tz":-330,"elapsed":1832,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"b33e03b7-f99d-4046-e516-0f3e48625447"},"source":["total_test_loss = []\n","total_test_accuracy = []\n","\n","\n","\n","for batch in validation_dataloader:\n","\n","        \n","  # Unpack this training batch from our dataloader. \n","  #\n","  # As we unpack the batch, we'll also copy each tensor to the GPU using \n","  # the `to` method.\n","  #\n","  # `batch` contains three pytorch tensors:\n","  #   [0]: input ids \n","  #   [1]: attention masks\n","  #   [2]: labels \n","  b_input_ids = batch[0].to(device)\n","  b_input_mask = batch[1].to(device)\n","  b_labels = batch[2].to(device)\n","        \n","  # Tell pytorch not to bother with constructing the compute graph during\n","  # the forward pass, since this is only needed for backprop (training).\n","  #with torch.no_grad():        \n","\n","  # Forward pass, calculate logit predictions.\n","  # token_type_ids is the same as the \"segment ids\", which \n","  # differentiates sentence 1 and 2 in 2-sentence tasks.\n","  result = model(b_input_ids, \n","                       token_type_ids=None, \n","                       attention_mask=b_input_mask, \n","                       labels=b_labels,\n","                       return_dict=True)\n","        # Get the loss and \"logits\" output by the model. The \"logits\" are the \n","        # output values prior to applying an activation function like the \n","        # softmax.\n","  loss = result.loss\n","  logits = result.logits\n","        \n","            \n","        # Accumulate the validation loss.\n","  total_test_loss = loss.item()\n","\n","        # Move logits and labels to CPU\n","  logits = logits.detach().cpu().numpy()\n","  label_ids = b_labels.to('cpu').numpy()\n","\n","        # Calculate the accuracy for this batch of test sentences, and\n","        # accumulate it over all batches.\n","  total_test_accuracy = flat_accuracy(logits, label_ids)\n","        \n","\n","    # Report the final accuracy for this validation run.\n","print(\"The total test accuracy is: \")\n","print(total_test_accuracy)\n","print(\"Testing complete!\")"],"execution_count":36,"outputs":[{"output_type":"stream","text":["The total test accuracy is: \n","0.9375\n","Testing complete!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"r8437NqbK1jW"},"source":["## Now we train again on the 10% of the dataset"]},{"cell_type":"code","metadata":{"id":"B0QDoTejKsh8"},"source":["df1_split_10_percent_test = combinedDF.iloc[:874, :]\n","df1_split_10_percent_train = combinedDF.iloc[875:, :]\n","\n","df1_split_10_percent_test.head(10)\n","df1_split_10_percent_test.info()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4t39sosALJzY","executionInfo":{"status":"ok","timestamp":1621102033027,"user_tz":-330,"elapsed":1026,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"4a7a245d-6b9e-4a60-fb1b-0d18cc8d1260"},"source":["sentences2 = df1_split_10_percent_train.Sentence.values\n","labels2 = df1_split_10_percent_train.Label.values\n","\n","\n","print(len(sentences2))"],"execution_count":38,"outputs":[{"output_type":"stream","text":["1873\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nEjOUeatLNef","executionInfo":{"status":"ok","timestamp":1621102036357,"user_tz":-330,"elapsed":2006,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"4b96d5a5-e193-4ebf-c438-27ede61d0d76"},"source":["max_len3 = 0\n","\n","# For every sentence...\n","for sent in sentences2:\n","\n","    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n","    input_ids2 = tokenizer.encode(sent, add_special_tokens=True)\n","\n","    # Update the maximum sentence length.\n","    max_len3 = max(max_len3, len(input_ids2))\n","\n","print('Max sentence length: ', max_len3)"],"execution_count":39,"outputs":[{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (1103 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["Max sentence length:  1103\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EE-ob1BfLTbc","executionInfo":{"status":"ok","timestamp":1621102040740,"user_tz":-330,"elapsed":1683,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"8700fe9c-5458-41c6-fe8b-c8bcf8c45189"},"source":["input_ids2 = []\n","attention_masks2 = []\n","\n","# For every sentence...\n","for sent in sentences2:\n","    # `encode_plus` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    #   (5) Pad or truncate the sentence to `max_length`\n","    #   (6) Create attention masks for [PAD] tokens.\n","    encoded_dict2 = tokenizer.encode_plus(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = 64,           # Pad & truncate all sentences.\n","                        pad_to_max_length = True,\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","    \n","    # Add the encoded sentence to the list.    \n","    input_ids2.append(encoded_dict2['input_ids'])\n","    \n","    # And its attention mask (simply differentiates padding from non-padding).\n","    attention_masks2.append(encoded_dict2['attention_mask'])\n","\n","# Convert the lists into tensors.\n","input_ids2 = torch.cat(input_ids2, dim=0)\n","attention_masks2 = torch.cat(attention_masks2, dim=0)\n","labels2 = torch.tensor(labels2)\n","\n","# Print sentence 0, now as a list of IDs.\n","print('Original: ', sentences2[0])\n","print('Token IDs:', input_ids2[0])"],"execution_count":40,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Original:  I was able to do voice dialing in the car with no problem.\n","Token IDs: tensor([  101,  1045,  2001,  2583,  2000,  2079,  2376, 13764,  2075,  1999,\n","         1996,  2482,  2007,  2053,  3291,  1012,   102,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uTixsk10LWg9","executionInfo":{"status":"ok","timestamp":1621102044018,"user_tz":-330,"elapsed":1527,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"b9bb40a0-6c56-4ab2-c6e0-f0f9b986213c"},"source":["train2_dataset = TensorDataset(input_ids2, attention_masks2, labels2)\n","\n","print(type(input_ids2))\n","print(type(attention_masks2))\n","print(type(labels2))\n","\n","\n","\n","train2_dataloader = DataLoader(\n","            train2_dataset, # The validation samples.\n","            sampler = SequentialSampler(train2_dataset), # Pull out batches sequentially.\n","            batch_size = 16 # Evaluate with this batch size.\n","        )\n","\n","\n","print(len(train2_dataset))"],"execution_count":41,"outputs":[{"output_type":"stream","text":["<class 'torch.Tensor'>\n","<class 'torch.Tensor'>\n","<class 'torch.Tensor'>\n","1873\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Zl8_ePZeNs23","executionInfo":{"status":"ok","timestamp":1621103209684,"user_tz":-330,"elapsed":1203,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}}},"source":["optimizer2 = AdamW(model.parameters(),\n","                  lr = 2e-4,\n","                  eps = 1e-8 \n","                )"],"execution_count":80,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U9suBzLFLYfq","executionInfo":{"status":"ok","timestamp":1621103452879,"user_tz":-330,"elapsed":241444,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"86ea81d0-81ab-4dbf-d3db-546d9d362629"},"source":["import random\n","import numpy as np\n","\n","seed_val = 42\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","training_stats = []\n","total_t0 = time.time()\n","\n","# For each epoch...\n","for epoch_i in range(0, epochs):\n","    \n","    # ========================================\n","    #               Training\n","    # ========================================\n","    \n","    # Perform one full pass over the training set.\n","\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    # Measure how long the training epoch takes.\n","    t0 = time.time()\n","    total_train_loss = 0\n","    model.train()\n","\n","    # For each batch of training data...\n","    for step, batch in enumerate(train2_dataloader):\n","        # Progress update every 40 batches.\n","        if step % 40 == 0 and not step == 0:\n","            elapsed = format_time(time.time() - t0)\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","\n","        model.zero_grad()        \n","\n","        embed = model.embed(input_ids = b_input_ids)\n","        preds = model.predict(embedding_output = embed)#,extended_attention_mask=b_input_mask)   <- Didn't use mask at all, which should be a problem\n","        loss_fct = CrossEntropyLoss()\n","        regular_loss = loss_fct(preds.view(-1,2), b_labels.view(-1))\n","        loss_list = [regular_loss]\n","        if MODE in [\"SMART-adv-only\", \"SIFT\"]:\n","          normalise = True if MODE == \"SIFT\" else False\n","          noised_embeddings = noise(embed, model, 1e-3, normalize=normalise, k=1)\n","          adv_logits = model.predict(embedding_output = noised_embeddings)#,extended_attention_mask = b_input_mask)   <- Didn't use mask at all, which should be a problem\n","\n","          adv_loss = stable_kl(preds.view(-1,2), adv_logits.view(-1,2))\n","          loss_list.append(adv_loss)\n","        loss = sum(loss_list)\n","        # END MODEL\n","        total_train_loss += loss.item()\n","        loss.backward()\n","\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","        optimizer2.step()\n","        scheduler.step()\n","\n","    avg_train_loss = total_train_loss / len(train_dataloader)            \n","\n","    training_time = format_time(time.time() - t0)\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epcoh took: {:}\".format(training_time))\n","        \n","    # ========================================\n","    #               Validation\n","    # ========================================\n","    # After the completion of each training epoch, measure our performance on\n","    # our validation set.\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    t0 = time.time()\n","    model.eval()\n","    total_eval_accuracy = 0\n","    total_eval_loss = 0\n","    nb_eval_steps = 0\n","\n","    # Evaluate data for one epoch\n","    for batch in validation_dataloader:\n","        \n","\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","\n","        with torch.no_grad():        \n","\n","            result = model(b_input_ids, \n","                           token_type_ids=None, \n","                           attention_mask=b_input_mask,\n","                           labels=b_labels,\n","                           return_dict=True)\n","\n","\n","        loss = result.loss\n","        logits = result.logits\n","\n","        total_eval_loss += loss.item()\n","\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","        total_eval_accuracy += flat_accuracy(logits, label_ids)   \n","\n","    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n","    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n","    avg_val_loss = total_eval_loss / len(validation_dataloader)\n","    validation_time = format_time(time.time() - t0)\n","    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n","    print(\"  Validation took: {:}\".format(validation_time))\n","    training_stats.append(\n","        {\n","            'epoch': epoch_i + 1,\n","            'Training Loss': avg_train_loss,\n","            'Valid. Loss': avg_val_loss,\n","            'Valid. Accur.': avg_val_accuracy,\n","            'Training Time': training_time,\n","            'Validation Time': validation_time\n","        }\n","    )\n","\n","print(\"\")\n","print(\"Training complete!\")\n","\n","print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"],"execution_count":81,"outputs":[{"output_type":"stream","text":["\n","======== Epoch 1 / 4 ========\n","Training...\n","  Batch    40  of    113.    Elapsed: 0:00:19.\n","  Batch    80  of    113.    Elapsed: 0:00:38.\n","\n","  Average training loss: 0.77\n","  Training epcoh took: 0:00:57\n","\n","Running Validation...\n","  Accuracy: 0.08\n","  Validation Loss: 0.80\n","  Validation took: 0:00:01\n","\n","======== Epoch 2 / 4 ========\n","Training...\n","  Batch    40  of    113.    Elapsed: 0:00:20.\n","  Batch    80  of    113.    Elapsed: 0:00:40.\n","\n","  Average training loss: 0.76\n","  Training epcoh took: 0:00:59\n","\n","Running Validation...\n","  Accuracy: 0.08\n","  Validation Loss: 0.76\n","  Validation took: 0:00:01\n","\n","======== Epoch 3 / 4 ========\n","Training...\n","  Batch    40  of    113.    Elapsed: 0:00:21.\n","  Batch    80  of    113.    Elapsed: 0:00:42.\n","\n","  Average training loss: 0.76\n","  Training epcoh took: 0:01:01\n","\n","Running Validation...\n","  Accuracy: 0.92\n","  Validation Loss: 0.68\n","  Validation took: 0:00:01\n","\n","======== Epoch 4 / 4 ========\n","Training...\n","  Batch    40  of    113.    Elapsed: 0:00:21.\n","  Batch    80  of    113.    Elapsed: 0:00:41.\n","\n","  Average training loss: 0.74\n","  Training epcoh took: 0:01:01\n","\n","Running Validation...\n","  Accuracy: 0.08\n","  Validation Loss: 0.71\n","  Validation took: 0:00:01\n","\n","Training complete!\n","Total training took 0:04:00 (h:mm:ss)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"CrjE4ZInLODI"},"source":["# Final Test on the rest of the UCI Dataset"]},{"cell_type":"code","metadata":{"id":"SVuaPBtNDlj1","executionInfo":{"status":"ok","timestamp":1621103486321,"user_tz":-330,"elapsed":1209,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}}},"source":["\n","combinedDF['Label'] = combinedDF['Label'].astype(int, errors = 'raise')\n","sentences3 = df1_split_10_percent_test.Sentence.values\n","labels3 = df1_split_10_percent_test.Label.values"],"execution_count":82,"outputs":[]},{"cell_type":"code","metadata":{"id":"ESDPcLjNDmKi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621103488160,"user_tz":-330,"elapsed":1336,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"3f6fdd5a-8bd1-4eff-8538-095dcb9cd6d1"},"source":["max_len3 = 0\n","\n","# For every sentence...\n","for sent in sentences3:\n","\n","    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n","    input_ids3 = tokenizer.encode(sent, add_special_tokens=True)\n","\n","    # Update the maximum sentence length.\n","    max_len3 = max(max_len3, len(input_ids3))\n","\n","print('Max sentence length: ', max_len3)"],"execution_count":83,"outputs":[{"output_type":"stream","text":["Max sentence length:  1790\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NOzFdf7EDn3j","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621103491388,"user_tz":-330,"elapsed":1228,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"f2980388-a67d-40d6-cb4f-8f8069c3a41f"},"source":["input_ids3 = []\n","attention_masks3 = []\n","\n","# For every sentence...\n","for sent in sentences3:\n","    # `encode_plus` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    #   (5) Pad or truncate the sentence to `max_length`\n","    #   (6) Create attention masks for [PAD] tokens.\n","    encoded_dict3 = tokenizer.encode_plus(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = 64,           # Pad & truncate all sentences.\n","                        pad_to_max_length = True,\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","    \n","    # Add the encoded sentence to the list.    \n","    input_ids3.append(encoded_dict3['input_ids'])\n","    \n","    # And its attention mask (simply differentiates padding from non-padding).\n","    attention_masks3.append(encoded_dict3['attention_mask'])\n","\n","# Convert the lists into tensors.\n","input_ids3 = torch.cat(input_ids3, dim=0)\n","attention_masks3 = torch.cat(attention_masks3, dim=0)\n","labels3 = torch.tensor(labels3)\n","\n","# Print sentence 0, now as a list of IDs.\n","print('Original: ', sentences3[0])\n","print('Token IDs:', input_ids3[0])\n","\n","\n","print(len(sentences3))\n"],"execution_count":84,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Original:  Not much flavor to them, and very poorly constructed.\n","Token IDs: tensor([  101,  2025,  2172, 14894,  2000,  2068,  1010,  1998,  2200,  9996,\n","         3833,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0])\n","874\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aEFlEYwZDp_D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621103494436,"user_tz":-330,"elapsed":1268,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"1937946b-da39-4638-f9e3-2f804968c246"},"source":["test_dataset = TensorDataset(input_ids3, attention_masks3, labels3)\n","\n","print(type(input_ids3))        \n","print(type(attention_masks3))\n","print(type(labels3))\n","\n","\n","\n","test_dataloader = DataLoader(        \n","            test_dataset, # The validation samples.\n","            sampler = SequentialSampler(test_dataset), # Pull out batches sequentially.\n","            batch_size = 32 \n","        )\n","\n","\n","print(len(test_dataset))"],"execution_count":85,"outputs":[{"output_type":"stream","text":["<class 'torch.Tensor'>\n","<class 'torch.Tensor'>\n","<class 'torch.Tensor'>\n","874\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qAS6R3FEDrys","colab":{"base_uri":"https://localhost:8080/","height":120},"executionInfo":{"status":"ok","timestamp":1621103495731,"user_tz":-330,"elapsed":773,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"9bcf1595-ffe9-42b2-d911-4f90525d0fec"},"source":["torch.cuda.memory_summary(device=None, abbreviated=False)\n"],"execution_count":86,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |    2628 MB |    5901 MB |   21604 GB |   21601 GB |\\n|       from large pool |    2580 MB |    5789 MB |   21353 GB |   21351 GB |\\n|       from small pool |      47 MB |     165 MB |     250 GB |     250 GB |\\n|---------------------------------------------------------------------------|\\n| Active memory         |    2628 MB |    5901 MB |   21604 GB |   21601 GB |\\n|       from large pool |    2580 MB |    5789 MB |   21353 GB |   21351 GB |\\n|       from small pool |      47 MB |     165 MB |     250 GB |     250 GB |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |    6130 MB |    6130 MB |    6130 MB |       0 B  |\\n|       from large pool |    5960 MB |    5960 MB |    5960 MB |       0 B  |\\n|       from small pool |     170 MB |     170 MB |     170 MB |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |  425496 KB |    1103 MB |   20971 GB |   20971 GB |\\n|       from large pool |  371968 KB |    1062 MB |   20678 GB |   20677 GB |\\n|       from small pool |   53528 KB |      69 MB |     293 GB |     293 GB |\\n|---------------------------------------------------------------------------|\\n| Allocations           |    1461    |    2412    |    9246 K  |    9244 K  |\\n|       from large pool |     450    |    1227    |    5085 K  |    5084 K  |\\n|       from small pool |    1011    |    1659    |    4160 K  |    4159 K  |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |    1461    |    2412    |    9246 K  |    9244 K  |\\n|       from large pool |     450    |    1227    |    5085 K  |    5084 K  |\\n|       from small pool |    1011    |    1659    |    4160 K  |    4159 K  |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |     382    |     382    |     382    |       0    |\\n|       from large pool |     297    |     297    |     297    |       0    |\\n|       from small pool |      85    |      85    |      85    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |     194    |     262    |    5393 K  |    5392 K  |\\n|       from large pool |      96    |     162    |    3532 K  |    3531 K  |\\n|       from small pool |      98    |     122    |    1861 K  |    1861 K  |\\n|===========================================================================|\\n'"]},"metadata":{"tags":[]},"execution_count":86}]},{"cell_type":"code","metadata":{"id":"OPQD0agDDtRH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621103503342,"user_tz":-330,"elapsed":4329,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"9fa2fdc0-6b57-4f1c-adb6-cec1d750d792"},"source":["total_test_loss2 = []\n","total_test_accuracy2 = []\n","\n","\n","\n","for batch in test_dataloader:\n","\n","        \n","  # Unpack this training batch from our dataloader. \n","  #\n","  # As we unpack the batch, we'll also copy each tensor to the GPU using \n","  # the `to` method.\n","  #\n","  # `batch` contains three pytorch tensors:\n","  #   [0]: input ids \n","  #   [1]: attention masks\n","  #   [2]: labels \n","  b_input_ids = batch[0].to(device)\n","  b_input_mask = batch[1].to(device)\n","  b_labels = batch[2].to(device)\n","        \n","  # Tell pytorch not to bother with constructing the compute graph during\n","  # the forward pass, since this is only needed for backprop (training).\n","  #with torch.no_grad():        \n","\n","  # Forward pass, calculate logit predictions.\n","  # token_type_ids is the same as the \"segment ids\", which \n","  # differentiates sentence 1 and 2 in 2-sentence tasks.\n","  result = model(b_input_ids, \n","                       token_type_ids=None, \n","                       attention_mask=b_input_mask, \n","                       labels=b_labels,\n","                       return_dict=True)\n","        # Get the loss and \"logits\" output by the model. The \"logits\" are the \n","        # output values prior to applying an activation function like the \n","        # softmax.\n","  loss = result.loss\n","  logits = result.logits\n","        \n","            \n","        # Accumulate the validation loss.\n","  total_test_loss = loss.item()\n","\n","        # Move logits and labels to CPU\n","  logits = logits.detach().cpu().numpy()\n","  label_ids = b_labels.to('cpu').numpy()\n","\n","        # Calculate the accuracy for this batch of test sentences, and\n","        # accumulate it over all batches.\n","  total_test_accuracy = flat_accuracy(logits, label_ids)\n","        \n","\n","    # Report the final accuracy for this validation run.\n","print(\"The total test accuracy is: \")\n","print(total_test_accuracy)\n","print(\"Testing complete!\")"],"execution_count":87,"outputs":[{"output_type":"stream","text":["The total test accuracy is: \n","0.7\n","Testing complete!\n"],"name":"stdout"}]}]}