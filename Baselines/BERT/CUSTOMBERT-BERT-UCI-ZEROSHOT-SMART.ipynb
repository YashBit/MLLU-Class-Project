{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CUSTOMBERT-BERT-UCI-ZEROSHOT-SMART.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"25273389f2374e52996a1343053cd79e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1d6c5f6cc30148f5982a45429fa79fca","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6b41ce2c37fb4aa29a0c5530ca0a1983","IPY_MODEL_b59cfc9e892a4ab6938a3fd755f05b87"]}},"1d6c5f6cc30148f5982a45429fa79fca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6b41ce2c37fb4aa29a0c5530ca0a1983":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_57429c40790a46be8fa678cd081dfd82","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ea14c4f3a3c041bfacca1a19288761be"}},"b59cfc9e892a4ab6938a3fd755f05b87":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7bca744bb1e74770be900b71ab8d9d86","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:00&lt;00:00, 745kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7d581d0c33c14712b2b95ed460880c67"}},"57429c40790a46be8fa678cd081dfd82":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ea14c4f3a3c041bfacca1a19288761be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7bca744bb1e74770be900b71ab8d9d86":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7d581d0c33c14712b2b95ed460880c67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e2d0e5868e604056ae13473cf40ebca4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6faff89278a448afa7816d6635c49473","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_2cbcb128ffde439183ea37318c4bc4c1","IPY_MODEL_30f05e163e4447519dd44ede5b3f6d07"]}},"6faff89278a448afa7816d6635c49473":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2cbcb128ffde439183ea37318c4bc4c1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_f30326a35444470cae8c237d0d6e59cc","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":28,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":28,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f7e0bfd0d9e3452a9997053c9cbe9074"}},"30f05e163e4447519dd44ede5b3f6d07":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_79954854ed844008b31d1a8196671966","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 28.0/28.0 [00:00&lt;00:00, 153B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4ba45aaa24664576bd91c1cea9863ca8"}},"f30326a35444470cae8c237d0d6e59cc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f7e0bfd0d9e3452a9997053c9cbe9074":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"79954854ed844008b31d1a8196671966":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4ba45aaa24664576bd91c1cea9863ca8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"aa69334886734744aa51cf65c0a77aa5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0fa72339c7194270815a5657f5512e7b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_03ead30c0d764e30b04a20ce85cc1b01","IPY_MODEL_4d4fbd3bbab74164be4eec11f0c89e2c"]}},"0fa72339c7194270815a5657f5512e7b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"03ead30c0d764e30b04a20ce85cc1b01":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_979e4ceb8a3542a49524a445e1974915","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":466062,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":466062,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c6a27acb6aa84f0aac82b94fc15f4fe5"}},"4d4fbd3bbab74164be4eec11f0c89e2c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_64a7dc705b77410db19b8bef46427190","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 466k/466k [00:00&lt;00:00, 5.33MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_76a78b28973d439b8dcfb1c0000ccb8a"}},"979e4ceb8a3542a49524a445e1974915":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c6a27acb6aa84f0aac82b94fc15f4fe5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"64a7dc705b77410db19b8bef46427190":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"76a78b28973d439b8dcfb1c0000ccb8a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d8a4675995454d029275cc66e1323e98":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_dd4c997fc9f04dd4971de73fdb40f0b4","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_10dba67243e3403a966290bba81a085e","IPY_MODEL_a6109290164a4a3e9e32a868da912cd8"]}},"dd4c997fc9f04dd4971de73fdb40f0b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"10dba67243e3403a966290bba81a085e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0248188e99184ada85cd2255dc4b55e6","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":570,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":570,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6d2700ac4d7248b98d7201acb38d8d51"}},"a6109290164a4a3e9e32a868da912cd8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_dba35dab479e42a3ad30835f69a9696f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 570/570 [00:03&lt;00:00, 143B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cca7ce0101f2414b9bbffd1a1aabe6e7"}},"0248188e99184ada85cd2255dc4b55e6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"6d2700ac4d7248b98d7201acb38d8d51":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dba35dab479e42a3ad30835f69a9696f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"cca7ce0101f2414b9bbffd1a1aabe6e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f2e0a2cdc5454b67b2bb25c917dcbd38":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_472537a8fdbc4d7dabd98788dcb4abb5","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9691a72cf8894333b84b61f7f08c0822","IPY_MODEL_86d362f10aa947f6918e065eb114aee7"]}},"472537a8fdbc4d7dabd98788dcb4abb5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9691a72cf8894333b84b61f7f08c0822":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_851e41de52e848409882beda4b2f82a9","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":440473133,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":440473133,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_48f1a52870fc4ee2a2f76c3fec6320a2"}},"86d362f10aa947f6918e065eb114aee7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1fb8425196d84730a24f5fbd9004cfc4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 440M/440M [00:09&lt;00:00, 48.0MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4d270735f43f49aeaa716ac8b03da525"}},"851e41de52e848409882beda4b2f82a9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"48f1a52870fc4ee2a2f76c3fec6320a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1fb8425196d84730a24f5fbd9004cfc4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4d270735f43f49aeaa716ac8b03da525":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"EKOTlwcmxmej"},"source":["# BERT Fine-Tuning on CoLA with UCI and SiFT\n","\n","\n","\n","This notebook is orginally created by Chris McCormick and Nick Ryan. We made changes for SiFT and SMART, as well as our custom BERT class."]},{"cell_type":"markdown","metadata":{"id":"jJKaoairpdRa"},"source":["##Data and Importing Modules "]},{"cell_type":"code","metadata":{"id":"DEfSbAA4QHas","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621048140384,"user_tz":-330,"elapsed":1093,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"08bbdffa-4fff-428b-af44-ab5bad36ad0c"},"source":["import tensorflow as tf\n","\n","# Get the GPU device name.\n","device_name = tf.test.gpu_device_name()\n","\n","# The device name should look like the following:\n","if device_name == '/device:GPU:0':\n","    print('Found GPU at: {}'.format(device_name))\n","else:\n","    raise SystemError('GPU device not found')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oYsV4H8fCpZ-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621048146882,"user_tz":-330,"elapsed":4708,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"724cc70e-c3b6-4020-f95e-9bc93df36d87"},"source":["import torch\n","\n","# If there's a GPU available...\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"execution_count":3,"outputs":[{"output_type":"stream","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla T4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0NmMdkZO8R6q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621048155499,"user_tz":-330,"elapsed":7675,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"021d63cf-af1c-4281-e854-1a6fcb799bef"},"source":["!pip install transformers"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/9e/5b80becd952d5f7250eaf8fc64b957077b12ccfe73e9c03d37146ab29712/transformers-4.6.0-py3-none-any.whl (2.3MB)\n","\u001b[K     |████████████████████████████████| 2.3MB 27.3MB/s \n","\u001b[?25hCollecting huggingface-hub==0.0.8\n","  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n","Collecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n","\u001b[K     |████████████████████████████████| 3.3MB 45.1MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n","\u001b[K     |████████████████████████████████| 901kB 48.3MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (8.0.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Installing collected packages: huggingface-hub, tokenizers, sacremoses, transformers\n","Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.6.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5m6AnuFv0QXQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621048158757,"user_tz":-330,"elapsed":4920,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"0e0113cd-816f-4595-c2bc-2dec5ebfb23a"},"source":["!pip install wget"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Collecting wget\n","  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n","Building wheels for collected packages: wget\n","  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wget: filename=wget-3.2-cp37-none-any.whl size=9681 sha256=9e186669e0f31ed7fa1f8d7552989c19eb2cd5d56e34d5c5f606dbd1d85ce879\n","  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n","Successfully built wget\n","Installing collected packages: wget\n","Successfully installed wget-3.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pMtmPMkBzrvs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621048188190,"user_tz":-330,"elapsed":28200,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"983d0498-7755-4c7a-9aaa-6e6b1d65ceca"},"source":["#Adding the datasets to the collab file\n","\n","#First we mount the google drive\n","\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0Yv-tNv20dnH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621048193885,"user_tz":-330,"elapsed":2512,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"33faa77c-e725-4c4f-eaa8-c3985118bd27"},"source":["# with open('/content/drive/My Drive/Undergraduate/Courses/MLLU Project/Code/Baseline - Draft Proposal/yelp_labelled.txt', 'r') as f:\n","#   f.write('Successfully opened Yelp Labelled')\n","\n","with open('/content/drive/MyDrive/Undergraduate /Courses /MLLU Project/Code/MLLU : Final Paper Submission Code/yelp_labelled.txt', 'r') as y:\n","  print(\"Successfully Opened Yelp\")\n","\n","\n","with open('/content/drive/MyDrive/Undergraduate /Courses /MLLU Project/Code/MLLU : Final Paper Submission Code/amazon_cells_labelled.txt', 'r') as a:\n","  print(\"Successfully Opened Amazon Labelled\")\n","\n","\n","\n","with open('/content/drive/MyDrive/Undergraduate /Courses /MLLU Project/Code/MLLU : Final Paper Submission Code/imdb_labelled.txt', 'r') as i:\n","  print(\"Successfully Opened IMDB Labelled\")"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Successfully Opened Yelp\n","Successfully Opened Amazon Labelled\n","Successfully Opened IMDB Labelled\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_UkeC7SG2krJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621048197742,"user_tz":-330,"elapsed":1495,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"cfb03f3f-5ddf-4c48-be5f-46d35503b391"},"source":["#Checking on the Yelp Dataframe\n","import pandas as pd\n","df1_yelp = pd.read_csv('/content/drive/MyDrive/Undergraduate /Courses /MLLU Project/Code/MLLU : Final Paper Submission Code/yelp_labelled.txt', delimiter = '\\t', delim_whitespace= False, names = ('Sentence', 'Label'))\n","df1_yelp.head()\n","\n","print(df1_yelp.info())"],"execution_count":8,"outputs":[{"output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 1000 entries, 0 to 999\n","Data columns (total 2 columns):\n"," #   Column    Non-Null Count  Dtype \n","---  ------    --------------  ----- \n"," 0   Sentence  1000 non-null   object\n"," 1   Label     1000 non-null   int64 \n","dtypes: int64(1), object(1)\n","memory usage: 15.8+ KB\n","None\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j-0v9aKSCWVg","executionInfo":{"status":"ok","timestamp":1621048201747,"user_tz":-330,"elapsed":1356,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"2afef5ce-b621-4c19-e2cf-405ea136ce7b"},"source":["\n","#Similarly for the dataframes for Amazon and IMDB\n","df1_amazon = pd.read_csv('/content/drive/MyDrive/Undergraduate /Courses /MLLU Project/Code/MLLU : Final Paper Submission Code/amazon_cells_labelled.txt', delimiter = '\\t', delim_whitespace= False, names = ('Sentence', 'Label'))\n","df1_amazon.head()\n","print(df1_amazon.info())"],"execution_count":9,"outputs":[{"output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 1000 entries, 0 to 999\n","Data columns (total 2 columns):\n"," #   Column    Non-Null Count  Dtype \n","---  ------    --------------  ----- \n"," 0   Sentence  1000 non-null   object\n"," 1   Label     1000 non-null   int64 \n","dtypes: int64(1), object(1)\n","memory usage: 15.8+ KB\n","None\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_wPamOpWCYhk","executionInfo":{"status":"ok","timestamp":1621048204119,"user_tz":-330,"elapsed":1263,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"b2f6c6a0-e227-4528-c69a-48bf1edcb903"},"source":["df1_imdb = pd.read_csv('/content/drive/MyDrive/Undergraduate /Courses /MLLU Project/Code/MLLU : Final Paper Submission Code/imdb_labelled.txt', delimiter = '\\t', delim_whitespace= False, names = ('Sentence', 'Label'))\n","df1_imdb.head()\n","print(df1_imdb.info())"],"execution_count":10,"outputs":[{"output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 748 entries, 0 to 747\n","Data columns (total 2 columns):\n"," #   Column    Non-Null Count  Dtype \n","---  ------    --------------  ----- \n"," 0   Sentence  748 non-null    object\n"," 1   Label     748 non-null    int64 \n","dtypes: int64(1), object(1)\n","memory usage: 11.8+ KB\n","None\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"blqIvQaQncdJ","colab":{"base_uri":"https://localhost:8080/","height":512},"executionInfo":{"status":"ok","timestamp":1621048207056,"user_tz":-330,"elapsed":1512,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"7f0aee97-f266-4cfe-c5d7-2695b054992b"},"source":["\n","combinedDF = pd.concat([df1_imdb, df1_amazon, df1_yelp], axis = 0, join = 'inner')\n","combinedDF.head()\n","combinedDF.info()\n","combinedDF.head(10)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 2748 entries, 0 to 999\n","Data columns (total 2 columns):\n"," #   Column    Non-Null Count  Dtype \n","---  ------    --------------  ----- \n"," 0   Sentence  2748 non-null   object\n"," 1   Label     2748 non-null   int64 \n","dtypes: int64(1), object(1)\n","memory usage: 64.4+ KB\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sentence</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>A very, very, very slow-moving, aimless movie ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Not sure who was more lost - the flat characte...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Attempting artiness with black &amp; white and cle...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Very little music or anything to speak of.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>The best scene in the movie was when Gerardo i...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>The rest of the movie lacks art, charm, meanin...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Wasted two hours.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Saw the movie today and thought it was a good ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>A bit predictable.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Loved the casting of Jimmy Buffet as the scien...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            Sentence  Label\n","0  A very, very, very slow-moving, aimless movie ...      0\n","1  Not sure who was more lost - the flat characte...      0\n","2  Attempting artiness with black & white and cle...      0\n","3       Very little music or anything to speak of.        0\n","4  The best scene in the movie was when Gerardo i...      1\n","5  The rest of the movie lacks art, charm, meanin...      0\n","6                                Wasted two hours.        0\n","7  Saw the movie today and thought it was a good ...      1\n","8                               A bit predictable.        0\n","9  Loved the casting of Jimmy Buffet as the scien...      1"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":512},"id":"qaDK92pbCfZZ","executionInfo":{"status":"ok","timestamp":1621048213189,"user_tz":-330,"elapsed":2246,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"1119128a-21a7-4578-ea2a-ddc0f3dca9f6"},"source":["combinedDF = combinedDF.sample(frac = 1).reset_index(drop = True)\n","combinedDF = combinedDF.dropna()\n","combinedDF.info()\n","combinedDF.head(10)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 2748 entries, 0 to 2747\n","Data columns (total 2 columns):\n"," #   Column    Non-Null Count  Dtype \n","---  ------    --------------  ----- \n"," 0   Sentence  2748 non-null   object\n"," 1   Label     2748 non-null   int64 \n","dtypes: int64(1), object(1)\n","memory usage: 64.4+ KB\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sentence</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Now I am getting angry and I want my damn pho.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>There's a horrible tick sound in the backgroun...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>The chipolte ranch dipping sause was tasteless...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>The cutouts and buttons are placed perfectly.</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Someone shouldve invented this sooner.</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>The food was delicious, our bartender was atte...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>The company shipped my product very promptly a...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Host staff were, for lack of a better word, BI...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>She was quite disappointed although some blame...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>The sets (especially designed to work with the...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            Sentence  Label\n","0     Now I am getting angry and I want my damn pho.      0\n","1  There's a horrible tick sound in the backgroun...      0\n","2  The chipolte ranch dipping sause was tasteless...      0\n","3      The cutouts and buttons are placed perfectly.      1\n","4             Someone shouldve invented this sooner.      1\n","5  The food was delicious, our bartender was atte...      1\n","6  The company shipped my product very promptly a...      1\n","7  Host staff were, for lack of a better word, BI...      0\n","8  She was quite disappointed although some blame...      0\n","9  The sets (especially designed to work with the...      1"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"GuE5BqICAne2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621048216069,"user_tz":-330,"elapsed":1539,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"860e6285-66d6-4a03-f14a-5aaa487d71ba"},"source":["df1_twitter = pd.read_csv('/content/drive/MyDrive/Undergraduate /Courses /MLLU Project/Code/MLLU : Final Paper Submission Code/train.csv', names = ('Label', 'Sentence'))\n","df1_twitter = df1_twitter.iloc[1:4000]\n","\n","df1_twitter['Label'] = df1_twitter['Label'].astype(int, errors = 'raise')"],"execution_count":13,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  after removing the cwd from sys.path.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_XcD3h68Ck7v","executionInfo":{"status":"ok","timestamp":1621048216981,"user_tz":-330,"elapsed":1059,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"14a630af-5328-4b2d-bb66-8bbb69b96bc5"},"source":["df1_twitter.head()\n","df1_twitter.info()"],"execution_count":14,"outputs":[{"output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","Index: 3999 entries, 1 to 3999\n","Data columns (total 2 columns):\n"," #   Column    Non-Null Count  Dtype \n","---  ------    --------------  ----- \n"," 0   Label     3999 non-null   int64 \n"," 1   Sentence  3999 non-null   object\n","dtypes: int64(1), object(1)\n","memory usage: 93.7+ KB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ykLveVUNCneG","executionInfo":{"status":"ok","timestamp":1621048220458,"user_tz":-330,"elapsed":777,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"50197e64-087f-4473-ff78-4e1c5065c5b0"},"source":["df1_twitter.head(10)\n","sentences = df1_twitter.Sentence.values\n","labels = df1_twitter.Label.values\n","\n","print(type(labels[0]))"],"execution_count":15,"outputs":[{"output_type":"stream","text":["<class 'numpy.int64'>\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EFSJzwI5pujc"},"source":["## Tokenization and DataLoader"]},{"cell_type":"code","metadata":{"id":"Z474sSC6oe7A","colab":{"base_uri":"https://localhost:8080/","height":181,"referenced_widgets":["25273389f2374e52996a1343053cd79e","1d6c5f6cc30148f5982a45429fa79fca","6b41ce2c37fb4aa29a0c5530ca0a1983","b59cfc9e892a4ab6938a3fd755f05b87","57429c40790a46be8fa678cd081dfd82","ea14c4f3a3c041bfacca1a19288761be","7bca744bb1e74770be900b71ab8d9d86","7d581d0c33c14712b2b95ed460880c67","e2d0e5868e604056ae13473cf40ebca4","6faff89278a448afa7816d6635c49473","2cbcb128ffde439183ea37318c4bc4c1","30f05e163e4447519dd44ede5b3f6d07","f30326a35444470cae8c237d0d6e59cc","f7e0bfd0d9e3452a9997053c9cbe9074","79954854ed844008b31d1a8196671966","4ba45aaa24664576bd91c1cea9863ca8","aa69334886734744aa51cf65c0a77aa5","0fa72339c7194270815a5657f5512e7b","03ead30c0d764e30b04a20ce85cc1b01","4d4fbd3bbab74164be4eec11f0c89e2c","979e4ceb8a3542a49524a445e1974915","c6a27acb6aa84f0aac82b94fc15f4fe5","64a7dc705b77410db19b8bef46427190","76a78b28973d439b8dcfb1c0000ccb8a"]},"executionInfo":{"status":"ok","timestamp":1621048226354,"user_tz":-330,"elapsed":1840,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"2a5def5d-4382-4784-a9c0-735ac8133bcf"},"source":["from transformers import BertTokenizer\n","print('Loading BERT tokenizer...')\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Loading BERT tokenizer...\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"25273389f2374e52996a1343053cd79e","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e2d0e5868e604056ae13473cf40ebca4","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aa69334886734744aa51cf65c0a77aa5","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dLIbudgfh6F0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621048228523,"user_tz":-330,"elapsed":916,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"94065a96-7589-4045-a134-43a75577a7e8"},"source":["print(' Original: ', sentences[0])\n","print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n","print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"],"execution_count":17,"outputs":[{"output_type":"stream","text":[" Original:   @user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run\n","Tokenized:  ['@', 'user', 'when', 'a', 'father', 'is', 'dysfunction', '##al', 'and', 'is', 'so', 'selfish', 'he', 'drag', '##s', 'his', 'kids', 'into', 'his', 'dysfunction', '.', '#', 'run']\n","Token IDs:  [1030, 5310, 2043, 1037, 2269, 2003, 28466, 2389, 1998, 2003, 2061, 14337, 2002, 8011, 2015, 2010, 4268, 2046, 2010, 28466, 1012, 1001, 2448]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cKsH2sU0OCQA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621048233007,"user_tz":-330,"elapsed":2860,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"23fb2a88-4f34-4cc6-92e7-b8f088d6ecbd"},"source":["max_len = 0\n","\n","# For every sentence...\n","for sent in sentences:\n","\n","    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n","    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n","\n","    # Update the maximum sentence length.\n","    max_len = max(max_len, len(input_ids))\n","\n","\n","print(len(sentences))\n","print('Max sentence length: ', max_len)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["3999\n","Max sentence length:  76\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2bBdb3pt8LuQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621048238440,"user_tz":-330,"elapsed":3249,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"edfd6794-ed73-4725-c1d6-48e28579c3f8"},"source":["# Tokenize all of the sentences and map the tokens to thier word IDs.\n","input_ids = []\n","attention_masks = []\n","\n","# For every sentence...\n","for sent in sentences:\n","    # `encode_plus` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    #   (5) Pad or truncate the sentence to `max_length`\n","    #   (6) Create attention masks for [PAD] tokens.\n","    encoded_dict = tokenizer.encode_plus(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = 32,           # Pad & truncate all sentences.\n","                        pad_to_max_length = True,\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","    \n","    # Add the encoded sentence to the list.    \n","    input_ids.append(encoded_dict['input_ids'])\n","    \n","    # And its attention mask (simply differentiates padding from non-padding).\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","# Convert the lists into tensors.\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","labels = torch.tensor(labels)\n","\n","# Print sentence 0, now as a list of IDs.\n","print('Original: ', sentences[0])\n","print('Token IDs:', input_ids[0])"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Original:   @user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run\n","Token IDs: tensor([  101,  1030,  5310,  2043,  1037,  2269,  2003, 28466,  2389,  1998,\n","         2003,  2061, 14337,  2002,  8011,  2015,  2010,  4268,  2046,  2010,\n","        28466,  1012,  1001,  2448,   102,     0,     0,     0,     0,     0,\n","            0,     0])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GEgLpFVlo1Z-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621048246881,"user_tz":-330,"elapsed":1073,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"c8bddcdb-f074-4114-e9ed-868383dda384"},"source":["from torch.utils.data import TensorDataset, random_split\n","\n","# Combine the training inputs into a TensorDataset.\n","dataset = TensorDataset(input_ids, attention_masks, labels)\n","print(type(input_ids))\n","print(type(attention_masks))\n","print(type(labels))\n","# Create a 90-10 train-validation split.\n","\n","# Calculate the number of samples to include in each set.\n","train_size = int(0.9 * len(dataset))\n","val_size = len(dataset) - train_size\n","\n","# Divide the dataset by randomly selecting samples.\n","train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n","\n","print('{:>5,} training samples'.format(train_size))\n","print('{:>5,} validation samples'.format(val_size))"],"execution_count":21,"outputs":[{"output_type":"stream","text":["<class 'torch.Tensor'>\n","<class 'torch.Tensor'>\n","<class 'torch.Tensor'>\n","3,599 training samples\n","  400 validation samples\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XGUqOCtgqGhP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621048249370,"user_tz":-330,"elapsed":856,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"3bbe673e-2382-483d-90a2-a050b36f3c84"},"source":["from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","\n","# The DataLoader needs to know our batch size for training, so we specify it \n","# here. \n","batch_size = 32\n","\n","# Create the DataLoaders for our training and validation sets.\n","# We'll take training samples in random order. \n","train_dataloader = DataLoader(\n","            train_dataset,  # The training samples.\n","            sampler = RandomSampler(train_dataset), # Select batches randomly\n","            batch_size = batch_size # Trains with this batch size.\n","        )\n","\n","# For validation the order doesn't matter, so we'll just read them sequentially.\n","validation_dataloader = DataLoader(\n","            val_dataset, # The validation samples.\n","            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n","            batch_size = batch_size # Evaluate with this batch size.\n","        )\n","\n","\n","print(\"hi\")"],"execution_count":22,"outputs":[{"output_type":"stream","text":["hi\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"73S4P4SMp6hX"},"source":["## Custom Bert Class and Initialization"]},{"cell_type":"code","metadata":{"id":"UOteWAT-Adqx","executionInfo":{"status":"ok","timestamp":1621048253736,"user_tz":-330,"elapsed":1302,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}}},"source":["from transformers import BertForSequenceClassification, AdamW, BertConfig, BertPreTrainedModel, BertModel\n","from transformers.models.bert.modeling_bert import BertEmbeddings,BertEncoder,BertPooler\n","from transformers.modeling_outputs import BaseModelOutputWithPoolingAndCrossAttentions\n","\n","import torch\n","import torch.utils.checkpoint\n","from torch import nn\n","from torch.nn import CrossEntropyLoss, MSELoss\n","\n","class CustomBertForClassification(BertForSequenceClassification):\n","    def __init__(self, config):\n","        super().__init__(config)\n","        #self.bert = BertForSequenceClassification(config).from_pretrained(\"bert-base-uncased\",num_labels = 2,output_attentions = False, output_hidden_states = False)\n","        self.embeddings = self.bert.embeddings\n","        self.encoder = self.bert.encoder\n","        self.pooler = self.bert.pooler\n","\n","    def embed(self, input_ids=None, \n","                    token_type_ids=None, \n","                    position_ids=None, \n","                    inputs_embeds=None, \n","                    past_key_values_length=0):\n","        # See: BERTModel.forward\n","        return self.embeddings(\n","            input_ids=input_ids,\n","            position_ids=position_ids,\n","            token_type_ids=token_type_ids,\n","            inputs_embeds=inputs_embeds,\n","            past_key_values_length=past_key_values_length\n","        )\n","    \n","    def predict(self,embedding_output,\n","                extended_attention_mask=None,\n","                head_mask=None,\n","                encoder_hidden_states=None,\n","                encoder_extended_attention_mask=None,\n","                past_key_values=None,\n","                use_cache=None,\n","                output_attentions=None,\n","                output_hidden_states=None,\n","                return_dict=True):\n","      # See: BERTModel.forward \n","        encoder_outputs = self.encoder(\n","            embedding_output,\n","            attention_mask=extended_attention_mask,\n","            head_mask=head_mask,\n","            encoder_hidden_states=encoder_hidden_states,\n","            encoder_attention_mask=encoder_extended_attention_mask,\n","            past_key_values=past_key_values,\n","            use_cache=use_cache,\n","            output_attentions=output_attentions,\n","            output_hidden_states=output_hidden_states,\n","            return_dict=return_dict,\n","        )\n","\n","        sequence_output = encoder_outputs[0]\n","        pooled_output = self.pooler(sequence_output) if self.pooler is not None else None\n","        \n","        bert_output = BaseModelOutputWithPoolingAndCrossAttentions(\n","                    last_hidden_state=sequence_output,\n","                    pooler_output=pooled_output,\n","                    past_key_values=encoder_outputs.past_key_values,\n","                    hidden_states=encoder_outputs.hidden_states,\n","                    attentions=encoder_outputs.attentions,\n","                    cross_attentions=encoder_outputs.cross_attentions,\n","                )\n","\n","        pooled_output = bert_output[1]\n","\n","        pooled_output = self.dropout(pooled_output)\n","        logits = self.classifier(pooled_output)\n","        \n","        return logits\n"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["d8a4675995454d029275cc66e1323e98","dd4c997fc9f04dd4971de73fdb40f0b4","10dba67243e3403a966290bba81a085e","a6109290164a4a3e9e32a868da912cd8","0248188e99184ada85cd2255dc4b55e6","6d2700ac4d7248b98d7201acb38d8d51","dba35dab479e42a3ad30835f69a9696f","cca7ce0101f2414b9bbffd1a1aabe6e7","f2e0a2cdc5454b67b2bb25c917dcbd38","472537a8fdbc4d7dabd98788dcb4abb5","9691a72cf8894333b84b61f7f08c0822","86d362f10aa947f6918e065eb114aee7","851e41de52e848409882beda4b2f82a9","48f1a52870fc4ee2a2f76c3fec6320a2","1fb8425196d84730a24f5fbd9004cfc4","4d270735f43f49aeaa716ac8b03da525"]},"id":"IdNBO5qk2-i_","collapsed":true,"executionInfo":{"status":"ok","timestamp":1621048279037,"user_tz":-330,"elapsed":23569,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"6aecfd2a-d5a3-407d-a2a5-d52934f55486"},"source":["#@title\n","model = CustomBertForClassification.from_pretrained(\n","    \"bert-base-uncased\",\n","    num_labels = 2,\n","    output_attentions = False, \n","    output_hidden_states = False, \n",")\n","\n","model.cuda()"],"execution_count":24,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d8a4675995454d029275cc66e1323e98","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f2e0a2cdc5454b67b2bb25c917dcbd38","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing CustomBertForClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n","- This IS expected if you are initializing CustomBertForClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing CustomBertForClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of CustomBertForClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'pooler.dense.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.dense.weight', 'classifier.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.8.attention.self.query.bias', 'pooler.dense.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.5.intermediate.dense.weight', 'classifier.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.8.attention.self.query.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.6.attention.self.value.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["CustomBertForClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n","  (embeddings): BertEmbeddings(\n","    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","    (position_embeddings): Embedding(512, 768)\n","    (token_type_embeddings): Embedding(2, 768)\n","    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (encoder): BertEncoder(\n","    (layer): ModuleList(\n","      (0): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (1): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (2): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (3): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (4): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (5): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (6): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (7): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (8): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (9): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (10): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (11): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","  )\n","  (pooler): BertPooler(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (activation): Tanh()\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"markdown","metadata":{"id":"hmSpMRD5qaqE"},"source":["##Noise Function"]},{"cell_type":"code","metadata":{"id":"pG5DszcpDAjw","executionInfo":{"status":"ok","timestamp":1621048286090,"user_tz":-330,"elapsed":1310,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}}},"source":["from torch.nn import LayerNorm\n","import torch.nn.functional as F\n","\n","def normalize_embed(embed):\n","    embed_mean = torch.mean(embed,dim=(1,2))\n","    embed_std = torch.std(embed, dim=(1,2))\n","\n","    embed_clone = torch.clone(embed)\n","\n","    for i in range(0,embed_clone.size()[0]):\n","        # embed_clone[i] = torch.div(torch.sub(embed_clone[i],embed_mean[i]),embed_std[i])\n","        embed_clone[i] = (embed_clone[i] - embed_mean[i]) / embed_std[i]\n","    return embed_clone, embed_mean, embed_std\n","\n","def denormalize_embed(embed, embed_mean, embed_std):\n","    for i in range(0,embed.size()[0]):\n","        # embed[i] = (embed[i] - embed_mean[i]) / embed_std[i]\n","        embed[i] = (embed[i] * embed_std[i]) + embed_mean[i]\n","    return embed \n","\n","def stable_kl(logit, target, epsilon=1e-6, reduce=True):\n","    logit = logit.view(-1, logit.size(-1)).float()\n","    target = target.view(-1, target.size(-1)).float()\n","    bs = logit.size(0)\n","    p = F.log_softmax(logit, 1).exp()\n","    y = F.log_softmax(target, 1).exp()\n","    rp = -(1.0/(p + epsilon) -1 + epsilon).detach().log()\n","    ry = -(1.0/(y + epsilon) -1 + epsilon).detach().log()\n","    if reduce:\n","        return (p* (rp- ry) * 2).sum() / bs\n","    else:\n","        return (p* (rp- ry) * 2).sum()\n","\n","def _norm_grad(grad, epsilon = 1e-6, eff_grad=None, sentence_level=False):\n","        if sentence_level:\n","            direction = grad / (grad.abs().max((-2, -1), keepdim=True)[0] + epsilon)\n","        else:\n","            direction = grad / (grad.abs().max(-1, keepdim=True)[0] + epsilon)\n","            eff_direction = eff_grad / (grad.abs().max(-1, keepdim=True)[0] + epsilon)\n","        return direction, eff_direction\n","\n","def noise(embed, model,step_size, normalize=False, k=1, mean=0, std=0.01):  ## Not including mask in the noise, so it means no mask as input for predict, should be a problem\n","    if normalize == True:\n","        logits = model.predict(embed)#,attention_mask)\n","        # LNorm = LayerNorm(embed.size(),elementwise_affine=False)\n","        # normalized_embed = LNorm(embed)\n","        normalized_embed, embed_mean, embed_std = normalize_embed(embed)\n","\n","        noise = torch.normal(mean=0, std=0.01,size=(normalized_embed.size()[0],normalized_embed.size()[1],normalized_embed.size()[2]))\n","        noise = noise.to(device)\n","        noise.requires_grad_()\n","        noised_normalized_embeddings = normalized_embed+noise\n","        adv_logits = model.predict(noised_normalized_embeddings)#,attention_mask)\n","        adv_loss = stable_kl(adv_logits, logits.detach(), reduce=False)\n","        delta_grad, = torch.autograd.grad(adv_loss, noise, only_inputs=True, retain_graph=False)\n","        norm = delta_grad.norm()\n","        # if (torch.isnan(norm) or torch.isinf(norm)):\n","        #     return 0\n","        eff_delta_grad = delta_grad * step_size\n","        delta_grad = noise + delta_grad * step_size\n","        noise, eff_noise = _norm_grad(delta_grad, eff_grad=eff_delta_grad, sentence_level=0)\n","        noise = noise.detach()\n","        noised_normalized_embeddings = normalized_embed+noise\n","        denormalize_noised_embed = denormalize_embed(noised_normalized_embeddings,embed_mean, embed_std) \n","        return denormalize_noised_embed\n","    else:\n","        logits = model.predict(embed)#,attention_mask)\n","        noise = torch.normal(mean=0, std=0.01,size=(embed.size()[0],embed.size()[1],embed.size()[2]))\n","        noise = noise.to(device)\n","        noise.requires_grad_()\n","        noised_embeddings = embed+noise\n","        adv_logits = model.predict(noised_embeddings)#,attention_mask)\n","        adv_loss = stable_kl(adv_logits, logits.detach(), reduce=False)\n","        delta_grad, = torch.autograd.grad(adv_loss, noise, only_inputs=True, retain_graph=False)\n","        norm = delta_grad.norm()\n","        # if (torch.isnan(norm) or torch.isinf(norm)):\n","        #     return 0\n","        eff_delta_grad = delta_grad * step_size\n","        delta_grad = noise + delta_grad * step_size\n","        noise, eff_noise = _norm_grad(delta_grad, eff_grad=eff_delta_grad, sentence_level=0)\n","        noise = noise.detach()\n","        noised_embeddings = embed+noise\n","        return noised_embeddings"],"execution_count":25,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bunW4qF4qSyZ"},"source":["## Optimizer, Scheduler, and Some Other Training Prep"]},{"cell_type":"code","metadata":{"id":"GLs72DuMODJO","executionInfo":{"status":"ok","timestamp":1621048290706,"user_tz":-330,"elapsed":1207,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}}},"source":["#@title\n","optimizer = AdamW(model.parameters(),\n","                  lr = 2e-5,\n","                  eps = 1e-8 \n","                )"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"-p0upAhhRiIx","executionInfo":{"status":"ok","timestamp":1621048292881,"user_tz":-330,"elapsed":1456,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}}},"source":["from transformers import get_linear_schedule_with_warmup\n","\n","# Number of training epochs. \n","# We chose to run for 4, but we'll see later that this may be over-fitting the\n","# training data.\n","epochs = 4\n","\n","# Total number of training steps is [number of batches] x [number of epochs]. \n","# (Note that this is not the same as the number of training samples).\n","total_steps = len(train_dataloader) * epochs\n","\n","# Create the learning rate scheduler.\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0, # Default value in run_glue.py\n","                                            num_training_steps = total_steps)"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"9cQNvaZ9bnyy","executionInfo":{"status":"ok","timestamp":1621048295141,"user_tz":-330,"elapsed":1062,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}}},"source":["#@title\n","import numpy as np\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"gpt6tR83keZD","executionInfo":{"status":"ok","timestamp":1621048297592,"user_tz":-330,"elapsed":1103,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}}},"source":["#@title\n","import time\n","import datetime\n","\n","def format_time(elapsed):\n","    elapsed_rounded = int(round((elapsed)))\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"ScjvBSBfHtBc","executionInfo":{"status":"ok","timestamp":1621048303122,"user_tz":-330,"elapsed":719,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}}},"source":["MODE = \"SMART-adv-only\""],"execution_count":31,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mCSpuOXLqor-"},"source":["##Training Loop with Validation"]},{"cell_type":"code","metadata":{"id":"6J-FYdx6nFE_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621048551002,"user_tz":-330,"elapsed":246877,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"871a510c-1a6f-4e89-9c3f-07d810402eb3"},"source":["import random\n","import numpy as np\n","\n","seed_val = 42\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","training_stats = []\n","total_t0 = time.time()\n","\n","# For each epoch...\n","for epoch_i in range(0, epochs):\n","    \n","    # ========================================\n","    #               Training\n","    # ========================================\n","    \n","    # Perform one full pass over the training set.\n","\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    # Measure how long the training epoch takes.\n","    t0 = time.time()\n","    total_train_loss = 0\n","    model.train()\n","\n","    # For each batch of training data...\n","    for step, batch in enumerate(train_dataloader):\n","        # Progress update every 40 batches.\n","        if step % 40 == 0 and not step == 0:\n","            elapsed = format_time(time.time() - t0)\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","\n","        model.zero_grad()        \n","\n","        embed = model.embed(input_ids = b_input_ids)\n","        preds = model.predict(embedding_output = embed)#,extended_attention_mask=b_input_mask)   <- Didn't use mask at all, which should be a problem\n","        loss_fct = CrossEntropyLoss()\n","        regular_loss = loss_fct(preds.view(-1,2), b_labels.view(-1))\n","        loss_list = [regular_loss]\n","        if MODE in [\"SMART-adv-only\", \"SIFT\"]:\n","          normalise = True if MODE == \"SIFT\" else False\n","          noised_embeddings = noise(embed, model, 1e-3, normalize=normalise, k=1)\n","          adv_logits = model.predict(embedding_output = noised_embeddings)#,extended_attention_mask = b_input_mask)   <- Didn't use mask at all, which should be a problem\n","\n","          adv_loss = stable_kl(preds.view(-1,2), adv_logits.view(-1,2))\n","          loss_list.append(adv_loss)\n","        loss = sum(loss_list)\n","        # END MODEL\n","        total_train_loss += loss.item()\n","        loss.backward()\n","\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","        optimizer.step()\n","        scheduler.step()\n","\n","    avg_train_loss = total_train_loss / len(train_dataloader)            \n","\n","    training_time = format_time(time.time() - t0)\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epcoh took: {:}\".format(training_time))\n","        \n","    # ========================================\n","    #               Validation\n","    # ========================================\n","    # After the completion of each training epoch, measure our performance on\n","    # our validation set.\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    t0 = time.time()\n","    model.eval()\n","    total_eval_accuracy = 0\n","    total_eval_loss = 0\n","    nb_eval_steps = 0\n","\n","    # Evaluate data for one epoch\n","    for batch in validation_dataloader:\n","        \n","\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","\n","        with torch.no_grad():        \n","\n","            result = model(b_input_ids, \n","                           token_type_ids=None, \n","                           attention_mask=b_input_mask,\n","                           labels=b_labels,\n","                           return_dict=True)\n","\n","\n","        loss = result.loss\n","        logits = result.logits\n","\n","        total_eval_loss += loss.item()\n","\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","        total_eval_accuracy += flat_accuracy(logits, label_ids)   \n","\n","    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n","    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n","    avg_val_loss = total_eval_loss / len(validation_dataloader)\n","    validation_time = format_time(time.time() - t0)\n","    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n","    print(\"  Validation took: {:}\".format(validation_time))\n","    training_stats.append(\n","        {\n","            'epoch': epoch_i + 1,\n","            'Training Loss': avg_train_loss,\n","            'Valid. Loss': avg_val_loss,\n","            'Valid. Accur.': avg_val_accuracy,\n","            'Training Time': training_time,\n","            'Validation Time': validation_time\n","        }\n","    )\n","\n","print(\"\")\n","print(\"Training complete!\")\n","\n","print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"],"execution_count":32,"outputs":[{"output_type":"stream","text":["\n","======== Epoch 1 / 4 ========\n","Training...\n","  Batch    40  of    113.    Elapsed: 0:00:20.\n","  Batch    80  of    113.    Elapsed: 0:00:41.\n","\n","  Average training loss: 0.22\n","  Training epcoh took: 0:00:58\n","\n","Running Validation...\n","  Accuracy: 0.93\n","  Validation Loss: 0.17\n","  Validation took: 0:00:01\n","\n","======== Epoch 2 / 4 ========\n","Training...\n","  Batch    40  of    113.    Elapsed: 0:00:22.\n","  Batch    80  of    113.    Elapsed: 0:00:44.\n","\n","  Average training loss: 0.14\n","  Training epcoh took: 0:01:02\n","\n","Running Validation...\n","  Accuracy: 0.94\n","  Validation Loss: 0.16\n","  Validation took: 0:00:01\n","\n","======== Epoch 3 / 4 ========\n","Training...\n","  Batch    40  of    113.    Elapsed: 0:00:22.\n","  Batch    80  of    113.    Elapsed: 0:00:43.\n","\n","  Average training loss: 0.08\n","  Training epcoh took: 0:01:01\n","\n","Running Validation...\n","  Accuracy: 0.95\n","  Validation Loss: 0.15\n","  Validation took: 0:00:01\n","\n","======== Epoch 4 / 4 ========\n","Training...\n","  Batch    40  of    113.    Elapsed: 0:00:22.\n","  Batch    80  of    113.    Elapsed: 0:00:43.\n","\n","  Average training loss: 0.05\n","  Training epcoh took: 0:01:01\n","\n","Running Validation...\n","  Accuracy: 0.95\n","  Validation Loss: 0.16\n","  Validation took: 0:00:01\n","\n","Training complete!\n","Total training took 0:04:05 (h:mm:ss)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VQTvJ1vRP7u4"},"source":["Let's view the summary of the training process."]},{"cell_type":"code","metadata":{"id":"6O_NbXFGMukX","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1621048554663,"user_tz":-330,"elapsed":1184,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"a20c19ad-248c-46be-efc9-96b1adfd4fea"},"source":["\n","import pandas as pd\n","\n","# Display floats with two decimal places.\n","pd.set_option('precision', 2)\n","\n","# Create a DataFrame from our training statistics.\n","df_stats = pd.DataFrame(data=training_stats)\n","\n","# Use the 'epoch' as the row index.\n","df_stats = df_stats.set_index('epoch')\n","\n","# A hack to force the column headers to wrap.\n","#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n","\n","# Display the table.\n","df_stats"],"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Training Loss</th>\n","      <th>Valid. Loss</th>\n","      <th>Valid. Accur.</th>\n","      <th>Training Time</th>\n","      <th>Validation Time</th>\n","    </tr>\n","    <tr>\n","      <th>epoch</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>0.22</td>\n","      <td>0.17</td>\n","      <td>0.93</td>\n","      <td>0:00:58</td>\n","      <td>0:00:01</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.14</td>\n","      <td>0.16</td>\n","      <td>0.94</td>\n","      <td>0:01:02</td>\n","      <td>0:00:01</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.08</td>\n","      <td>0.15</td>\n","      <td>0.95</td>\n","      <td>0:01:01</td>\n","      <td>0:00:01</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.05</td>\n","      <td>0.16</td>\n","      <td>0.95</td>\n","      <td>0:01:01</td>\n","      <td>0:00:01</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n","epoch                                                                         \n","1               0.22         0.17           0.93       0:00:58         0:00:01\n","2               0.14         0.16           0.94       0:01:02         0:00:01\n","3               0.08         0.15           0.95       0:01:01         0:00:01\n","4               0.05         0.16           0.95       0:01:01         0:00:01"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"id":"68xreA9JAmG5","colab":{"base_uri":"https://localhost:8080/","height":427},"executionInfo":{"status":"ok","timestamp":1621048559872,"user_tz":-330,"elapsed":2068,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"2e5b1788-9206-4cad-ce4b-33fdaa0da99b"},"source":["import matplotlib.pyplot as plt\n","% matplotlib inline\n","\n","import seaborn as sns\n","\n","# Use plot styling from seaborn.\n","sns.set(style='darkgrid')\n","\n","# Increase the plot size and font size.\n","sns.set(font_scale=1.5)\n","plt.rcParams[\"figure.figsize\"] = (12,6)\n","\n","# Plot the learning curve.\n","plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n","plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n","\n","# Label the plot.\n","plt.title(\"Training & Validation Loss\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.xticks([1, 2, 3, 4])\n","\n","plt.show()"],"execution_count":34,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 864x432 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zWeYo84kDYZM","executionInfo":{"status":"ok","timestamp":1621048566933,"user_tz":-330,"elapsed":1686,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"21efd054-9de8-4723-bf88-6f0bb3dcf2e6"},"source":["total_test_loss = []\n","total_test_accuracy = []\n","\n","\n","\n","for batch in validation_dataloader:\n","\n","        \n","  # Unpack this training batch from our dataloader. \n","  #\n","  # As we unpack the batch, we'll also copy each tensor to the GPU using \n","  # the `to` method.\n","  #\n","  # `batch` contains three pytorch tensors:\n","  #   [0]: input ids \n","  #   [1]: attention masks\n","  #   [2]: labels \n","  b_input_ids = batch[0].to(device)\n","  b_input_mask = batch[1].to(device)\n","  b_labels = batch[2].to(device)\n","        \n","  # Tell pytorch not to bother with constructing the compute graph during\n","  # the forward pass, since this is only needed for backprop (training).\n","  #with torch.no_grad():        \n","\n","  # Forward pass, calculate logit predictions.\n","  # token_type_ids is the same as the \"segment ids\", which \n","  # differentiates sentence 1 and 2 in 2-sentence tasks.\n","  result = model(b_input_ids, \n","                       token_type_ids=None, \n","                       attention_mask=b_input_mask, \n","                       labels=b_labels,\n","                       return_dict=True)\n","        # Get the loss and \"logits\" output by the model. The \"logits\" are the \n","        # output values prior to applying an activation function like the \n","        # softmax.\n","  loss = result.loss\n","  logits = result.logits\n","        \n","            \n","        # Accumulate the validation loss.\n","  total_test_loss = loss.item()\n","\n","        # Move logits and labels to CPU\n","  logits = logits.detach().cpu().numpy()\n","  label_ids = b_labels.to('cpu').numpy()\n","\n","        # Calculate the accuracy for this batch of test sentences, and\n","        # accumulate it over all batches.\n","  total_test_accuracy = flat_accuracy(logits, label_ids)\n","        \n","\n","    # Report the final accuracy for this validation run.\n","print(\"The total test accuracy is: \")\n","print(total_test_accuracy)\n","print(\"Testing complete!\")"],"execution_count":35,"outputs":[{"output_type":"stream","text":["The total test accuracy is: \n","0.9375\n","Testing complete!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mkyubuJSOzg3"},"source":["##Performance On Test Set"]},{"cell_type":"markdown","metadata":{"id":"Tg42jJqqM68F"},"source":["### Data Preparation\n"]},{"cell_type":"markdown","metadata":{"id":"xWe0_JW21MyV"},"source":["\n","We'll need to apply all of the same steps that we did for the training data to prepare our test data set."]},{"cell_type":"markdown","metadata":{"id":"16lctEOyNFik"},"source":["NOW AFTER TRAINING WE FINALLY CALCULATE THE ACCURACY ON THE RESERVED 100% DATASET"]},{"cell_type":"markdown","metadata":{"id":"rhR99IISNMg9"},"source":["*italicized text*\n","With the test set prepared, we can apply our fine-tuned model to generate predictions on the test set."]},{"cell_type":"code","metadata":{"id":"SVuaPBtNDlj1","executionInfo":{"status":"ok","timestamp":1621048573191,"user_tz":-330,"elapsed":1186,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}}},"source":["\n","combinedDF['Label'] = combinedDF['Label'].astype(int, errors = 'raise')\n","sentences3 = combinedDF.Sentence.values\n","labels3 = combinedDF.Label.values"],"execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"id":"ESDPcLjNDmKi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621048576737,"user_tz":-330,"elapsed":2129,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"17e2d7db-42e7-446e-c6be-32f79ee8c971"},"source":["max_len3 = 0\n","\n","# For every sentence...\n","for sent in sentences3:\n","\n","    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n","    input_ids3 = tokenizer.encode(sent, add_special_tokens=True)\n","\n","    # Update the maximum sentence length.\n","    max_len3 = max(max_len3, len(input_ids3))\n","\n","print('Max sentence length: ', max_len3)"],"execution_count":37,"outputs":[{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (1790 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["Max sentence length:  1790\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NOzFdf7EDn3j","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621048580078,"user_tz":-330,"elapsed":2278,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"48c51b03-106b-4913-afc2-e64a157df1db"},"source":["input_ids3 = []\n","attention_masks3 = []\n","\n","# For every sentence...\n","for sent in sentences3:\n","    # `encode_plus` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    #   (5) Pad or truncate the sentence to `max_length`\n","    #   (6) Create attention masks for [PAD] tokens.\n","    encoded_dict3 = tokenizer.encode_plus(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = 64,           # Pad & truncate all sentences.\n","                        pad_to_max_length = True,\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","    \n","    # Add the encoded sentence to the list.    \n","    input_ids3.append(encoded_dict3['input_ids'])\n","    \n","    # And its attention mask (simply differentiates padding from non-padding).\n","    attention_masks3.append(encoded_dict3['attention_mask'])\n","\n","# Convert the lists into tensors.\n","input_ids3 = torch.cat(input_ids3, dim=0)\n","attention_masks3 = torch.cat(attention_masks3, dim=0)\n","labels3 = torch.tensor(labels3)\n","\n","# Print sentence 0, now as a list of IDs.\n","print('Original: ', sentences3[0])\n","print('Token IDs:', input_ids3[0])\n","\n","\n","print(len(sentences3))\n"],"execution_count":38,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Original:  Now I am getting angry and I want my damn pho.\n","Token IDs: tensor([ 101, 2085, 1045, 2572, 2893, 4854, 1998, 1045, 2215, 2026, 4365, 6887,\n","        2080, 1012,  102,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0])\n","2748\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aEFlEYwZDp_D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621048583238,"user_tz":-330,"elapsed":795,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"8df52c00-9e84-4485-c062-a5dcd5d8bb54"},"source":["test_dataset = TensorDataset(input_ids3, attention_masks3, labels3)\n","\n","print(type(input_ids3))        \n","print(type(attention_masks3))\n","print(type(labels3))\n","\n","\n","\n","test_dataloader = DataLoader(        \n","            test_dataset, # The validation samples.\n","            sampler = SequentialSampler(test_dataset), # Pull out batches sequentially.\n","            batch_size = 32 \n","        )\n","\n","\n","print(len(test_dataset))"],"execution_count":39,"outputs":[{"output_type":"stream","text":["<class 'torch.Tensor'>\n","<class 'torch.Tensor'>\n","<class 'torch.Tensor'>\n","2748\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qAS6R3FEDrys","colab":{"base_uri":"https://localhost:8080/","height":120},"executionInfo":{"status":"ok","timestamp":1621048586089,"user_tz":-330,"elapsed":1406,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"8da16495-49d1-442a-de83-51f4d58a9c9e"},"source":["torch.cuda.memory_summary(device=None, abbreviated=False)\n"],"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |    2374 MB |    4421 MB |    3836 GB |    3834 GB |\\n|       from large pool |    2317 MB |    4328 MB |    3793 GB |    3790 GB |\\n|       from small pool |      56 MB |     133 MB |      43 GB |      43 GB |\\n|---------------------------------------------------------------------------|\\n| Active memory         |    2374 MB |    4421 MB |    3836 GB |    3834 GB |\\n|       from large pool |    2317 MB |    4328 MB |    3793 GB |    3790 GB |\\n|       from small pool |      56 MB |     133 MB |      43 GB |      43 GB |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |    4526 MB |    4526 MB |    4526 MB |       0 B  |\\n|       from large pool |    4382 MB |    4382 MB |    4382 MB |       0 B  |\\n|       from small pool |     144 MB |     144 MB |     144 MB |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |  638972 KB |  639324 KB |    3558 GB |    3557 GB |\\n|       from large pool |  612480 KB |  612480 KB |    3507 GB |    3506 GB |\\n|       from small pool |   26492 KB |   47120 KB |      50 GB |      50 GB |\\n|---------------------------------------------------------------------------|\\n| Allocations           |    1259    |    1808    |    1639 K  |    1638 K  |\\n|       from large pool |     544    |     931    |     949 K  |     948 K  |\\n|       from small pool |     715    |     987    |     690 K  |     689 K  |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |    1259    |    1808    |    1639 K  |    1638 K  |\\n|       from large pool |     544    |     931    |     949 K  |     948 K  |\\n|       from small pool |     715    |     987    |     690 K  |     689 K  |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |     307    |     307    |     307    |       0    |\\n|       from large pool |     235    |     235    |     235    |       0    |\\n|       from small pool |      72    |      72    |      72    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |     121    |     177    |    1017 K  |    1017 K  |\\n|       from large pool |      66    |      90    |     689 K  |     689 K  |\\n|       from small pool |      55    |      89    |     328 K  |     328 K  |\\n|===========================================================================|\\n'"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"code","metadata":{"id":"OPQD0agDDtRH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621048600412,"user_tz":-330,"elapsed":12532,"user":{"displayName":"Yash Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gild8Odm0H-eBe0PGDUvXNharCipuIl3350SiqJBw=s64","userId":"02175383882112157218"}},"outputId":"9ec0ac65-a83d-490b-8baa-ec542cd206b5"},"source":["total_test_loss2 = []\n","total_test_accuracy2 = []\n","\n","\n","\n","for batch in test_dataloader:\n","\n","        \n","  # Unpack this training batch from our dataloader. \n","  #\n","  # As we unpack the batch, we'll also copy each tensor to the GPU using \n","  # the `to` method.\n","  #\n","  # `batch` contains three pytorch tensors:\n","  #   [0]: input ids \n","  #   [1]: attention masks\n","  #   [2]: labels \n","  b_input_ids = batch[0].to(device)\n","  b_input_mask = batch[1].to(device)\n","  b_labels = batch[2].to(device)\n","        \n","  # Tell pytorch not to bother with constructing the compute graph during\n","  # the forward pass, since this is only needed for backprop (training).\n","  #with torch.no_grad():        \n","\n","  # Forward pass, calculate logit predictions.\n","  # token_type_ids is the same as the \"segment ids\", which \n","  # differentiates sentence 1 and 2 in 2-sentence tasks.\n","  result = model(b_input_ids, \n","                       token_type_ids=None, \n","                       attention_mask=b_input_mask, \n","                       labels=b_labels,\n","                       return_dict=True)\n","        # Get the loss and \"logits\" output by the model. The \"logits\" are the \n","        # output values prior to applying an activation function like the \n","        # softmax.\n","  loss = result.loss\n","  logits = result.logits\n","        \n","            \n","        # Accumulate the validation loss.\n","  total_test_loss = loss.item()\n","\n","        # Move logits and labels to CPU\n","  logits = logits.detach().cpu().numpy()\n","  label_ids = b_labels.to('cpu').numpy()\n","\n","        # Calculate the accuracy for this batch of test sentences, and\n","        # accumulate it over all batches.\n","  total_test_accuracy = flat_accuracy(logits, label_ids)\n","        \n","\n","    # Report the final accuracy for this validation run.\n","print(\"The total test accuracy is: \")\n","print(total_test_accuracy)\n","print(\"Testing complete!\")"],"execution_count":41,"outputs":[{"output_type":"stream","text":["The total test accuracy is: \n","0.5714285714285714\n","Testing complete!\n"],"name":"stdout"}]}]}