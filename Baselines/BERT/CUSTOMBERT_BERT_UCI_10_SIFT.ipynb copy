{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CUSTOMBERT-BERT-UCI-10%-SIFT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ba014d96571c440192fe189955fd5050": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7f393e1d4b894609aa601c63e589ffe5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5c95c659ea824358805206eac4d13e10",
              "IPY_MODEL_9550e6f25481494dbdf84400731623ac"
            ]
          }
        },
        "7f393e1d4b894609aa601c63e589ffe5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5c95c659ea824358805206eac4d13e10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b3fffa1fcd1348e8a4a5b2e9e12a565a",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_14565757f8f846c3a41e91c7cbd5327e"
          }
        },
        "9550e6f25481494dbdf84400731623ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_73ec22161e734854b95c4839cdad9e41",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 742kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9a276213f31c4e508a58a13cd71ab650"
          }
        },
        "b3fffa1fcd1348e8a4a5b2e9e12a565a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "14565757f8f846c3a41e91c7cbd5327e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "73ec22161e734854b95c4839cdad9e41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9a276213f31c4e508a58a13cd71ab650": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5727715ad7ac4e1b8e40efea2c1f37d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_65c1221d06e64ae896845f40cb66aa0c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b61504885ca64d638c18d863a1e27562",
              "IPY_MODEL_cc169a9c19154ae8b441c38a0cdb2acb"
            ]
          }
        },
        "65c1221d06e64ae896845f40cb66aa0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b61504885ca64d638c18d863a1e27562": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a6f8791df71740e69487f8cbaea98e4b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ef9ea797173844528b67b5d7ff7b5ad1"
          }
        },
        "cc169a9c19154ae8b441c38a0cdb2acb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a27befe4e33b4defb23c10d520f5aacd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 153B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_14e145ee60b34134baea8b66618429ad"
          }
        },
        "a6f8791df71740e69487f8cbaea98e4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ef9ea797173844528b67b5d7ff7b5ad1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a27befe4e33b4defb23c10d520f5aacd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "14e145ee60b34134baea8b66618429ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "43f356ae58d94be59a759036be5d5af6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e529a138d7534ab8b710aee3471ad899",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3e63e30db7ff4581878793753b02fb0f",
              "IPY_MODEL_006f454681f84be6bb4c8d47f0731136"
            ]
          }
        },
        "e529a138d7534ab8b710aee3471ad899": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3e63e30db7ff4581878793753b02fb0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fb246abd98d94c59b27a3d12427dd8bc",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e53cef519d154c93b8229fe95a06f70c"
          }
        },
        "006f454681f84be6bb4c8d47f0731136": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_610d933e9d4b4c44be0e30f444acc323",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:00&lt;00:00, 5.20MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_123eb35a74354e0fb6ac77743021cf00"
          }
        },
        "fb246abd98d94c59b27a3d12427dd8bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e53cef519d154c93b8229fe95a06f70c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "610d933e9d4b4c44be0e30f444acc323": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "123eb35a74354e0fb6ac77743021cf00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b29e48324da34ae19c5304b236233ff6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c6c6e9c64aaf4c32b4a69ae426e6b7b3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_222c66ca8e694e3aba9311c390e8fbb5",
              "IPY_MODEL_e26f6df4067f4b22b11465d8663de213"
            ]
          }
        },
        "c6c6e9c64aaf4c32b4a69ae426e6b7b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "222c66ca8e694e3aba9311c390e8fbb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e8857d4888df4168b548c206763f56ec",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5090e1afb82c41408299d212d70e4f7f"
          }
        },
        "e26f6df4067f4b22b11465d8663de213": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b642454f178d4df28ef4f25ddf8d28e9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [00:09&lt;00:00, 59.9B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bda5ac6758fa44aa95daa38861c27efd"
          }
        },
        "e8857d4888df4168b548c206763f56ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5090e1afb82c41408299d212d70e4f7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b642454f178d4df28ef4f25ddf8d28e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bda5ac6758fa44aa95daa38861c27efd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0a0c82ba64ee417796eb540cfba62540": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6f4648b85a2a4e3f90c6e839cad2e79f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ddd125eede5b4f1bac8af0b28b2e7bec",
              "IPY_MODEL_bc4c6cc1f8c241349a34e3564db9bbb7"
            ]
          }
        },
        "6f4648b85a2a4e3f90c6e839cad2e79f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ddd125eede5b4f1bac8af0b28b2e7bec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c48e89d283c849949b9433de9319416b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7d9e96c52dd0414097fac1a5c083ecb9"
          }
        },
        "bc4c6cc1f8c241349a34e3564db9bbb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f215bdd1b69a460e9d263cd26a80f563",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:09&lt;00:00, 47.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_17a0a2bfe2464e34a3f43dcec63df63f"
          }
        },
        "c48e89d283c849949b9433de9319416b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7d9e96c52dd0414097fac1a5c083ecb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f215bdd1b69a460e9d263cd26a80f563": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "17a0a2bfe2464e34a3f43dcec63df63f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKOTlwcmxmej"
      },
      "source": [
        "# BERT Fine-Tuning on CoLA with UCI and SiFT\n",
        "\n",
        "\n",
        "\n",
        "This notebook is orginally created by Chris McCormick and Nick Ryan. We made changes for SiFT and SMART, as well as our custom BERT class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJKaoairpdRa"
      },
      "source": [
        "##Data and Importing Modules "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEfSbAA4QHas",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bf86acc-e902-4f36-8ad1-b3036b1ad2c7"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYsV4H8fCpZ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f5e5103-1d9d-47c5-c6a6-aa12040128f8"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NmMdkZO8R6q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6afe6c79-e75f-44c0-e0bb-437050424e54"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/9e/5b80becd952d5f7250eaf8fc64b957077b12ccfe73e9c03d37146ab29712/transformers-4.6.0-py3-none-any.whl (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 29.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Collecting huggingface-hub==0.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 47.1MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 34.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (8.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Installing collected packages: huggingface-hub, tokenizers, sacremoses, transformers\n",
            "Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5m6AnuFv0QXQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2457100d-339e-4bf8-b96f-027e3710a8fb"
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp37-none-any.whl size=9681 sha256=892b82e29f1d6f2cd2ad8fb3a807f51e95ec7913902cf2db57a6bdffaa4c4e69\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMtmPMkBzrvs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73ee509c-0ffb-4aaa-f19a-4ee4f2b7918e"
      },
      "source": [
        "#Adding the datasets to the collab file\n",
        "\n",
        "#First we mount the google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Yv-tNv20dnH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e57d3c8a-e9b7-42ae-e9d5-10daf9aa632e"
      },
      "source": [
        "# with open('/content/drive/My Drive/Undergraduate/Courses/MLLU Project/Code/Baseline - Draft Proposal/yelp_labelled.txt', 'r') as f:\n",
        "#   f.write('Successfully opened Yelp Labelled')\n",
        "\n",
        "with open('/content/drive/MyDrive/Undergraduate /Courses /MLLU Project/Code/MLLU : Final Paper Submission Code/yelp_labelled.txt', 'r') as y:\n",
        "  print(\"Successfully Opened Yelp\")\n",
        "\n",
        "\n",
        "with open('/content/drive/MyDrive/Undergraduate /Courses /MLLU Project/Code/MLLU : Final Paper Submission Code/amazon_cells_labelled.txt', 'r') as a:\n",
        "  print(\"Successfully Opened Amazon Labelled\")\n",
        "\n",
        "\n",
        "\n",
        "with open('/content/drive/MyDrive/Undergraduate /Courses /MLLU Project/Code/MLLU : Final Paper Submission Code/imdb_labelled.txt', 'r') as i:\n",
        "  print(\"Successfully Opened IMDB Labelled\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully Opened Yelp\n",
            "Successfully Opened Amazon Labelled\n",
            "Successfully Opened IMDB Labelled\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UkeC7SG2krJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a0b4338-2981-40ee-e2cb-071757f1c2fe"
      },
      "source": [
        "#Checking on the Yelp Dataframe\n",
        "import pandas as pd\n",
        "df1_yelp = pd.read_csv('/content/drive/MyDrive/Undergraduate /Courses /MLLU Project/Code/MLLU : Final Paper Submission Code/yelp_labelled.txt', delimiter = '\\t', delim_whitespace= False, names = ('Sentence', 'Label'))\n",
        "df1_yelp.head()\n",
        "\n",
        "print(df1_yelp.info())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   Sentence  1000 non-null   object\n",
            " 1   Label     1000 non-null   int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 15.8+ KB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-0v9aKSCWVg",
        "outputId": "343c95ab-9ebb-4369-b9bd-ec780a17c3ff"
      },
      "source": [
        "\n",
        "#Similarly for the dataframes for Amazon and IMDB\n",
        "df1_amazon = pd.read_csv('/content/drive/MyDrive/Undergraduate /Courses /MLLU Project/Code/MLLU : Final Paper Submission Code/amazon_cells_labelled.txt', delimiter = '\\t', delim_whitespace= False, names = ('Sentence', 'Label'))\n",
        "df1_amazon.head()\n",
        "print(df1_amazon.info())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   Sentence  1000 non-null   object\n",
            " 1   Label     1000 non-null   int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 15.8+ KB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wPamOpWCYhk",
        "outputId": "633352e5-a41c-48be-b8e2-c3bf9edeca9c"
      },
      "source": [
        "df1_imdb = pd.read_csv('/content/drive/MyDrive/Undergraduate /Courses /MLLU Project/Code/MLLU : Final Paper Submission Code/imdb_labelled.txt', delimiter = '\\t', delim_whitespace= False, names = ('Sentence', 'Label'))\n",
        "df1_imdb.head()\n",
        "print(df1_imdb.info())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 748 entries, 0 to 747\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   Sentence  748 non-null    object\n",
            " 1   Label     748 non-null    int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 11.8+ KB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blqIvQaQncdJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "outputId": "3d20ccff-3436-4ab7-870a-4104834025c0"
      },
      "source": [
        "\n",
        "combinedDF = pd.concat([df1_imdb, df1_amazon, df1_yelp], axis = 0, join = 'inner')\n",
        "combinedDF.head()\n",
        "combinedDF.info()\n",
        "combinedDF.head(10)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 2748 entries, 0 to 999\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   Sentence  2748 non-null   object\n",
            " 1   Label     2748 non-null   int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 64.4+ KB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Not sure who was more lost - the flat characte...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Very little music or anything to speak of.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The best scene in the movie was when Gerardo i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>The rest of the movie lacks art, charm, meanin...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Wasted two hours.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Saw the movie today and thought it was a good ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>A bit predictable.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Loved the casting of Jimmy Buffet as the scien...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Sentence  Label\n",
              "0  A very, very, very slow-moving, aimless movie ...      0\n",
              "1  Not sure who was more lost - the flat characte...      0\n",
              "2  Attempting artiness with black & white and cle...      0\n",
              "3       Very little music or anything to speak of.        0\n",
              "4  The best scene in the movie was when Gerardo i...      1\n",
              "5  The rest of the movie lacks art, charm, meanin...      0\n",
              "6                                Wasted two hours.        0\n",
              "7  Saw the movie today and thought it was a good ...      1\n",
              "8                               A bit predictable.        0\n",
              "9  Loved the casting of Jimmy Buffet as the scien...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "qaDK92pbCfZZ",
        "outputId": "a3cd4ff8-bd74-4150-91a0-eece6fd6d60b"
      },
      "source": [
        "combinedDF = combinedDF.sample(frac = 1).reset_index(drop = True)\n",
        "combinedDF = combinedDF.dropna()\n",
        "combinedDF.info()\n",
        "combinedDF.head(10)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 2748 entries, 0 to 2747\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   Sentence  2748 non-null   object\n",
            " 1   Label     2748 non-null   int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 64.4+ KB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Cinematography: The film was shot in an intere...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The plantains were the worst I've ever tasted.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Comfortable fit - you need your headset to be ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I wasn't really impressed with Strip Steak.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>good protection and does not make phone too bu...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>I came back today since they relocated and sti...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Highly recommended A+</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>All the bread is made in-house!</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>The battery runs down quickly.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>The food was terrible.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Sentence  Label\n",
              "0  Cinematography: The film was shot in an intere...      1\n",
              "1     The plantains were the worst I've ever tasted.      0\n",
              "2  Comfortable fit - you need your headset to be ...      1\n",
              "3        I wasn't really impressed with Strip Steak.      0\n",
              "4  good protection and does not make phone too bu...      1\n",
              "5  I came back today since they relocated and sti...      0\n",
              "6                            Highly recommended A+        1\n",
              "7                    All the bread is made in-house!      1\n",
              "8                     The battery runs down quickly.      0\n",
              "9                             The food was terrible.      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuE5BqICAne2"
      },
      "source": [
        "df1_twitter = pd.read_csv('/content/drive/MyDrive/Undergraduate /Courses /MLLU Project/Code/MLLU : Final Paper Submission Code/train.csv', names = ('Label', 'Sentence'))\n",
        "df1_twitter = df1_twitter.iloc[1:4000]\n",
        "\n",
        "df1_twitter['Label'] = df1_twitter['Label'].astype(int, errors = 'raise')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XcD3h68Ck7v",
        "outputId": "4551e510-2e52-4025-f19d-f3a04b8fbd1d"
      },
      "source": [
        "df1_twitter.head()\n",
        "df1_twitter.info()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 3999 entries, 1 to 3999\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   Label     3999 non-null   int64 \n",
            " 1   Sentence  3999 non-null   object\n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 93.7+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykLveVUNCneG",
        "outputId": "1d6b1f54-677d-43bd-9cad-03e38f1d1e31"
      },
      "source": [
        "df1_twitter.head(10)\n",
        "sentences = df1_twitter.Sentence.values\n",
        "labels = df1_twitter.Label.values\n",
        "\n",
        "print(type(labels[0]))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.int64'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFSJzwI5pujc"
      },
      "source": [
        "## Tokenization and DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z474sSC6oe7A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181,
          "referenced_widgets": [
            "ba014d96571c440192fe189955fd5050",
            "7f393e1d4b894609aa601c63e589ffe5",
            "5c95c659ea824358805206eac4d13e10",
            "9550e6f25481494dbdf84400731623ac",
            "b3fffa1fcd1348e8a4a5b2e9e12a565a",
            "14565757f8f846c3a41e91c7cbd5327e",
            "73ec22161e734854b95c4839cdad9e41",
            "9a276213f31c4e508a58a13cd71ab650",
            "5727715ad7ac4e1b8e40efea2c1f37d7",
            "65c1221d06e64ae896845f40cb66aa0c",
            "b61504885ca64d638c18d863a1e27562",
            "cc169a9c19154ae8b441c38a0cdb2acb",
            "a6f8791df71740e69487f8cbaea98e4b",
            "ef9ea797173844528b67b5d7ff7b5ad1",
            "a27befe4e33b4defb23c10d520f5aacd",
            "14e145ee60b34134baea8b66618429ad",
            "43f356ae58d94be59a759036be5d5af6",
            "e529a138d7534ab8b710aee3471ad899",
            "3e63e30db7ff4581878793753b02fb0f",
            "006f454681f84be6bb4c8d47f0731136",
            "fb246abd98d94c59b27a3d12427dd8bc",
            "e53cef519d154c93b8229fe95a06f70c",
            "610d933e9d4b4c44be0e30f444acc323",
            "123eb35a74354e0fb6ac77743021cf00"
          ]
        },
        "outputId": "6530eb97-b6e9-44ed-b442-a62aafed0345"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ba014d96571c440192fe189955fd5050",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5727715ad7ac4e1b8e40efea2c1f37d7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "43f356ae58d94be59a759036be5d5af6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLIbudgfh6F0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6eae029-0f4c-4cfd-83ad-fe0dd7eea59a"
      },
      "source": [
        "print(' Original: ', sentences[0])\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:   @user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run\n",
            "Tokenized:  ['@', 'user', 'when', 'a', 'father', 'is', 'dysfunction', '##al', 'and', 'is', 'so', 'selfish', 'he', 'drag', '##s', 'his', 'kids', 'into', 'his', 'dysfunction', '.', '#', 'run']\n",
            "Token IDs:  [1030, 5310, 2043, 1037, 2269, 2003, 28466, 2389, 1998, 2003, 2061, 14337, 2002, 8011, 2015, 2010, 4268, 2046, 2010, 28466, 1012, 1001, 2448]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKsH2sU0OCQA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ac24c0e-ce41-4835-b462-c971374e9984"
      },
      "source": [
        "max_len = 0\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "\n",
        "    # Update the maximum sentence length.\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "\n",
        "\n",
        "print(len(sentences))\n",
        "print('Max sentence length: ', max_len)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3999\n",
            "Max sentence length:  76\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bBdb3pt8LuQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0ac8215-c167-44b4-fd05-a4cbb270dfee"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 32,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:   @user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run\n",
            "Token IDs: tensor([  101,  1030,  5310,  2043,  1037,  2269,  2003, 28466,  2389,  1998,\n",
            "         2003,  2061, 14337,  2002,  8011,  2015,  2010,  4268,  2046,  2010,\n",
            "        28466,  1012,  1001,  2448,   102,     0,     0,     0,     0,     0,\n",
            "            0,     0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEgLpFVlo1Z-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdbdc3f4-47b8-4e33-a514-db9b3baf0953"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "print(type(input_ids))\n",
        "print(type(attention_masks))\n",
        "print(type(labels))\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "3,599 training samples\n",
            "  400 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGUqOCtgqGhP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60152b32-4d62-432e-db1a-9997055a9ebd"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. \n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )\n",
        "\n",
        "\n",
        "print(\"hi\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73S4P4SMp6hX"
      },
      "source": [
        "## Custom Bert Class and Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOteWAT-Adqx"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig, BertPreTrainedModel, BertModel\n",
        "from transformers.models.bert.modeling_bert import BertEmbeddings,BertEncoder,BertPooler\n",
        "from transformers.modeling_outputs import BaseModelOutputWithPoolingAndCrossAttentions\n",
        "\n",
        "import torch\n",
        "import torch.utils.checkpoint\n",
        "from torch import nn\n",
        "from torch.nn import CrossEntropyLoss, MSELoss\n",
        "\n",
        "class CustomBertForClassification(BertForSequenceClassification):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        #self.bert = BertForSequenceClassification(config).from_pretrained(\"bert-base-uncased\",num_labels = 2,output_attentions = False, output_hidden_states = False)\n",
        "        self.embeddings = self.bert.embeddings\n",
        "        self.encoder = self.bert.encoder\n",
        "        self.pooler = self.bert.pooler\n",
        "\n",
        "    def embed(self, input_ids=None, \n",
        "                    token_type_ids=None, \n",
        "                    position_ids=None, \n",
        "                    inputs_embeds=None, \n",
        "                    past_key_values_length=0):\n",
        "        # See: BERTModel.forward\n",
        "        return self.embeddings(\n",
        "            input_ids=input_ids,\n",
        "            position_ids=position_ids,\n",
        "            token_type_ids=token_type_ids,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            past_key_values_length=past_key_values_length\n",
        "        )\n",
        "    \n",
        "    def predict(self,embedding_output,\n",
        "                extended_attention_mask=None,\n",
        "                head_mask=None,\n",
        "                encoder_hidden_states=None,\n",
        "                encoder_extended_attention_mask=None,\n",
        "                past_key_values=None,\n",
        "                use_cache=None,\n",
        "                output_attentions=None,\n",
        "                output_hidden_states=None,\n",
        "                return_dict=True):\n",
        "      # See: BERTModel.forward \n",
        "        encoder_outputs = self.encoder(\n",
        "            embedding_output,\n",
        "            attention_mask=extended_attention_mask,\n",
        "            head_mask=head_mask,\n",
        "            encoder_hidden_states=encoder_hidden_states,\n",
        "            encoder_attention_mask=encoder_extended_attention_mask,\n",
        "            past_key_values=past_key_values,\n",
        "            use_cache=use_cache,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "\n",
        "        sequence_output = encoder_outputs[0]\n",
        "        pooled_output = self.pooler(sequence_output) if self.pooler is not None else None\n",
        "        \n",
        "        bert_output = BaseModelOutputWithPoolingAndCrossAttentions(\n",
        "                    last_hidden_state=sequence_output,\n",
        "                    pooler_output=pooled_output,\n",
        "                    past_key_values=encoder_outputs.past_key_values,\n",
        "                    hidden_states=encoder_outputs.hidden_states,\n",
        "                    attentions=encoder_outputs.attentions,\n",
        "                    cross_attentions=encoder_outputs.cross_attentions,\n",
        "                )\n",
        "\n",
        "        pooled_output = bert_output[1]\n",
        "\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "        \n",
        "        return logits\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b29e48324da34ae19c5304b236233ff6",
            "c6c6e9c64aaf4c32b4a69ae426e6b7b3",
            "222c66ca8e694e3aba9311c390e8fbb5",
            "e26f6df4067f4b22b11465d8663de213",
            "e8857d4888df4168b548c206763f56ec",
            "5090e1afb82c41408299d212d70e4f7f",
            "b642454f178d4df28ef4f25ddf8d28e9",
            "bda5ac6758fa44aa95daa38861c27efd",
            "0a0c82ba64ee417796eb540cfba62540",
            "6f4648b85a2a4e3f90c6e839cad2e79f",
            "ddd125eede5b4f1bac8af0b28b2e7bec",
            "bc4c6cc1f8c241349a34e3564db9bbb7",
            "c48e89d283c849949b9433de9319416b",
            "7d9e96c52dd0414097fac1a5c083ecb9",
            "f215bdd1b69a460e9d263cd26a80f563",
            "17a0a2bfe2464e34a3f43dcec63df63f"
          ]
        },
        "id": "IdNBO5qk2-i_",
        "collapsed": true,
        "outputId": "6c271215-2495-4897-d006-057eb1daec1e"
      },
      "source": [
        "#@title\n",
        "model = CustomBertForClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    num_labels = 2,\n",
        "    output_attentions = False, \n",
        "    output_hidden_states = False, \n",
        ")\n",
        "\n",
        "model.cuda()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b29e48324da34ae19c5304b236233ff6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0a0c82ba64ee417796eb540cfba62540",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing CustomBertForClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing CustomBertForClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing CustomBertForClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of CustomBertForClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['encoder.layer.3.attention.output.dense.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.8.output.dense.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.6.attention.self.value.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.bias', 'pooler.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.4.output.dense.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.1.attention.output.dense.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.6.attention.output.dense.bias', 'pooler.dense.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.bias', 'classifier.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.weight', 'classifier.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.2.output.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomBertForClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmSpMRD5qaqE"
      },
      "source": [
        "##Noise Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pG5DszcpDAjw"
      },
      "source": [
        "from torch.nn import LayerNorm\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def normalize_embed(embed):\n",
        "    embed_mean = torch.mean(embed,dim=(1,2))\n",
        "    embed_std = torch.std(embed, dim=(1,2))\n",
        "\n",
        "    embed_clone = torch.clone(embed)\n",
        "\n",
        "    for i in range(0,embed_clone.size()[0]):\n",
        "        # embed_clone[i] = torch.div(torch.sub(embed_clone[i],embed_mean[i]),embed_std[i])\n",
        "        embed_clone[i] = (embed_clone[i] - embed_mean[i]) / embed_std[i]\n",
        "    return embed_clone, embed_mean, embed_std\n",
        "\n",
        "def denormalize_embed(embed, embed_mean, embed_std):\n",
        "    for i in range(0,embed.size()[0]):\n",
        "        # embed[i] = (embed[i] - embed_mean[i]) / embed_std[i]\n",
        "        embed[i] = (embed[i] * embed_std[i]) + embed_mean[i]\n",
        "    return embed \n",
        "\n",
        "def stable_kl(logit, target, epsilon=1e-6, reduce=True):\n",
        "    logit = logit.view(-1, logit.size(-1)).float()\n",
        "    target = target.view(-1, target.size(-1)).float()\n",
        "    bs = logit.size(0)\n",
        "    p = F.log_softmax(logit, 1).exp()\n",
        "    y = F.log_softmax(target, 1).exp()\n",
        "    rp = -(1.0/(p + epsilon) -1 + epsilon).detach().log()\n",
        "    ry = -(1.0/(y + epsilon) -1 + epsilon).detach().log()\n",
        "    if reduce:\n",
        "        return (p* (rp- ry) * 2).sum() / bs\n",
        "    else:\n",
        "        return (p* (rp- ry) * 2).sum()\n",
        "\n",
        "def _norm_grad(grad, epsilon = 1e-6, eff_grad=None, sentence_level=False):\n",
        "        if sentence_level:\n",
        "            direction = grad / (grad.abs().max((-2, -1), keepdim=True)[0] + epsilon)\n",
        "        else:\n",
        "            direction = grad / (grad.abs().max(-1, keepdim=True)[0] + epsilon)\n",
        "            eff_direction = eff_grad / (grad.abs().max(-1, keepdim=True)[0] + epsilon)\n",
        "        return direction, eff_direction\n",
        "\n",
        "def noise(embed, model,step_size, normalize=False, k=1, mean=0, std=0.01):  ## Not including mask in the noise, so it means no mask as input for predict, should be a problem\n",
        "    if normalize == True:\n",
        "        logits = model.predict(embed)#,attention_mask)\n",
        "        # LNorm = LayerNorm(embed.size(),elementwise_affine=False)\n",
        "        # normalized_embed = LNorm(embed)\n",
        "        normalized_embed, embed_mean, embed_std = normalize_embed(embed)\n",
        "\n",
        "        noise = torch.normal(mean=0, std=0.01,size=(normalized_embed.size()[0],normalized_embed.size()[1],normalized_embed.size()[2]))\n",
        "        noise = noise.to(device)\n",
        "        noise.requires_grad_()\n",
        "        noised_normalized_embeddings = normalized_embed+noise\n",
        "        adv_logits = model.predict(noised_normalized_embeddings)#,attention_mask)\n",
        "        adv_loss = stable_kl(adv_logits, logits.detach(), reduce=False)\n",
        "        delta_grad, = torch.autograd.grad(adv_loss, noise, only_inputs=True, retain_graph=False)\n",
        "        norm = delta_grad.norm()\n",
        "        # if (torch.isnan(norm) or torch.isinf(norm)):\n",
        "        #     return 0\n",
        "        eff_delta_grad = delta_grad * step_size\n",
        "        delta_grad = noise + delta_grad * step_size\n",
        "        noise, eff_noise = _norm_grad(delta_grad, eff_grad=eff_delta_grad, sentence_level=0)\n",
        "        noise = noise.detach()\n",
        "        noised_normalized_embeddings = normalized_embed+noise\n",
        "        denormalize_noised_embed = denormalize_embed(noised_normalized_embeddings,embed_mean, embed_std) \n",
        "        return denormalize_noised_embed\n",
        "    else:\n",
        "        logits = model.predict(embed)#,attention_mask)\n",
        "        noise = torch.normal(mean=0, std=0.01,size=(embed.size()[0],embed.size()[1],embed.size()[2]))\n",
        "        noise = noise.to(device)\n",
        "        noise.requires_grad_()\n",
        "        noised_embeddings = embed+noise\n",
        "        adv_logits = model.predict(noised_embeddings)#,attention_mask)\n",
        "        adv_loss = stable_kl(adv_logits, logits.detach(), reduce=False)\n",
        "        delta_grad, = torch.autograd.grad(adv_loss, noise, only_inputs=True, retain_graph=False)\n",
        "        norm = delta_grad.norm()\n",
        "        # if (torch.isnan(norm) or torch.isinf(norm)):\n",
        "        #     return 0\n",
        "        eff_delta_grad = delta_grad * step_size\n",
        "        delta_grad = noise + delta_grad * step_size\n",
        "        noise, eff_noise = _norm_grad(delta_grad, eff_grad=eff_delta_grad, sentence_level=0)\n",
        "        noise = noise.detach()\n",
        "        noised_embeddings = embed+noise\n",
        "        return noised_embeddings"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bunW4qF4qSyZ"
      },
      "source": [
        "## Optimizer, Scheduler, and Some Other Training Prep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLs72DuMODJO"
      },
      "source": [
        "#@title\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5,\n",
        "                  eps = 1e-8 \n",
        "                )"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p0upAhhRiIx"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cQNvaZ9bnyy"
      },
      "source": [
        "#@title\n",
        "import numpy as np\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpt6tR83keZD"
      },
      "source": [
        "#@title\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScjvBSBfHtBc"
      },
      "source": [
        "MODE = \"SIFT\""
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCSpuOXLqor-"
      },
      "source": [
        "##Training Loop with Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6J-FYdx6nFE_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e4ae3ce-952d-4729-bb22-76d8552571c7"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "training_stats = []\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "    total_train_loss = 0\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        model.zero_grad()        \n",
        "\n",
        "        embed = model.embed(input_ids = b_input_ids)\n",
        "        preds = model.predict(embedding_output = embed)#,extended_attention_mask=b_input_mask)   <- Didn't use mask at all, which should be a problem\n",
        "        loss_fct = CrossEntropyLoss()\n",
        "        regular_loss = loss_fct(preds.view(-1,2), b_labels.view(-1))\n",
        "        loss_list = [regular_loss]\n",
        "        if MODE in [\"SMART-adv-only\", \"SIFT\"]:\n",
        "          normalise = True if MODE == \"SIFT\" else False\n",
        "          noised_embeddings = noise(embed, model, 1e-3, normalize=normalise, k=1)\n",
        "          adv_logits = model.predict(embedding_output = noised_embeddings)#,extended_attention_mask = b_input_mask)   <- Didn't use mask at all, which should be a problem\n",
        "\n",
        "          adv_loss = stable_kl(preds.view(-1,2), adv_logits.view(-1,2))\n",
        "          loss_list.append(adv_loss)\n",
        "        loss = sum(loss_list)\n",
        "        # END MODEL\n",
        "        total_train_loss += loss.item()\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "    model.eval()\n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            result = model(b_input_ids, \n",
        "                           token_type_ids=None, \n",
        "                           attention_mask=b_input_mask,\n",
        "                           labels=b_labels,\n",
        "                           return_dict=True)\n",
        "\n",
        "\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)   \n",
        "\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    113.    Elapsed: 0:00:19.\n",
            "  Batch    80  of    113.    Elapsed: 0:00:37.\n",
            "\n",
            "  Average training loss: 0.26\n",
            "  Training epcoh took: 0:00:52\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.95\n",
            "  Validation Loss: 0.14\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    113.    Elapsed: 0:00:19.\n",
            "  Batch    80  of    113.    Elapsed: 0:00:38.\n",
            "\n",
            "  Average training loss: 0.16\n",
            "  Training epcoh took: 0:00:54\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.96\n",
            "  Validation Loss: 0.12\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    113.    Elapsed: 0:00:20.\n",
            "  Batch    80  of    113.    Elapsed: 0:00:40.\n",
            "\n",
            "  Average training loss: 0.11\n",
            "  Training epcoh took: 0:00:56\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.95\n",
            "  Validation Loss: 0.11\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    113.    Elapsed: 0:00:20.\n",
            "  Batch    80  of    113.    Elapsed: 0:00:40.\n",
            "\n",
            "  Average training loss: 0.10\n",
            "  Training epcoh took: 0:00:57\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.96\n",
            "  Validation Loss: 0.11\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:03:43 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQTvJ1vRP7u4"
      },
      "source": [
        "Let's view the summary of the training process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O_NbXFGMukX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "3ace4fc3-8141-4232-845f-49d2555cb92c"
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.26</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0:00:52</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.16</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0:00:54</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.11</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0:00:56</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.10</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0:00:57</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.26         0.14           0.95       0:00:52         0:00:01\n",
              "2               0.16         0.12           0.96       0:00:54         0:00:01\n",
              "3               0.11         0.11           0.95       0:00:56         0:00:01\n",
              "4               0.10         0.11           0.96       0:00:57         0:00:01"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68xreA9JAmG5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "12c0e6e3-5fc4-4675-ba8c-ba4ba4553d7b"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWeYo84kDYZM",
        "outputId": "d0ba9d54-c6a3-4d59-c40b-658ecd692ae8"
      },
      "source": [
        "total_test_loss = []\n",
        "total_test_accuracy = []\n",
        "\n",
        "\n",
        "\n",
        "for batch in validation_dataloader:\n",
        "\n",
        "        \n",
        "  # Unpack this training batch from our dataloader. \n",
        "  #\n",
        "  # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "  # the `to` method.\n",
        "  #\n",
        "  # `batch` contains three pytorch tensors:\n",
        "  #   [0]: input ids \n",
        "  #   [1]: attention masks\n",
        "  #   [2]: labels \n",
        "  b_input_ids = batch[0].to(device)\n",
        "  b_input_mask = batch[1].to(device)\n",
        "  b_labels = batch[2].to(device)\n",
        "        \n",
        "  # Tell pytorch not to bother with constructing the compute graph during\n",
        "  # the forward pass, since this is only needed for backprop (training).\n",
        "  #with torch.no_grad():        \n",
        "\n",
        "  # Forward pass, calculate logit predictions.\n",
        "  # token_type_ids is the same as the \"segment ids\", which \n",
        "  # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "  result = model(b_input_ids, \n",
        "                       token_type_ids=None, \n",
        "                       attention_mask=b_input_mask, \n",
        "                       labels=b_labels,\n",
        "                       return_dict=True)\n",
        "        # Get the loss and \"logits\" output by the model. The \"logits\" are the \n",
        "        # output values prior to applying an activation function like the \n",
        "        # softmax.\n",
        "  loss = result.loss\n",
        "  logits = result.logits\n",
        "        \n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "  total_test_loss = loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "  total_test_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "print(\"The total test accuracy is: \")\n",
        "print(total_test_accuracy)\n",
        "print(\"Testing complete!\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The total test accuracy is: \n",
            "0.9375\n",
            "Testing complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8437NqbK1jW"
      },
      "source": [
        "## Now we train again on the 10% of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0QDoTejKsh8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98f16511-ca55-4b23-e741-2975ec18db4b"
      },
      "source": [
        "df1_split_10_percent_test = combinedDF.iloc[:874, :]\n",
        "df1_split_10_percent_train = combinedDF.iloc[875:, :]\n",
        "\n",
        "df1_split_10_percent_test.head(10)\n",
        "df1_split_10_percent_test.info()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 874 entries, 0 to 873\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   Sentence  874 non-null    object\n",
            " 1   Label     874 non-null    int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 20.5+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4t39sosALJzY",
        "outputId": "9f51653b-5727-4d97-f957-8d60ecab3cc1"
      },
      "source": [
        "sentences2 = df1_split_10_percent_train.Sentence.values\n",
        "labels2 = df1_split_10_percent_train.Label.values\n",
        "\n",
        "\n",
        "print(len(sentences2))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1873\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEjOUeatLNef",
        "outputId": "b164518d-5a6e-4f9f-ec51-f9461398fa21"
      },
      "source": [
        "max_len3 = 0\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences2:\n",
        "\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    input_ids2 = tokenizer.encode(sent, add_special_tokens=True)\n",
        "\n",
        "    # Update the maximum sentence length.\n",
        "    max_len3 = max(max_len3, len(input_ids2))\n",
        "\n",
        "print('Max sentence length: ', max_len3)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1790 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  1790\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EE-ob1BfLTbc",
        "outputId": "31be1a01-eb73-44aa-987b-ea04270499c2"
      },
      "source": [
        "input_ids2 = []\n",
        "attention_masks2 = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences2:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict2 = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 64,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids2.append(encoded_dict2['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks2.append(encoded_dict2['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids2 = torch.cat(input_ids2, dim=0)\n",
        "attention_masks2 = torch.cat(attention_masks2, dim=0)\n",
        "labels2 = torch.tensor(labels2)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences2[0])\n",
        "print('Token IDs:', input_ids2[0])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:  Superb Phone on a Great Network.\n",
            "Token IDs: tensor([  101, 21688,  3042,  2006,  1037,  2307,  2897,  1012,   102,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTixsk10LWg9",
        "outputId": "307a04e7-1a88-4f50-d78f-cc892207dc2e"
      },
      "source": [
        "train2_dataset = TensorDataset(input_ids2, attention_masks2, labels2)\n",
        "\n",
        "print(type(input_ids2))\n",
        "print(type(attention_masks2))\n",
        "print(type(labels2))\n",
        "\n",
        "\n",
        "\n",
        "train2_dataloader = DataLoader(\n",
        "            train2_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(train2_dataset), # Pull out batches sequentially.\n",
        "            batch_size = 16 # Evaluate with this batch size.\n",
        "        )\n",
        "\n",
        "\n",
        "print(len(train2_dataset))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "1873\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zl8_ePZeNs23"
      },
      "source": [
        "optimizer2 = AdamW(model.parameters(),\n",
        "                  lr = 2e-4,\n",
        "                  eps = 1e-8 \n",
        "                )"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9suBzLFLYfq",
        "outputId": "7e6b2ff2-5e73-4a74-cdfa-dbdd00fe0351"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "training_stats = []\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "    total_train_loss = 0\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train2_dataloader):\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        model.zero_grad()        \n",
        "\n",
        "        embed = model.embed(input_ids = b_input_ids)\n",
        "        preds = model.predict(embedding_output = embed)#,extended_attention_mask=b_input_mask)   <- Didn't use mask at all, which should be a problem\n",
        "        loss_fct = CrossEntropyLoss()\n",
        "        regular_loss = loss_fct(preds.view(-1,2), b_labels.view(-1))\n",
        "        loss_list = [regular_loss]\n",
        "        if MODE in [\"SMART-adv-only\", \"SIFT\"]:\n",
        "          normalise = True if MODE == \"SIFT\" else False\n",
        "          noised_embeddings = noise(embed, model, 1e-3, normalize=normalise, k=1)\n",
        "          adv_logits = model.predict(embedding_output = noised_embeddings)#,extended_attention_mask = b_input_mask)   <- Didn't use mask at all, which should be a problem\n",
        "\n",
        "          adv_loss = stable_kl(preds.view(-1,2), adv_logits.view(-1,2))\n",
        "          loss_list.append(adv_loss)\n",
        "        loss = sum(loss_list)\n",
        "        # END MODEL\n",
        "        total_train_loss += loss.item()\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer2.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "    model.eval()\n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            result = model(b_input_ids, \n",
        "                           token_type_ids=None, \n",
        "                           attention_mask=b_input_mask,\n",
        "                           labels=b_labels,\n",
        "                           return_dict=True)\n",
        "\n",
        "\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)   \n",
        "\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    113.    Elapsed: 0:00:21.\n",
            "  Batch    80  of    113.    Elapsed: 0:00:41.\n",
            "\n",
            "  Average training loss: 0.77\n",
            "  Training epcoh took: 0:01:00\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.61\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    113.    Elapsed: 0:00:20.\n",
            "  Batch    80  of    113.    Elapsed: 0:00:41.\n",
            "\n",
            "  Average training loss: 0.74\n",
            "  Training epcoh took: 0:01:00\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.63\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    113.    Elapsed: 0:00:20.\n",
            "  Batch    80  of    113.    Elapsed: 0:00:41.\n",
            "\n",
            "  Average training loss: 0.74\n",
            "  Training epcoh took: 0:01:00\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.66\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    113.    Elapsed: 0:00:21.\n",
            "  Batch    80  of    113.    Elapsed: 0:00:41.\n",
            "\n",
            "  Average training loss: 0.74\n",
            "  Training epcoh took: 0:01:00\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.62\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:04:03 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrjE4ZInLODI"
      },
      "source": [
        "# Final Test on the rest of the UCI Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVuaPBtNDlj1"
      },
      "source": [
        "\n",
        "combinedDF['Label'] = combinedDF['Label'].astype(int, errors = 'raise')\n",
        "sentences3 = df1_split_10_percent_test.Sentence.values\n",
        "labels3 = df1_split_10_percent_test.Label.values"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESDPcLjNDmKi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abad82a2-cc2b-434e-ecd8-d15fc196375e"
      },
      "source": [
        "max_len3 = 0\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences3:\n",
        "\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    input_ids3 = tokenizer.encode(sent, add_special_tokens=True)\n",
        "\n",
        "    # Update the maximum sentence length.\n",
        "    max_len3 = max(max_len3, len(input_ids3))\n",
        "\n",
        "print('Max sentence length: ', max_len3)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  379\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOzFdf7EDn3j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60ae59dc-3aa4-4973-c765-d15a3d535068"
      },
      "source": [
        "input_ids3 = []\n",
        "attention_masks3 = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences3:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict3 = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 64,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids3.append(encoded_dict3['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks3.append(encoded_dict3['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids3 = torch.cat(input_ids3, dim=0)\n",
        "attention_masks3 = torch.cat(attention_masks3, dim=0)\n",
        "labels3 = torch.tensor(labels3)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences3[0])\n",
        "print('Token IDs:', input_ids3[0])\n",
        "\n",
        "\n",
        "print(len(sentences3))\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:  Cinematography: The film was shot in an interesting way.  \n",
            "Token IDs: tensor([  101, 16434,  1024,  1996,  2143,  2001,  2915,  1999,  2019,  5875,\n",
            "         2126,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0])\n",
            "874\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEFlEYwZDp_D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c26d611f-11b6-4862-f524-b033d84520d7"
      },
      "source": [
        "test_dataset = TensorDataset(input_ids3, attention_masks3, labels3)\n",
        "\n",
        "print(type(input_ids3))        \n",
        "print(type(attention_masks3))\n",
        "print(type(labels3))\n",
        "\n",
        "\n",
        "\n",
        "test_dataloader = DataLoader(        \n",
        "            test_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(test_dataset), # Pull out batches sequentially.\n",
        "            batch_size = 32 \n",
        "        )\n",
        "\n",
        "\n",
        "print(len(test_dataset))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "874\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAS6R3FEDrys",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "90a4c610-fcc0-4446-e5b7-9b9d2d394fe5"
      },
      "source": [
        "torch.cuda.memory_summary(device=None, abbreviated=False)\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |    2634 MB |    5826 MB |    7969 GB |    7967 GB |\\n|       from large pool |    2586 MB |    5690 MB |    7861 GB |    7859 GB |\\n|       from small pool |      47 MB |     186 MB |     108 GB |     108 GB |\\n|---------------------------------------------------------------------------|\\n| Active memory         |    2634 MB |    5826 MB |    7969 GB |    7967 GB |\\n|       from large pool |    2586 MB |    5690 MB |    7861 GB |    7859 GB |\\n|       from small pool |      47 MB |     186 MB |     108 GB |     108 GB |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |    6144 MB |    6144 MB |    6144 MB |       0 B  |\\n|       from large pool |    5950 MB |    5950 MB |    5950 MB |       0 B  |\\n|       from small pool |     194 MB |     194 MB |     194 MB |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |  513720 KB |  711319 KB |    7387 GB |    7387 GB |\\n|       from large pool |  456288 KB |  656992 KB |    7242 GB |    7242 GB |\\n|       from small pool |   57432 KB |   74562 KB |     144 GB |     144 GB |\\n|---------------------------------------------------------------------------|\\n| Allocations           |    1463    |    2449    |    3437 K  |    3436 K  |\\n|       from large pool |     450    |    1205    |    1931 K  |    1931 K  |\\n|       from small pool |    1013    |    1704    |    1506 K  |    1505 K  |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |    1463    |    2449    |    3437 K  |    3436 K  |\\n|       from large pool |     450    |    1205    |    1931 K  |    1931 K  |\\n|       from small pool |    1013    |    1704    |    1506 K  |    1505 K  |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |     418    |     418    |     418    |       0    |\\n|       from large pool |     321    |     321    |     321    |       0    |\\n|       from small pool |      97    |      97    |      97    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |     186    |     280    |    1967 K  |    1967 K  |\\n|       from large pool |      96    |     176    |    1244 K  |    1244 K  |\\n|       from small pool |      90    |     114    |     723 K  |     723 K  |\\n|===========================================================================|\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPQD0agDDtRH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec39cf36-7468-497a-b4e7-313b82821fae"
      },
      "source": [
        "total_test_loss2 = []\n",
        "total_test_accuracy2 = []\n",
        "\n",
        "\n",
        "\n",
        "for batch in test_dataloader:\n",
        "\n",
        "        \n",
        "  # Unpack this training batch from our dataloader. \n",
        "  #\n",
        "  # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "  # the `to` method.\n",
        "  #\n",
        "  # `batch` contains three pytorch tensors:\n",
        "  #   [0]: input ids \n",
        "  #   [1]: attention masks\n",
        "  #   [2]: labels \n",
        "  b_input_ids = batch[0].to(device)\n",
        "  b_input_mask = batch[1].to(device)\n",
        "  b_labels = batch[2].to(device)\n",
        "        \n",
        "  # Tell pytorch not to bother with constructing the compute graph during\n",
        "  # the forward pass, since this is only needed for backprop (training).\n",
        "  #with torch.no_grad():        \n",
        "\n",
        "  # Forward pass, calculate logit predictions.\n",
        "  # token_type_ids is the same as the \"segment ids\", which \n",
        "  # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "  result = model(b_input_ids, \n",
        "                       token_type_ids=None, \n",
        "                       attention_mask=b_input_mask, \n",
        "                       labels=b_labels,\n",
        "                       return_dict=True)\n",
        "        # Get the loss and \"logits\" output by the model. The \"logits\" are the \n",
        "        # output values prior to applying an activation function like the \n",
        "        # softmax.\n",
        "  loss = result.loss\n",
        "  logits = result.logits\n",
        "        \n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "  total_test_loss = loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "  total_test_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "print(\"The total test accuracy is: \")\n",
        "print(total_test_accuracy)\n",
        "print(\"Testing complete!\")"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The total test accuracy is: \n",
            "0.8\n",
            "Testing complete!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}