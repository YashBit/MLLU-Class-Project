{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CUSTOMDEBERTA-UCI-ZEROSHOT-SMART.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "93f6503d282e4c2cbe24ed014afd9934": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_963ac1974699480bbfcb7252c4dc7db3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_313fc9ccca5d4ecdad092e487022e0f0",
              "IPY_MODEL_57a6abad11b64703aafe7c64fe43868b"
            ]
          }
        },
        "963ac1974699480bbfcb7252c4dc7db3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "313fc9ccca5d4ecdad092e487022e0f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_da6c91c83f4f401f8a9bbfe1830b14a3",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 898825,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 898825,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_95d8d92e3220432aad0ac130b1adba09"
          }
        },
        "57a6abad11b64703aafe7c64fe43868b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5c700b8a874540c39762fdc0c111de4f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 899k/899k [00:00&lt;00:00, 2.18MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8e1676d6cb8b430f90cd11e608cc0ca1"
          }
        },
        "da6c91c83f4f401f8a9bbfe1830b14a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "95d8d92e3220432aad0ac130b1adba09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5c700b8a874540c39762fdc0c111de4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8e1676d6cb8b430f90cd11e608cc0ca1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b9e6f3325ebf4363b648e77b00c7727b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a2dd6a5a28954da8b79c6e0ea341d2dd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ae156569b7bc43f0a2965febaf07cce8",
              "IPY_MODEL_79fc791ad14a4e46baf4f42babd1aebe"
            ]
          }
        },
        "a2dd6a5a28954da8b79c6e0ea341d2dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ae156569b7bc43f0a2965febaf07cce8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3b7c3925f58b4fdba4070979e677e7b2",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b60b7bd1d7254279b60a29f29eb83d84"
          }
        },
        "79fc791ad14a4e46baf4f42babd1aebe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8108a5e920bd4509bb6aa2d9dd513392",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:00&lt;00:00, 1.67MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_aa590382ae464121b8ae982203746026"
          }
        },
        "3b7c3925f58b4fdba4070979e677e7b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b60b7bd1d7254279b60a29f29eb83d84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8108a5e920bd4509bb6aa2d9dd513392": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "aa590382ae464121b8ae982203746026": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4ff9986d2e8d4104bbe0acf716385dd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7f348a0652404f4c928a21c46875eda7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f6e87609660d470d9eac802f08e653ea",
              "IPY_MODEL_840115bceb074778bcbf0aaa1cc767f9"
            ]
          }
        },
        "7f348a0652404f4c928a21c46875eda7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f6e87609660d470d9eac802f08e653ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cdd46f8e886844d489284432611c25d2",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 52,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 52,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_88680717c5324a0db7fd9a8ab577b5d6"
          }
        },
        "840115bceb074778bcbf0aaa1cc767f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d454229d5aad410ea4f3df61cb747ae1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 52.0/52.0 [00:00&lt;00:00, 493B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f2d68e57fe9b4af2a2006befb9c52a8a"
          }
        },
        "cdd46f8e886844d489284432611c25d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "88680717c5324a0db7fd9a8ab577b5d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d454229d5aad410ea4f3df61cb747ae1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f2d68e57fe9b4af2a2006befb9c52a8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4e11b9060e264692b6c0dad2e95f974c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a5c4b8192eb4415ba42f6f514593ab26",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3e9a310f59b0419c9f4ee5c3c53b1735",
              "IPY_MODEL_df1ecb1fac494b4d95331db4d8cb63f1"
            ]
          }
        },
        "a5c4b8192eb4415ba42f6f514593ab26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3e9a310f59b0419c9f4ee5c3c53b1735": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_16a1ed478b584fbea7a4c81802e922f4",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 474,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 474,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6d791e14800f4c38a65c15226f0d8a21"
          }
        },
        "df1ecb1fac494b4d95331db4d8cb63f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_64b332c297284f54b4c0a238740f9dce",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 474/474 [00:12&lt;00:00, 37.6B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_efbc95b409594974a4dca771381d8d9d"
          }
        },
        "16a1ed478b584fbea7a4c81802e922f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6d791e14800f4c38a65c15226f0d8a21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "64b332c297284f54b4c0a238740f9dce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "efbc95b409594974a4dca771381d8d9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "35f4785c21174786ab0a81e8a23a2920": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_34ea33cdd46442839d1a262584cb2f7d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2937237979fe4ddb996ca25c13a39694",
              "IPY_MODEL_5fbb564ff30e4e1db291d09046c07afd"
            ]
          }
        },
        "34ea33cdd46442839d1a262584cb2f7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2937237979fe4ddb996ca25c13a39694": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b31d1c7b14c9404ca3fe1b1a595e0c6e",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 558582766,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 558582766,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e8a6f3629e1242799da4bab36d4b0672"
          }
        },
        "5fbb564ff30e4e1db291d09046c07afd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a0fa54ef9d5947cd93ce361d25dfa41f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 559M/559M [00:11&lt;00:00, 47.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cf86d47d8ac5410da90b044e5bbc2009"
          }
        },
        "b31d1c7b14c9404ca3fe1b1a595e0c6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e8a6f3629e1242799da4bab36d4b0672": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a0fa54ef9d5947cd93ce361d25dfa41f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cf86d47d8ac5410da90b044e5bbc2009": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKOTlwcmxmej"
      },
      "source": [
        "# DEBERTA Fine-Tuning on CoLA with SMART and SiFT\n",
        "\n",
        "This notebook is orginally created by Chris McCormick and Nick Ryan. We made changes for SiFT and SMART, as well as our custom BERT class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJKaoairpdRa"
      },
      "source": [
        "##Data and Importing Modules "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEfSbAA4QHas",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4985f4eb-3cd1-40e0-c3d4-f37f4b768642"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYsV4H8fCpZ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6b0f5de-0cd2-4145-fa69-d8fcfc898832"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NmMdkZO8R6q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a13ef122-df6c-4c55-f3be-bd6657dc5a90"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/9e/5b80becd952d5f7250eaf8fc64b957077b12ccfe73e9c03d37146ab29712/transformers-4.6.0-py3-none-any.whl (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 30.7MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 37.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Collecting huggingface-hub==0.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 46.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (8.0.0)\n",
            "Installing collected packages: tokenizers, huggingface-hub, sacremoses, transformers\n",
            "Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5m6AnuFv0QXQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd2b71e8-2a21-492e-b557-55cc3a803a0f"
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp37-none-any.whl size=9681 sha256=c69248b0eda8043f473b456aa39b4c0c9850808bf22638703c3652b2a45d5859\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMtmPMkBzrvs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7a1dcdf-6d40-4a22-8740-8fbd011d1368"
      },
      "source": [
        "#Adding the datasets to the collab file\n",
        "\n",
        "#First we mount the google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Yv-tNv20dnH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bb33c1b-51b4-4af0-f502-4ec7c6520d34"
      },
      "source": [
        "# with open('/content/drive/My Drive/Undergraduate/Courses/MLLU Project/Code/Baseline - Draft Proposal/yelp_labelled.txt', 'r') as f:\n",
        "#   f.write('Successfully opened Yelp Labelled')\n",
        "\n",
        "with open('/content/drive/MyDrive/Undergraduate /Courses /MLLU Project/Code/MLLU : Final Paper Submission Code/yelp_labelled.txt', 'r') as y:\n",
        "  print(\"Successfully Opened Yelp\")\n",
        "\n",
        "\n",
        "with open('/content/drive/MyDrive/Undergraduate /Courses /MLLU Project/Code/MLLU : Final Paper Submission Code/amazon_cells_labelled.txt', 'r') as a:\n",
        "  print(\"Successfully Opened Amazon Labelled\")\n",
        "\n",
        "\n",
        "\n",
        "with open('/content/drive/MyDrive/Undergraduate /Courses /MLLU Project/Code/MLLU : Final Paper Submission Code/imdb_labelled.txt', 'r') as i:\n",
        "  print(\"Successfully Opened IMDB Labelled\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully Opened Yelp\n",
            "Successfully Opened Amazon Labelled\n",
            "Successfully Opened IMDB Labelled\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UkeC7SG2krJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7655abe0-6602-4ebc-c6d0-def566cb27cf"
      },
      "source": [
        "#Checking on the Yelp Dataframe\n",
        "import pandas as pd\n",
        "df1_yelp = pd.read_csv('/content/drive/MyDrive/Undergraduate /Courses /MLLU Project/Code/MLLU : Final Paper Submission Code/yelp_labelled.txt', delimiter = '\\t', delim_whitespace= False, names = ('Sentence', 'Label'))\n",
        "df1_yelp.head()\n",
        "\n",
        "print(df1_yelp.info())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   Sentence  1000 non-null   object\n",
            " 1   Label     1000 non-null   int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 15.8+ KB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-0v9aKSCWVg",
        "outputId": "5899bac9-5db2-4607-b89d-7e6106e6570e"
      },
      "source": [
        "\n",
        "#Similarly for the dataframes for Amazon and IMDB\n",
        "df1_amazon = pd.read_csv('/content/drive/MyDrive/Undergraduate /Courses /MLLU Project/Code/MLLU : Final Paper Submission Code/amazon_cells_labelled.txt', delimiter = '\\t', delim_whitespace= False, names = ('Sentence', 'Label'))\n",
        "df1_amazon.head()\n",
        "print(df1_amazon.info())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   Sentence  1000 non-null   object\n",
            " 1   Label     1000 non-null   int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 15.8+ KB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wPamOpWCYhk",
        "outputId": "5ba2250e-0511-4ef1-a7ee-58d659afb247"
      },
      "source": [
        "df1_imdb = pd.read_csv('/content/drive/MyDrive/Undergraduate /Courses /MLLU Project/Code/MLLU : Final Paper Submission Code/imdb_labelled.txt', delimiter = '\\t', delim_whitespace= False, names = ('Sentence', 'Label'))\n",
        "df1_imdb.head()\n",
        "print(df1_imdb.info())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 748 entries, 0 to 747\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   Sentence  748 non-null    object\n",
            " 1   Label     748 non-null    int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 11.8+ KB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blqIvQaQncdJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "outputId": "c8c573f8-7bc4-4828-a71c-bee270d56321"
      },
      "source": [
        "\n",
        "combinedDF = pd.concat([df1_imdb, df1_amazon, df1_yelp], axis = 0, join = 'inner')\n",
        "combinedDF.head()\n",
        "combinedDF.info()\n",
        "combinedDF.head(10)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 2748 entries, 0 to 999\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   Sentence  2748 non-null   object\n",
            " 1   Label     2748 non-null   int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 64.4+ KB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Not sure who was more lost - the flat characte...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Very little music or anything to speak of.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The best scene in the movie was when Gerardo i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>The rest of the movie lacks art, charm, meanin...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Wasted two hours.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Saw the movie today and thought it was a good ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>A bit predictable.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Loved the casting of Jimmy Buffet as the scien...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Sentence  Label\n",
              "0  A very, very, very slow-moving, aimless movie ...      0\n",
              "1  Not sure who was more lost - the flat characte...      0\n",
              "2  Attempting artiness with black & white and cle...      0\n",
              "3       Very little music or anything to speak of.        0\n",
              "4  The best scene in the movie was when Gerardo i...      1\n",
              "5  The rest of the movie lacks art, charm, meanin...      0\n",
              "6                                Wasted two hours.        0\n",
              "7  Saw the movie today and thought it was a good ...      1\n",
              "8                               A bit predictable.        0\n",
              "9  Loved the casting of Jimmy Buffet as the scien...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "qaDK92pbCfZZ",
        "outputId": "f48f3099-df85-4167-a0ef-9680f6be8174"
      },
      "source": [
        "combinedDF = combinedDF.sample(frac = 1).reset_index(drop = True)\n",
        "combinedDF = combinedDF.dropna()\n",
        "combinedDF.info()\n",
        "combinedDF.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 2748 entries, 0 to 2747\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   Sentence  2748 non-null   object\n",
            " 1   Label     2748 non-null   int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 64.4+ KB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>They really want to make your experience a goo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Whatever prompted such a documentary is beyond...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The case is a flimsy piece of plastic and has ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The real disappointment was our waiter.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hated it.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>The manager was the worst.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Artless camera-work endlessly presents us with...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Very disappointed and wondered how it could be...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>I love that they put their food in nice plasti...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Food was below average.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Sentence  Label\n",
              "0  They really want to make your experience a goo...      1\n",
              "1  Whatever prompted such a documentary is beyond...      0\n",
              "2  The case is a flimsy piece of plastic and has ...      0\n",
              "3            The real disappointment was our waiter.      0\n",
              "4                                        Hated it.        0\n",
              "5                         The manager was the worst.      0\n",
              "6  Artless camera-work endlessly presents us with...      0\n",
              "7  Very disappointed and wondered how it could be...      0\n",
              "8  I love that they put their food in nice plasti...      1\n",
              "9                            Food was below average.      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuE5BqICAne2"
      },
      "source": [
        "df1_twitter = pd.read_csv('/content/drive/MyDrive/Undergraduate /Courses /MLLU Project/Code/MLLU : Final Paper Submission Code/train.csv', names = ('Label', 'Sentence'))\n",
        "df1_twitter = df1_twitter.iloc[1:4000]\n",
        "\n",
        "df1_twitter['Label'] = df1_twitter['Label'].astype(int, errors = 'raise')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XcD3h68Ck7v",
        "outputId": "46f6618d-1000-4ddf-a0b7-88eaa3ef157b"
      },
      "source": [
        "df1_twitter.head()\n",
        "df1_twitter.info()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 3999 entries, 1 to 3999\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   Label     3999 non-null   int64 \n",
            " 1   Sentence  3999 non-null   object\n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 93.7+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykLveVUNCneG",
        "outputId": "d72135c5-2656-4d30-da8d-18348e89d291"
      },
      "source": [
        "df1_twitter.head(10)\n",
        "sentences = df1_twitter.Sentence.values\n",
        "labels = df1_twitter.Label.values\n",
        "\n",
        "print(type(labels[0]))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.int64'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFSJzwI5pujc"
      },
      "source": [
        "## Tokenization and DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z474sSC6oe7A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181,
          "referenced_widgets": [
            "93f6503d282e4c2cbe24ed014afd9934",
            "963ac1974699480bbfcb7252c4dc7db3",
            "313fc9ccca5d4ecdad092e487022e0f0",
            "57a6abad11b64703aafe7c64fe43868b",
            "da6c91c83f4f401f8a9bbfe1830b14a3",
            "95d8d92e3220432aad0ac130b1adba09",
            "5c700b8a874540c39762fdc0c111de4f",
            "8e1676d6cb8b430f90cd11e608cc0ca1",
            "b9e6f3325ebf4363b648e77b00c7727b",
            "a2dd6a5a28954da8b79c6e0ea341d2dd",
            "ae156569b7bc43f0a2965febaf07cce8",
            "79fc791ad14a4e46baf4f42babd1aebe",
            "3b7c3925f58b4fdba4070979e677e7b2",
            "b60b7bd1d7254279b60a29f29eb83d84",
            "8108a5e920bd4509bb6aa2d9dd513392",
            "aa590382ae464121b8ae982203746026",
            "4ff9986d2e8d4104bbe0acf716385dd2",
            "7f348a0652404f4c928a21c46875eda7",
            "f6e87609660d470d9eac802f08e653ea",
            "840115bceb074778bcbf0aaa1cc767f9",
            "cdd46f8e886844d489284432611c25d2",
            "88680717c5324a0db7fd9a8ab577b5d6",
            "d454229d5aad410ea4f3df61cb747ae1",
            "f2d68e57fe9b4af2a2006befb9c52a8a"
          ]
        },
        "outputId": "49e82e78-8b28-4c9a-d09a-9977641474ec"
      },
      "source": [
        "from transformers import DebertaTokenizer\n",
        "print('Loading DeBERTa tokenizer...')\n",
        "tokenizer = DebertaTokenizer.from_pretrained('microsoft/deberta-base', do_lower_case=True)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading DeBERTa tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "93f6503d282e4c2cbe24ed014afd9934",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898825.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b9e6f3325ebf4363b648e77b00c7727b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4ff9986d2e8d4104bbe0acf716385dd2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=52.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLIbudgfh6F0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4410436b-80ba-47c8-f01e-4a88ded77149"
      },
      "source": [
        "print(' Original: ', sentences[0])\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:   @user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run\n",
            "Tokenized:  ['Ġ@', 'user', 'Ġwhen', 'Ġa', 'Ġfather', 'Ġis', 'Ġdysfunctional', 'Ġand', 'Ġis', 'Ġso', 'Ġselfish', 'Ġhe', 'Ġdr', 'ags', 'Ġhis', 'Ġkids', 'Ġinto', 'Ġhis', 'Ġdysfunction', '.', 'Ġ', 'Ġ', 'Ġ#', 'run']\n",
            "Token IDs:  [787, 12105, 77, 10, 1150, 16, 30599, 8, 16, 98, 20462, 37, 12402, 8299, 39, 1159, 88, 39, 26971, 4, 1437, 1437, 849, 2962]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKsH2sU0OCQA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae74878a-7945-4909-dd60-642e7c9ffaab"
      },
      "source": [
        "max_len = 0\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "\n",
        "    # Update the maximum sentence length.\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "\n",
        "\n",
        "print(len(sentences))\n",
        "print('Max sentence length: ', max_len)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3999\n",
            "Max sentence length:  192\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bBdb3pt8LuQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b689d282-116c-428a-f1b7-ec11befab282"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 32,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:   @user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run\n",
            "Token IDs: tensor([    1,   787, 12105,    77,    10,  1150,    16, 30599,     8,    16,\n",
            "           98, 20462,    37, 12402,  8299,    39,  1159,    88,    39, 26971,\n",
            "            4,  1437,  1437,   849,  2962,     2,     0,     0,     0,     0,\n",
            "            0,     0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEgLpFVlo1Z-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba99c0b8-9434-4eec-d9fa-84f517b56f48"
      },
      "source": [
        "\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "print(type(input_ids))\n",
        "print(type(attention_masks))\n",
        "print(type(labels))\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "3,599 training samples\n",
            "  400 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGUqOCtgqGhP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f3ca757-cb8e-4170-b279-588afc4afd3c"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. \n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )\n",
        "\n",
        "\n",
        "print(\"hi\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73S4P4SMp6hX"
      },
      "source": [
        "*italicized text*## Custom DEBerta Class and Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOteWAT-Adqx"
      },
      "source": [
        "from transformers import DebertaForSequenceClassification, AdamW, DebertaConfig, DebertaPreTrainedModel, DebertaModel\n",
        "from transformers.models.deberta.modeling_deberta import *\n",
        "#from transformers.modeling_outputs import BaseModelOutputWithPoolingAndCrossAttentions\n",
        "\n",
        "import torch\n",
        "import torch.utils.checkpoint\n",
        "from torch import nn\n",
        "from torch.nn import CrossEntropyLoss, MSELoss\n",
        "\n",
        "class CustomDebertaForClassification(DebertaForSequenceClassification):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        #self.bert = BertForSequenceClassification(config).from_pretrained(\"bert-base-uncased\",num_labels = 2,output_attentions = False, output_hidden_states = False)\n",
        "        self.embeddings = self.deberta.embeddings\n",
        "        self.encoder = self.deberta.encoder\n",
        "        self.z_steps = 0 #copied from DebertaModel source code\n",
        "\n",
        "\n",
        "    def embed(self, input_ids=None, \n",
        "                    mask=None,\n",
        "                    token_type_ids=None, \n",
        "                    position_ids=None, \n",
        "                    inputs_embeds=None\n",
        "                    ):\n",
        "        # See: BERTModel.forward\n",
        "        return self.embeddings(\n",
        "            input_ids=input_ids,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            mask=mask,\n",
        "            inputs_embeds=inputs_embeds\n",
        "        )\n",
        "    \n",
        "    def predict(self,embedding_output,\n",
        "                attention_mask=None,\n",
        "                head_mask=None,\n",
        "                encoder_hidden_states=None,\n",
        "                encoder_extended_attention_mask=None,\n",
        "                past_key_values=None,\n",
        "                use_cache=None,\n",
        "                output_attentions=None,\n",
        "                output_hidden_states=None,\n",
        "                return_dict=True): \n",
        "        encoder_outputs = self.encoder(\n",
        "                                        embedding_output,\n",
        "                                        attention_mask,\n",
        "                                        output_hidden_states=True,\n",
        "                                        output_attentions=output_attentions,\n",
        "                                        return_dict=return_dict\n",
        "        )\n",
        "        encoded_layers = encoder_outputs[1]\n",
        "\n",
        "        if self.z_steps > 1:\n",
        "            hidden_states = encoded_layers[-2]\n",
        "            layers = [self.encoder.layer[-1] for _ in range(self.z_steps)]\n",
        "            query_states = encoded_layers[-1]\n",
        "            rel_embeddings = self.encoder.get_rel_embedding()\n",
        "            attention_mask = self.encoder.get_attention_mask(attention_mask)\n",
        "            rel_pos = self.encoder.get_rel_pos(embedding_output)\n",
        "            for layer in layers[1:]:\n",
        "                query_states = layer(\n",
        "                    hidden_states,\n",
        "                    attention_mask,\n",
        "                    return_att=False,\n",
        "                    query_states=query_states,\n",
        "                    relative_pos=rel_pos,\n",
        "                    rel_embeddings=rel_embeddings,\n",
        "                )\n",
        "                encoded_layers.append(query_states)\n",
        "\n",
        "        sequence_output = encoded_layers[-1]\n",
        "\n",
        "        # if not return_dict:\n",
        "        #     return (sequence_output,) + encoder_outputs[(1 if output_hidden_states else 2) :]\n",
        "\n",
        "        outputs = BaseModelOutput(\n",
        "            last_hidden_state=sequence_output,\n",
        "            hidden_states=encoder_outputs.hidden_states if output_hidden_states else None,\n",
        "            attentions=encoder_outputs.attentions,\n",
        "        )\n",
        "\n",
        "        \n",
        "\n",
        "        pooled_output = self.pooler(outputs[0])\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "        \n",
        "        return logits"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4e11b9060e264692b6c0dad2e95f974c",
            "a5c4b8192eb4415ba42f6f514593ab26",
            "3e9a310f59b0419c9f4ee5c3c53b1735",
            "df1ecb1fac494b4d95331db4d8cb63f1",
            "16a1ed478b584fbea7a4c81802e922f4",
            "6d791e14800f4c38a65c15226f0d8a21",
            "64b332c297284f54b4c0a238740f9dce",
            "efbc95b409594974a4dca771381d8d9d",
            "35f4785c21174786ab0a81e8a23a2920",
            "34ea33cdd46442839d1a262584cb2f7d",
            "2937237979fe4ddb996ca25c13a39694",
            "5fbb564ff30e4e1db291d09046c07afd",
            "b31d1c7b14c9404ca3fe1b1a595e0c6e",
            "e8a6f3629e1242799da4bab36d4b0672",
            "a0fa54ef9d5947cd93ce361d25dfa41f",
            "cf86d47d8ac5410da90b044e5bbc2009"
          ]
        },
        "id": "IdNBO5qk2-i_",
        "collapsed": true,
        "outputId": "3e4f7c10-fadc-47fb-ad6b-e0fb276fbed3"
      },
      "source": [
        "\n",
        "#@title\n",
        "model = CustomDebertaForClassification.from_pretrained(\n",
        "    \"microsoft/deberta-base\",\n",
        "    num_labels = 2,\n",
        "    output_attentions = False, \n",
        "    output_hidden_states = False, \n",
        ")\n",
        "\n",
        "model.cuda()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4e11b9060e264692b6c0dad2e95f974c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=474.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "35f4785c21174786ab0a81e8a23a2920",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=558582766.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing CustomDebertaForClassification: ['lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'config']\n",
            "- This IS expected if you are initializing CustomDebertaForClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing CustomDebertaForClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of CustomDebertaForClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['encoder.layer.2.intermediate.dense.weight', 'encoder.layer.9.attention.self.pos_proj.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.rel_embeddings.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.8.attention.self.pos_q_proj.weight', 'encoder.layer.7.attention.self.pos_q_proj.weight', 'encoder.layer.4.attention.self.v_bias', 'encoder.layer.5.attention.self.in_proj.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.0.attention.self.pos_q_proj.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.5.attention.self.pos_q_proj.bias', 'encoder.layer.10.attention.self.pos_proj.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.3.attention.self.v_bias', 'encoder.layer.9.attention.self.in_proj.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.5.attention.self.pos_q_proj.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.6.attention.self.in_proj.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.1.attention.self.v_bias', 'encoder.layer.9.attention.self.pos_q_proj.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.3.attention.self.in_proj.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.7.attention.self.q_bias', 'encoder.layer.11.attention.self.pos_proj.weight', 'encoder.layer.0.attention.self.v_bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.4.attention.self.pos_q_proj.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.0.attention.self.pos_proj.weight', 'encoder.layer.2.attention.self.in_proj.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.5.attention.self.v_bias', 'encoder.layer.10.attention.self.v_bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.v_bias', 'encoder.layer.2.attention.self.pos_q_proj.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.7.attention.self.pos_proj.weight', 'encoder.layer.0.attention.self.pos_q_proj.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'pooler.dense.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.7.attention.self.v_bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.10.output.dense.bias', 'pooler.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.1.attention.self.q_bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.8.attention.self.pos_proj.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.5.attention.self.pos_proj.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.3.attention.self.q_bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.2.attention.self.q_bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.7.attention.self.pos_q_proj.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.in_proj.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.8.attention.self.pos_q_proj.bias', 'encoder.layer.4.attention.self.in_proj.weight', 'encoder.layer.9.attention.self.q_bias', 'encoder.layer.1.attention.self.pos_q_proj.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.5.attention.self.q_bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.8.attention.self.q_bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.1.attention.self.pos_q_proj.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.bias', 'classifier.bias', 'encoder.layer.3.attention.self.pos_proj.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.0.attention.self.q_bias', 'encoder.layer.1.attention.self.pos_proj.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.10.attention.self.pos_q_proj.bias', 'encoder.layer.6.attention.self.pos_q_proj.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.3.attention.self.pos_q_proj.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.11.attention.self.v_bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.10.attention.self.in_proj.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.11.attention.self.in_proj.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.0.attention.self.in_proj.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.9.attention.self.pos_q_proj.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.10.attention.self.pos_q_proj.weight', 'encoder.layer.6.attention.self.pos_q_proj.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.11.attention.self.pos_q_proj.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.4.attention.self.pos_proj.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.7.attention.self.in_proj.weight', 'encoder.layer.3.attention.self.pos_q_proj.weight', 'encoder.layer.1.attention.self.in_proj.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.6.attention.self.pos_proj.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.2.attention.self.pos_q_proj.bias', 'encoder.layer.11.attention.self.q_bias', 'encoder.layer.10.attention.self.q_bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.4.attention.self.pos_q_proj.bias', 'classifier.weight', 'encoder.layer.6.attention.self.q_bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.6.attention.self.v_bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.q_bias', 'encoder.layer.11.attention.self.pos_q_proj.bias', 'encoder.layer.8.attention.self.v_bias', 'encoder.layer.2.attention.self.pos_proj.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.2.attention.self.v_bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomDebertaForClassification(\n",
              "  (deberta): DebertaModel(\n",
              "    (embeddings): DebertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=0)\n",
              "      (LayerNorm): DebertaLayerNorm()\n",
              "      (dropout): StableDropout()\n",
              "    )\n",
              "    (encoder): DebertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (1): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (2): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (3): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (4): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (5): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (6): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (7): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (8): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (9): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (10): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (11): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (rel_embeddings): Embedding(1024, 768)\n",
              "    )\n",
              "  )\n",
              "  (pooler): ContextPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): StableDropout()\n",
              "  )\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              "  (dropout): StableDropout()\n",
              "  (embeddings): DebertaEmbeddings(\n",
              "    (word_embeddings): Embedding(50265, 768, padding_idx=0)\n",
              "    (LayerNorm): DebertaLayerNorm()\n",
              "    (dropout): StableDropout()\n",
              "  )\n",
              "  (encoder): DebertaEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (1): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (2): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (3): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (4): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (5): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (6): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (7): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (8): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (9): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (10): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (11): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (rel_embeddings): Embedding(1024, 768)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmSpMRD5qaqE"
      },
      "source": [
        "##Noise Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pG5DszcpDAjw"
      },
      "source": [
        "from torch.nn import LayerNorm\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def stable_kl(logit, target, epsilon=1e-6, reduce=True):\n",
        "    logit = logit.view(-1, logit.size(-1)).float()\n",
        "    target = target.view(-1, target.size(-1)).float()\n",
        "    bs = logit.size(0)\n",
        "    p = F.log_softmax(logit, 1).exp()\n",
        "    y = F.log_softmax(target, 1).exp()\n",
        "    rp = -(1.0/(p + epsilon) -1 + epsilon).detach().log()\n",
        "    ry = -(1.0/(y + epsilon) -1 + epsilon).detach().log()\n",
        "    if reduce:\n",
        "        return (p* (rp- ry) * 2).sum() / bs\n",
        "    else:\n",
        "        return (p* (rp- ry) * 2).sum()\n",
        "\n",
        "def _norm_grad(grad, epsilon = 1e-6, eff_grad=None, sentence_level=False):\n",
        "        if sentence_level:\n",
        "            direction = grad / (grad.abs().max((-2, -1), keepdim=True)[0] + epsilon)\n",
        "        else:\n",
        "            direction = grad / (grad.abs().max(-1, keepdim=True)[0] + epsilon)\n",
        "            eff_direction = eff_grad / (grad.abs().max(-1, keepdim=True)[0] + epsilon)\n",
        "        return direction, eff_direction\n",
        "\n",
        "def noise(embed, model, step_size, normalize=False, k=1, mean=0, std=0.01):\n",
        "    if normalize == True:\n",
        "        logits = model.predict(embed)\n",
        "        LNorm = LayerNorm(embed.size(),elementwise_affine=False)\n",
        "        normalized_embed = LNorm(embed)\n",
        "        \n",
        "        noise = torch.normal(mean=0, std=0.01,size=(normalized_embed.size()[0],normalized_embed.size()[1],normalized_embed.size()[2]))\n",
        "        noise = noise.to(device)\n",
        "        noise.requires_grad_()\n",
        "        noised_normalized_embeddings = normalized_embed+noise\n",
        "        adv_logits = model.predict(noised_normalized_embeddings)\n",
        "        adv_loss = stable_kl(adv_logits, logits.detach(), reduce=False)\n",
        "        delta_grad, = torch.autograd.grad(adv_loss, noise, only_inputs=True, retain_graph=False)\n",
        "        norm = delta_grad.norm()\n",
        "        # if (torch.isnan(norm) or torch.isinf(norm)):\n",
        "        #     return 0\n",
        "        eff_delta_grad = delta_grad * step_size\n",
        "        delta_grad = noise + delta_grad * step_size\n",
        "        noise, eff_noise = _norm_grad(delta_grad, eff_grad=eff_delta_grad, sentence_level=0)\n",
        "        noise = noise.detach()\n",
        "        noised_normalized_embeddings = normalized_embed+noise\n",
        "        return noised_normalized_embeddings\n",
        "\n",
        "    else:\n",
        "        logits = model.predict(embed)\n",
        "        noise = torch.normal(mean=0, std=0.01,size=(embed.size()[0],embed.size()[1],embed.size()[2]))\n",
        "        noise = noise.to(device)\n",
        "        noise.requires_grad_()\n",
        "        noised_embeddings = embed+noise\n",
        "        adv_logits = model.predict(noised_embeddings)\n",
        "        adv_loss = stable_kl(adv_logits, logits.detach(), reduce=False)\n",
        "        delta_grad, = torch.autograd.grad(adv_loss, noise, only_inputs=True, retain_graph=False)\n",
        "        norm = delta_grad.norm()\n",
        "        # if (torch.isnan(norm) or torch.isinf(norm)):\n",
        "        #     return 0\n",
        "        eff_delta_grad = delta_grad * step_size\n",
        "        delta_grad = noise + delta_grad * step_size\n",
        "        noise, eff_noise = _norm_grad(delta_grad, eff_grad=eff_delta_grad, sentence_level=0)\n",
        "        noise = noise.detach()\n",
        "        noised_embeddings = embed+noise\n",
        "        return noised_embeddings\n",
        "\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bunW4qF4qSyZ"
      },
      "source": [
        "## Optimizer, Scheduler, and Some Other Training Prep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLs72DuMODJO"
      },
      "source": [
        "#@title\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5,\n",
        "                  eps = 1e-8 \n",
        "                )"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p0upAhhRiIx"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cQNvaZ9bnyy"
      },
      "source": [
        "#@title\n",
        "import numpy as np\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpt6tR83keZD"
      },
      "source": [
        "#@title\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScjvBSBfHtBc"
      },
      "source": [
        "MODE = \"SMART-adv-only\""
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCSpuOXLqor-"
      },
      "source": [
        "##Training Loop with Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6J-FYdx6nFE_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71c5dbcb-83f3-4c8a-d8f1-d6939386a466"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # In PyTorch, calling `model` will in turn call the model's `forward` \n",
        "        # function and pass down the arguments. The `forward` function is \n",
        "        # documented here: \n",
        "        # https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification\n",
        "        # The results are returned in a results object, documented here:\n",
        "        # https://huggingface.co/transformers/main_classes/output.html#transformers.modeling_outputs.SequenceClassifierOutput\n",
        "        # Specifically, we'll get the loss (because we provided labels) and the\n",
        "        # \"logits\"--the model outputs prior to activation.\n",
        "        result = model(b_input_ids, \n",
        "                       token_type_ids=None, \n",
        "                       attention_mask=b_input_mask, \n",
        "                       labels=b_labels,\n",
        "                       return_dict=True)\n",
        "\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            result = model(b_input_ids, \n",
        "                           token_type_ids=None, \n",
        "                           attention_mask=b_input_mask,\n",
        "                           labels=b_labels,\n",
        "                           return_dict=True)\n",
        "\n",
        "        # Get the loss and \"logits\" output by the model. The \"logits\" are the \n",
        "        # output values prior to applying an activation function like the \n",
        "        # softmax.\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "        \n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    113.    Elapsed: 0:00:10.\n",
            "  Batch    80  of    113.    Elapsed: 0:00:20.\n",
            "\n",
            "  Average training loss: 0.20\n",
            "  Training epcoh took: 0:00:28\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.96\n",
            "  Validation Loss: 0.11\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    113.    Elapsed: 0:00:10.\n",
            "  Batch    80  of    113.    Elapsed: 0:00:20.\n",
            "\n",
            "  Average training loss: 0.10\n",
            "  Training epcoh took: 0:00:29\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.97\n",
            "  Validation Loss: 0.11\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    113.    Elapsed: 0:00:10.\n",
            "  Batch    80  of    113.    Elapsed: 0:00:21.\n",
            "\n",
            "  Average training loss: 0.05\n",
            "  Training epcoh took: 0:00:29\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.97\n",
            "  Validation Loss: 0.11\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    113.    Elapsed: 0:00:11.\n",
            "  Batch    80  of    113.    Elapsed: 0:00:21.\n",
            "\n",
            "  Average training loss: 0.03\n",
            "  Training epcoh took: 0:00:30\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.97\n",
            "  Validation Loss: 0.11\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:02:00 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQTvJ1vRP7u4"
      },
      "source": [
        "Let's view the summary of the training process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O_NbXFGMukX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "0252027f-3e31-4147-cf37-936f6b6c5d04"
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.20</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0:00:28</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.10</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0:00:29</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.05</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0:00:29</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.03</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0:00:30</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.20         0.11           0.96       0:00:28         0:00:01\n",
              "2               0.10         0.11           0.97       0:00:29         0:00:01\n",
              "3               0.05         0.11           0.97       0:00:29         0:00:01\n",
              "4               0.03         0.11           0.97       0:00:30         0:00:01"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68xreA9JAmG5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "f875d609-59b3-48f6-9389-ed2252b14d5f"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvAAAAGaCAYAAABpIXfbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd1xUR/s28GsXlqWDIAixlwBKE7BGEiM27IoUSzDGbmzRGMWgTxLzoImSWKNPLDEGO82Kxm5iYjSgggUbVkSBoFSl7r5/+LK/rEtZYOEAXt+/snPOzNznyHxy7+ycOSK5XC4HERERERHVCWKhAyAiIiIiIvUxgSciIiIiqkOYwBMRERER1SFM4ImIiIiI6hAm8EREREREdQgTeCIiIiKiOoQJPBG98RITE2Fra4s1a9ZUuo2AgADY2tpqMKr6q7T7bWtri4CAALXaWLNmDWxtbZGYmKjx+CIiImBra4vz589rvG0iIk3QFjoAIqLXVSQRPnHiBJo0aVKN0dQ9L168wP/+9z9ERUUhJSUFZmZmcHNzw8cff4zWrVur1cbMmTPx66+/Yu/evWjbtm2J58jlcvTs2ROZmZk4e/YsdHV1NXkZ1er8+fO4cOECPvzwQxgbGwsdjorExET07NkTo0ePxn/+8x+hwyGiWoYJPBHVOsuWLVP6HBMTg927d8PPzw9ubm5Kx8zMzKrcX+PGjREXFwctLa1Kt/H111/jq6++qnIsmrBw4UIcOnQIAwcORKdOnZCamoqTJ08iNjZW7QTe29sbv/76K8LDw7Fw4cISz/nrr7/w+PFj+Pn5aSR5j4uLg1hcMz8MX7hwAWvXrsWwYcNUEvghQ4ZgwIABkEgkNRILEVFFMYEnolpnyJAhSp+Lioqwe/dutG/fXuXY67Kzs2FoaFih/kQiEaRSaYXj/Lfakuy9fPkSR44cgbu7O7777jtF+fTp05Gfn692O+7u7rC2tsaBAwcwb9486OjoqJwTEREB4FWyrwlV/TfQFC0trSp9mSMiqm5cA09EdZaHhwf8/f1x/fp1jB8/Hm5ubhg8eDCAV4n8ihUr4OPjg86dO8PBwQG9e/dGcHAwXr58qdROSWuy/1126tQpDB8+HI6OjnB3d8e3336LwsJCpTZKWgNfXJaVlYUvvvgCXbt2haOjI0aMGIHY2FiV63n+/DkWLFiAzp07w8XFBWPGjMH169fh7+8PDw8Pte6JSCSCSCQq8QtFSUl4acRiMYYNG4b09HScPHlS5Xh2djaOHj0KGxsbODk5Veh+l6akNfAymQw//vgjPDw84OjoiIEDB2L//v0l1k9ISMCXX36JAQMGwMXFBc7OzvDy8kJoaKjSeQEBAVi7di0AoGfPnrC1tVX69y9tDfyzZ8/w1VdfoXv37nBwcED37t3x1Vdf4fnz50rnFdc/d+4cNm/ejF69esHBwQF9+/ZFZGSkWveiIm7cuIFp06ahc+fOcHR0RP/+/bFx40YUFRUpnffkyRMsWLAAPXr0gIODA7p27YoRI0YoxSSTyfDzzz9j0KBBcHFxgaurK/r27YvPP/8cBQUFGo+diCqHM/BEVKclJSXhww8/hKenJ/r06YMXL14AAJKTkxEWFoY+ffpg4MCB0NbWxoULF7Bp0ybEx8dj8+bNarV/5swZ7NixAyNGjMDw4cNx4sQJ/PTTTzAxMcGUKVPUamP8+PEwMzPDtGnTkJ6eji1btmDSpEk4ceKE4teC/Px8fPTRR4iPj4eXlxccHR1x8+ZNfPTRRzAxMVH7fujq6mLo0KEIDw/HwYMHMXDgQLXrvs7Lywvr169HREQEPD09lY4dOnQIubm5GD58OADN3e/XLV26FL/88gs6duyIsWPHIi0tDYsXL0bTpk1Vzr1w4QKio6Px/vvvo0mTJopfIxYuXIhnz55h8uTJAAA/Pz9kZ2fj2LFjWLBgARo0aACg7GcvsrKyMHLkSDx48ADDhw9Hu3btEB8fj507d+Kvv/5CaGioyi8/K1asQG5uLvz8/KCjo4OdO3ciICAAzZo1U1kKVllXrlyBv78/tLW1MXr0aDRs2BCnTp1CcHAwbty4ofgVprCwEB999BGSk5MxatQotGjRAtnZ2bh58yaio6MxbNgwAMD69euxevVq9OjRAyNGjICWlhYSExNx8uRJ5Ofn15pfmojeeHIiolouPDxcbmNjIw8PD1cq79Gjh9zGxka+Z88elTp5eXny/Px8lfIVK1bIbWxs5LGxsYqyR48eyW1sbOSrV69WKXN2dpY/evRIUS6TyeQDBgyQd+vWTand+fPny21sbEos++KLL5TKo6Ki5DY2NvKdO3cqyrZt2ya3sbGRr1u3Tunc4vIePXqoXEtJsrKy5BMnTpQ7ODjI27VrJz906JBa9UozZswYedu2beXJyclK5b6+vnJ7e3t5WlqaXC6v+v2Wy+VyGxsb+fz58xWfExIS5La2tvIxY8bICwsLFeVXr16V29raym1sbJT+bXJyclT6Lyoqkn/wwQdyV1dXpfhWr16tUr9Y8d/bX3/9pSj7/vvv5TY2NvJt27YpnVv877NixQqV+kOGDJHn5eUpyp8+fSq3t7eXz549W6XP1xXfo6+++qrM8/z8/ORt27aVx8fHK8pkMpl85syZchsbG/mff/4pl8vl8vj4eLmNjY18w4YNZbY3dOhQeb9+/cqNj4iExSU0RFSnmZqawsvLS6VcR0dHMVtYWFiIjIwMPHv2DO+88w4AlLiEpSQ9e/ZU2uVGJBKhc+fOSE1NRU5OjlptjB07Vulzly5dAAAPHjxQlJ06dQpaWloYM2aM0rk+Pj4wMjJSqx+ZTIZZs2bhxo0bOHz4MN577z3MnTsXBw4cUDpv0aJFsLe3V2tNvLe3N4qKirB3715FWUJCAi5fvgwPDw/FQ8Saut//duLECcjlcnz00UdKa9Lt7e3RrVs3lfP19fUV/52Xl4fnz58jPT0d3bp1Q3Z2Nu7evVvhGIodO3YMZmZm8PPzUyr38/ODmZkZjh8/rlJn1KhRSsuWGjVqhJYtW+L+/fuVjuPf0tLScOnSJXh4eMDOzk5RLhKJMHXqVEXcABR/Q+fPn0daWlqpbRoaGiI5ORnR0dEaiZGIqgeX0BBRnda0adNSHzjcvn07du3ahTt37kAmkykdy8jIULv915mamgIA0tPTYWBgUOE2ipdspKenK8oSExNhaWmp0p6Ojg6aNGmCzMzMcvs5ceIEzp49i+XLl6NJkyZYtWoVpk+fjnnz5qGwsFCxTOLmzZtwdHRUa018nz59YGxsjIiICEyaNAkAEB4eDgCK5TPFNHG//+3Ro0cAgFatWqkca926Nc6ePatUlpOTg7Vr1+Lw4cN48uSJSh117mFpEhMT4eDgAG1t5f9tamtro0WLFrh+/bpKndL+dh4/flzpOF6PCQDatGmjcqxVq1YQi8WKe9i4cWNMmTIFGzZsgLu7O9q2bYsuXbrA09MTTk5Oinpz5szBtGnTMHr0aFhaWqJTp054//330bdv3wo9Q0FE1YsJPBHVaXp6eiWWb9myBd988w3c3d0xZswYWFpaQiKRIDk5GQEBAZDL5Wq1X9ZuJFVtQ9366ip+6LJjx44AXiX/a9euxdSpU7FgwQIUFhbCzs4OsbGxCAoKUqtNqVSKgQMHYseOHbh48SKcnZ2xf/9+WFlZ4d1331Wcp6n7XRWffvopTp8+DV9fX3Ts2BGmpqbQ0tLCmTNn8PPPP6t8qahuNbUlprpmz54Nb29vnD59GtHR0QgLC8PmzZsxYcIEfPbZZwAAFxcXHDt2DGfPnsX58+dx/vx5HDx4EOvXr8eOHTsUX16JSFhM4ImoXtq3bx8aN26MjRs3KiVSv/32m4BRla5x48Y4d+4ccnJylGbhCwoKkJiYqNbLhoqv8/Hjx7C2tgbwKolft24dpkyZgkWLFqFx48awsbHB0KFD1Y7N29sbO3bsQEREBDIyMpCamoopU6Yo3dfquN/FM9h3795Fs2bNlI4lJCQofc7MzMTp06cxZMgQLF68WOnYn3/+qdK2SCSqcCz37t1DYWGh0ix8YWEh7t+/X+Jse3UrXtp1584dlWN3796FTCZTiatp06bw9/eHv78/8vLyMH78eGzatAnjxo2Dubk5AMDAwAB9+/ZF3759Abz6ZWXx4sUICwvDhAkTqvmqiEgdtWt6gIhIQ8RiMUQikdLMb2FhITZu3ChgVKXz8PBAUVERfvnlF6XyPXv2ICsrS602unfvDuDV7if/Xt8ulUrx/fffw9jYGImJiejbt6/KUpCy2Nvbo23btoiKisL27dshEolU9n6vjvvt4eEBkUiELVu2KG2JeO3aNZWkvPhLw+sz/SkpKSrbSAL/t15e3aU9vXr1wrNnz1Ta2rNnD549e4ZevXqp1Y4mmZubw8XFBadOncKtW7cU5XK5HBs2bAAA9O7dG8CrXXRe3wZSKpUqlicV34dnz56p9GNvb690DhEJjzPwRFQveXp64rvvvsPEiRPRu3dvZGdn4+DBgxVKXGuSj48Pdu3ahZUrV+Lhw4eKbSSPHDmC5s2bq+w7X5Ju3brB29sbYWFhGDBgAIYMGQIrKys8evQI+/btA/AqGfvhhx/QunVr9OvXT+34vL298fXXX+P3339Hp06dVGZ2q+N+t27dGqNHj8a2bdvw4Ycfok+fPkhLS8P27dthZ2entO7c0NAQ3bp1w/79+6GrqwtHR0c8fvwYu3fvRpMmTZSeNwAAZ2dnAEBwcDAGDRoEqVSKt99+GzY2NiXGMmHCBBw5cgSLFy/G9evX0bZtW8THxyMsLAwtW7astpnpq1evYt26dSrl2tramDRpEgIDA+Hv74/Ro0dj1KhRsLCwwKlTp3D27FkMHDgQXbt2BfBqedWiRYvQp08ftGzZEgYGBrh69SrCwsLg7OysSOT79++P9u3bw8nJCZaWlkhNTcWePXsgkUgwYMCAarlGIqq42vl/MiKiKho/fjzkcjnCwsIQFBQECwsL9OvXD8OHD0f//v2FDk+Fjo4Otm7dimXLluHEiRM4fPgwnJyc8PPPPyMwMBC5ublqtRMUFIROnTph165d2Lx5MwoKCtC4cWN4enpi3Lhx0NHRgZ+fHz777DMYGRnB3d1drXYHDRqEZcuWIS8vT+XhVaD67ndgYCAaNmyIPXv2YNmyZWjRogX+85//4MGDByoPji5fvhzfffcdTp48icjISLRo0QKzZ8+GtrY2FixYoHSum5sb5s6di127dmHRokUoLCzE9OnTS03gjYyMsHPnTqxevRonT55EREQEzM3NMWLECMyYMaPCb/9VV2xsbIk7+Ojo6GDSpElwdHTErl27sHr1auzcuRMvXrxA06ZNMXfuXIwbN05xvq2tLXr37o0LFy7gwIEDkMlksLa2xuTJk5XOGzduHM6cOYOQkBBkZWXB3Nwczs7OmDx5stJON0QkLJG8Jp4sIiKiSikqKkKXLl3g5ORU6ZchERFR/cI18EREtURJs+y7du1CZmZmifueExHRm4lLaIiIaomFCxciPz8fLi4u0NHRwaVLl3Dw4EE0b94cvr6+QodHRES1BJfQEBHVEnv37sX27dtx//59vHjxAubm5ujevTtmzZqFhg0bCh0eERHVEkzgiYiIiIjqEK6BJyIiIiKqQ5jAExERERHVIXyItYKeP8+BTFbzq47MzQ2RlpZd4/0S1TUcK0Tq4VghUo8QY0UsFqFBA4NSjzOBryCZTC5IAl/cNxGVj2OFSD0cK0TqqW1jhUtoiIiIiIjqEEET+Pz8fCxfvhzu7u5wcnKCr68vzp07V269o0eP4pNPPoGHhwecnZ3h6emJb7/9FllZWSWeHxoain79+sHR0RF9+/bF9u3bNX0pREREREQ1QtAEPiAgAFu3bsXgwYMRGBgIsViMiRMn4tKlS2XWW7RoERISEjBkyBAsXLgQ7u7uCAkJwciRI5GXl6d07q5du7Bw4ULY2Nhg0aJFcHZ2xuLFi/HTTz9V56UREREREVULwfaBj4uLg4+PDxYsWICxY8cCAPLy8jBw4EBYWlqWOUt+/vx5dO7cWals7969mD9/PpYuXQovLy8Ar15L3r17d7i5uWHdunWKc+fOnYuTJ0/izJkzMDIyqlDcaWnZgqyDsrAwQmpqyb8wENH/4VghUg/HCpF6hBgrYrEI5uaGpR+vwViUHDlyBBKJBD4+PooyqVQKb29vxMTEICUlpdS6ryfvANCrVy8AQEJCgqLs/PnzSE9Px6hRo5TOHT16NHJycvDbb79V9TKIiIiIiGqUYLvQxMfHo2XLljAwUN4ix8nJCXK5HPHx8bC0tFS7vX/++QcA0KBBA0XZ9evXAQAODg5K59rb20MsFuP69esYMGBAZS+BiIiISOHlyxxkZ2egqKhA6FBIg1JSxJDJZBprT0tLAkNDE+jplb5NZHkES+BTU1PRqFEjlXILCwsAKHMGviQbN26ElpYW+vTpo9SHjo4OTE1Nlc4tLqtoH0REREQlKSjIR1bWc5iaNoREIoVIJBI6JNIQbW0xCgs1k8DL5XIUFOQhPf0faGtLIJHoVC4mjURTCbm5uZBIJCrlUqkUAFQeRi3LgQMHEBYWhsmTJ6NZs2bl9lHcT0X6KFbWeqTqZmFRsfX6RG8qjhUi9XCsaM6DBw9hbGwKfX19oUOhaqCtrblV5xKJPmQyUxQU5OCtt8wrF4/GoqkgXV1dFBSo/sRUnFQXJ/LliY6ORmBgIN5//33MmjVLpY/8/PwS6+Xl5andx7/xIVai2o1jhUg9HCualZ2dA3NzK43N1FLtockZ+GISiS7S0tJLHYPlPcQqWAJvYWFR4hKW1NRUAFBr/fuNGzcwdepU2NraYsWKFdDS0lLpo6CgAOnp6UrLaPLz85Genl6hNfZCOXftKSLOJOBZZh7MjKXw6t4aXe2thA6LiIiI/kUmK4JYrFX+iUQAxGItyGRFla+vwVgqxM7ODvfu3UNOTo5SeWxsrOJ4WR4+fIgJEybAzMwMP/74Y4k/WbVt2xYAcPXqVaXyq1evQiaTKY7XVueuPcXWwzeQlpkHOYC0zDxsPXwD5649FTo0IiIieg3XvZO6qvq3IlgC7+npiYKCAoSGhirK8vPzERERAVdXV8UDrklJSUpbQwKvZunHjRsHkUiEzZs3w8zMrMQ+unTpAlNTU+zYsUOpfOfOndDX18d7772n4avSrIgzCch/7Seb/EIZIs4klFKDiIiIiOo7wZbQODs7w9PTE8HBwUhNTUWzZs0QGRmJpKQkLF26VHHe/PnzceHCBdy8eVNRNmHCBDx69AgTJkxATEwMYmJiFMeaNWsGFxcXAK/WwM+cOROLFy/GrFmz4O7ujujoaOzfvx9z586FsbFxzV1wJaRllvyQbWnlRERERHXN9OmTAABr126o0bp1mWAJPAAsW7YMK1euxL59+5CRkQFbW1ts2LABbm5uZda7ceMGAGDTpk0qx4YNG6ZI4IFXL22SSCT46aefcOLECVhbWyMwMBBjxozR7MVUA3NjaYnJuplRxR++JSIiIqoId/cOap0XGrof1tZvVXM09G8iuVxe81uq1GE1uQtN8Rr415fRmBtLsfDDjjAxqNzeoUT1GXfWIFIPx4pmPX36AFZWzYUOQ6N+/TVK6fOePTuRnPwEM2bMUSp/770e0NPTq3Q/xbsSlrb1d3XVVVd17EIDlP03U2t3oaHyFe828+9daDrYWeLUpccI+iUac/zaw8qM+80SERGR5vXt21/p8+nTJ5CRka5S/rrc3Fzo6uqq3U9Vku/qTNxrMybwtVxXeyt0tbdSminpaNcIq8JisSQkBjO9ndCmsYnAURIREdGbaPr0ScjOzsa8eZ9jzZoVuHnzBkaPHoPx4yfj999PY//+SNy6dROZmRmwsLBE//6D4O//kdLW36+vY794MRozZ05BUNAy3Lt3F3v3hiMzMwOOjs747LPP0aRJU43UBYDw8D3YtWs70tL+QevWrTF9+mxs3Lheqc3aiAl8HdTqLWN87u+GFXtisXznJUwZbA8XGwuhwyIiIiINKn4XTFpmHsxr8btg0tOfY9682ejTxxOengPQqNGrGKOiDkJPTx9+fqOhr6+HmJhobNr0P+Tk5GDatFnltAps3boZYrEWRo0ag6ysTOzcGYKvvlqIjRu3aqRuZGQYVqxYhvbtXeHnNxJPnjzBggVzYWRkBAuL2v2uICbwdVSjBvr43N8Nq0LjsDbyCj7obYMerk2EDouIiIg04PXn4IrfBQOg1iXx//yTioCARRg4cIhS+Zdf/hdS6f8tpRk61BvLly9BZGQoJk6cCh2dsp/lKywsxE8/bYW29qt01djYBKtWBePu3Tto1apNleoWFBRg06b1sLd3xMqV6xTntWnzNoKCvmQCT9XHWF8H80a64H/7riLk6C2kZebBq3sriPkiCSIiolrhjytPcDbuSYXrJSRloLBIedOM/EIZtkTF47fLSRVuz93JGt0crStcTx26urrw9BygUv7v5P3Fixzk5xfA2dkF+/ZF4MGD+3j7bZsy2x0wYLAisQYAZ+f2AICkpMflJvDl1b1x4zoyMjLw8cfDlM7r3dsTq1d/X2bbtQET+DpOqqOF6cMdsf3oLUT99QDPsnIxrn9baGsJ9o4uIiIiqqLXk/fyyoVkYWGplAQXu3s3ARs3rsfFi38jJydH6VhOTna57RYvxSlmZPTq/T1ZWeXvnlRe3adPX32pen1NvLa2Nqytq+eLjiYxga8HtMRi+Pe1hZmxLiJ+u4uM7HxMG+YIfV3+8xIREQmpm2PlZr4/W/dHie+CMTeWYv5oV02EpjH/nmkvlpWVhRkzJkFf3xDjx09B48ZNoKOjg1u3bmD9+jWQycrfllEs1iqxXJ0d0KtSty7gNG09IRKJMPCdFhg/oC1uPUrHN9sv4nkW39hKRERUF3l1bw0dbeU0TUdbDK/urQWKqGIuXYpBRkYGAgO/gK/vSHTr9i46duysmAkXmpXVqy9ViYmPlMoLCwvx5EnFlzzVNCbw9Uw3R2vM8nFCasZLBIVE43Fq+T9RERERUe3S1d4KH/azg7nxq7evmxtL8WE/u1r3AGtpxOJXKea/Z7wLCgoQGRkqVEhK7OzawcTEBPv3R6KwsFBRfuzYEWRlZQoYmXq4xqIecmhpjgWjXbFiTyyWbruIGcMdYdusgdBhERERUQUUvwumLnJ0dIKRkTGCgr6Et7cfRCIRfv01CrVlBYtEIsG4cZOwYsVyfPLJx+jRoyeePHmCw4cPoHHjJhDV8g1BOANfTzVrZITAMW4wMdTBd7sv40J8stAhERER0RvCxMQUy5atgLl5Q2zcuB47d25Dhw6d8fHHM4UOTWH4cD988slcPH36BD/8sAqxsZfwzTffw9DQCDo6UqHDK5NIXl9W89eQtLRsyGQ1f8v+/SbWish+WYA14XG4nZgBP4826NupWTVER1R7VHasEL1pOFY06+nTB7Cyai50GFRFMpkMAwf2RvfuPTB//kIAgLa2GIWF5T90W1Fl/c2IxSKYmxuWWpcz8PWcoZ4Ec0e0h5utBXafvIOdx29Dxu9sRERE9IbLy1Pd7OPIkUPIzMyAi4ubABGpj2vg3wASbS1MHeKAXSdv41j0IzzPysXEQe0g0S55iyUiIiKi+i4u7jLWr1+D99/3gLGxCW7duoFDh/ajVavW6NGjl9DhlYkJ/BtCLBZhVC8bmBvrYvfJO8jMuYzpw51gqCcROjQiIiKiGvfWW43RsKEFwsJ2IzMzA8bGJvD0HIApU6ZDIqnd+RET+DdM307N0MBIik0Hr2PpthjM9nVGQxM9ocMiIiIiqlGNGzfBsmUrhA6jUrgG/g3UqW0jzPFtj/TsfASFxOBhMh9iIiIiIqormMC/oeyaN8DnH7hCLBJh6faLuHbvmdAhEREREZEamMC/wRpbGGLhmA6wMNHFytBY/HGl9r86mIiIiOhNxwT+DdfASIqA0W6waWqKzYficfDP++CrAYiIiIhqLybwBH1dbcz2dUYX+0aI+O0uQo7eQpFM8y8sICIiIqKq4y40BADQ1hJjwsB2MDPSRdRfD5CelYfJQ+whlXCveCIiIqLahDPwpCAWieD9fmuM7m2D2Dv/YPnOS8h8kS90WERERET0L4Im8Pn5+Vi+fDnc3d3h5OQEX19fnDt3rtx6cXFx+PLLL+Hl5QUHBwfY2tqWem5KSgoWLlwIDw8PODs7o0+fPggODkZmZqYmL6Ve6enWBNO8HPEoJRtLQmKQ8vyF0CERERFRHRcVdQDu7h3w5EmSoszbexCCgr6sVN2qungxGu7uHXDxYrTG2qwpgibwAQEB2Lp1KwYPHozAwECIxWJMnDgRly5dKrPemTNnEBoaCgBo2rRpqee9ePECI0aMwPHjxzFs2DAsXLgQ3bp1w5YtWzBlyhSNXkt942pjgc9GuCDnZQGCQmJwN4lfeIiIiN4k8+bNRq9e7nj58mWp58yZMx19+3ZHXl5eDUZWMceP/4o9e3YIHYZGCbYGPi4uDocOHcKCBQswduxYAMDQoUMxcOBABAcHY/v27aXWHTlyJCZOnAhdXV0EBQXh7t27JZ53+vRpPH78GD/++CPef/99Rbmuri5++uknPHr0qMwvAG+6Nk1M8Lm/G1bsicWynRcxZYgD2rdpKHRYREREVAN69+6LP//8HWfPnkHv3p4qx58/f4aYmL/Rp08/SKXSSvWxY0c4xOLqnU8+ceIobt++BV/fUUrl7du74sSJPyCRSKq1/+og2Az8kSNHIJFI4OPjoyiTSqXw9vZGTEwMUlJSSq3bsGFD6OrqlttHdnY2AMDc3FylPgC12njTWZsbIHBMB1ibG2BNeBzOXH4sdEhERERUA959933o6enj+PFfSzx+8uRxFBUVoU8f1eReXTo6OtDWFmY+WSwWQyqVVvsXiOog2Ax8fHw8WrZsCQMDA6VyJycnyOVyxMfHw9LSskp9uLm5QSwWIygoCAEBAbCyssL169exZcsWeHl5wcLCokrtvylMDHQwf5QL1u+9hq1HbuJZZh6GvtsSIpFI6NCIiIiomujq6uLdd7vj1KnjyMzMhLGxsdLx48d/hbm5OZo2bY7g4JeZTZ4AACAASURBVG8QE3MBycnJ0NXVhatrB0ybNgvW1m+V2Ye39yC4uLghMPBLRdnduwlYuXI5rl69AhMTEwwZ4oWGDVVztt9/P439+yNx69ZNZGZmwMLCEv37D4K//0fQ0nq1i9706ZNw+fJFAIC7ewcAgJWVNcLCDuDixWjMnDkFq1f/D66uHRTtnjhxFNu2/YwHD+5DX98A7777HiZPngFTU1PFOdOnT0J2djb+85/F+P77ZYiPvwYjI2P4+IzA6NEfVuxGV4JgCXxqaioaNWqkUl6cVJc1A6+u1q1bY/HixVi2bBn8/PwU5X5+fvjyyy+r3P6bRFdHGzOGO+KXX2/iwJ/38SwrFx962kFbq+59ayUiIqoLLjy9iP0JR/A8Lx0NpKYY3NoTnaxcazSG3r09cfToYZw+fQKDBw9TlD99+gRXr8bB23sE4uOv4erVOPTq1RcWFpZ48iQJe/eGY8aMydi2LbRCKx7S0v7BzJlTIJPJ8MEHH0JXVw/790eWuEQnKuog9PT04ec3Gvr6eoiJicamTf9DTk4Opk2bBQD48MNxePnyJZKTn2DGjDkAAD09/VL7j4o6gCVLvoK9vSOmTp2JlJRkhIfvxrVrV7Fx4y9KcWRmZuDTT2eiR4+e6NmzD06dOo7169egVas26Nq1m9rXXBmCJfC5ubklrjkqvjGaehjCysoKzs7OeO+99/DWW28hOjoaISEhMDExwaefflrh9szNDTUSV2VYWBgJ1nexeWM6otnRm9hx9CZe5sswf0wH6OvWvbVjVL/VhrFCVBdwrGhOSooY2tqam9Q6nxSDnTfCkS8rAAA8z0vHzhvh0BKL0PktN431U56uXbuiQYMGOHHiV3h5DVeUnzx5DHK5HJ6e/dC6dRv07t1HqV737t0xYcJY/P77SfTrNxAAIBa/+uVeS0v5XolEIsXnnTt/QUZGOrZs2QY7u7YAgEGDBsPHZ4hK3a+/XqL05cDb2xfffhuEyMhQTJ06DTo6Ouja9R1ERoYhIyMdAwYMVIpR6/9PQha3WVhYgPXr1+Dtt22wfv1G6OjoAADatWuHRYsW4NChffD1HaGIOSUlGYsXL1EsIRo6dBiGDh2AqKj9ePfdd8u9t2KxuNJjULAEXldXFwUFBSrlxYl7ZR+G+LeYmBhMmTIFYWFhaNv21R9Br169YGhoiLVr12LYsGFo1apVhdpMS8uGTCavcmwVZWFhhNTUrBrvtyS9XBtDR0uEX47cxGerf8MnPs4wNaz6vxeRJtSmsUJUm3GsaJZMJkNhoepbzM8/icG5J39XuL17GQ9RKC9UKsuXFeCXa6H4PfF8hdvrat0Rna0rk/iL0aNHL+zdG46nT1MUzxEePXoETZo0ha1tOwBQXHthYSFycrJhZdUEhoZGiI+PR+/e/QFAkT8VFSnfK7lcrvj8xx9n4ejojDZtbBVlRkYm6N27HyIjQ5XqamvrKP77xYsc5OcXwNGxPSIjw5GQcBdvv22jaP/fMRYrKpIpxXP16jU8f/4MEydOhVisrTi/Z8/eWL16Bc6e/R1eXr6KNg0NDdGjR2/FeSKRFtq2bYfHjxNL/Ft4nUwmK3UMisWiMieNBUvgLSwsSlwmk5qaCgBVXv8OALt374alpaUieS/m4eGBNWvW4PLlyxVO4OmV95zfgqmhDtbtvYqgX2Iwx88Z1uYG5VckIiKicr2evJdXXp169/ZEREQoTp48Cl/fUbh//x7u3LmFjz6aCADIy8tFSMjPiIo6gNTUFEXCDPzfhiLqSk5+CkdHZ5XyZs2aq5TdvZuAjRvX4+LFv5GTk6N0LCenYv0Cr5YFldSXWCxGkyZNkZz8RKnc0rKRyvOARkbGSEi4U+G+K0qwBN7Ozg4hISHIyclRepA1NjZWcbyq0tLSUFRUpFJeWPjqj7+kY6Q+p9YNMX+UK1aFxmJJSAxmejvh7Sam5VckIiJ6Q3S2dqvUzPfCP5bgeV66SnkDqSk+ca3Zd9k4OjrD2roxjh07Al/fUTh27AgAKLaWXLFiOaKiDsDHZyQcHBxhaGgIQIQvv/xcKZnXpKysLMyYMQn6+oYYP34KGjduAh0dHdy6dQPr16+BTFb+DHhVicVaJZZX1zUr9V3tPZTC09MTBQUFihcyAa/ezBoREQFXV1fFA65JSUlISEioVB8tWrRAcnIyoqOV37B18OBBAFCZmaeKa2ltjM/HdIChngTLd15GzM2qP3xMRET0phvc2hMSsfIzZhKxBINbV37Lxqro1asP4uOvIzHxEU6cOApb27aKmerTp0/A03MAZsyYjR49eqFjxy5wcmpf4dl3AGjUyAqJiY9Uyh8+fKD0+dKlGGRkZCAw8Av4+o5Et27vomPHzjAyMlapC6i3a56VlXWJfcnlciQmPkKjRtbqXUQNEGwG3tnZGZ6enggODkZqaiqaNWuGyMhIJCUlYenSpYrz5s+fjwsXLuDmzZuKssePH2Pfvn0AgCtXrgAA1q1bB+DVzL2HhwcAYPTo0YiIiMDkyZPxwQcfwNraGn///TcOHjyId999Fw4ODjV1ufWapakePvd3w+rwOKyLvIqRvd5Grw58QRYREVFlFe82I/QuNMX69OmHkJAtWLt2BRITH2HGjNmKYyXNRIeH767USoeuXbshNHQXbt68AVvbV6sxnj9/jmPHDiudV7x3+79nuwsKChAZGYrX6enpqfVlws6uHRo0MMPevWHo12+gYrOVkyePIzU1BaNHj6nw9VQXwRJ4AFi2bBlWrlyJffv2ISMjA7a2ttiwYQPc3Mr+qSkxMRGrVq1SKiv+PGzYMEUC36pVK4SHhyv6+Oeff2BpaYkJEyZgxowZ1XNRbygjfR3MHeGCDfuvYcfx23iWlQfv91tDzL3iiYiIKqWTlatgCfvrWrZshTZtbHD27G8Qi8Xo2bOv4tg777jj11+jYGBgiBYtWuLatSuIjr4AExOTCvczatSH+PXXKMyZMw3e3iMglepi//5INGpkjezs24rzHB2dYGRkjKCgL+Ht7QeRSIRff41CSatXbG3tcPToYaxZ8z3s7NpBT08f7u7vqZynra2NqVNnYMmSrzBjxmT06tUHKSnJCAvbjVatWmPQoGGqjQtE0AReKpVi/vz5mD9/fqnnhISEqJR17txZaUa+LK1atcLq1asrHSOpTyrRwrRhjth+/BaOnH+IZ5m5GD+gHSQa3FaLiIiIhNGnjyfu3LkFFxc3xW40ADBr1lyIxWIcO3YYeXn5cHR0xsqVP2DOnIpPljZs2BCrV/+IFSuWISTkZ6UXOX3zzdeK80xMTLFs2QqsXbsSGzeuh5GRMfr06YcOHTphzpzpSm0OGTIct27dQFTUQezevQNWVtYlJvAA0L//IOjo6GD79q344YdVMDAwQN++/TBp0nSN7JCoKSJ5Tay0r0e4jWT55HI5Dp9/iLDTCbBrZorpXo7cK55qTF0aK0RC4ljRrKdPH8DKSnWnFKr7Xu0Rr/mHYsv6mylvG0lOjZLGiUQi9O/SHBMHtsPtxAws3X4RzzJzhQ6LiIiIqF5gAk/VpquDFWb7OuNZZi6CQmKQmFLxp9GJiIiISBkTeKpW7VqYIWC0G+RyOZZuj0H8g+dCh0RERERUpzGBp2rX1NIQgf4d0MBIF9/vvoy/rj0VOiQiIiKiOosJPNUIcxNdLPjAFW0am2DDges4/NeDGnlTGREREVF9wwSeaoyBrgRz/Nqjo50lQk8nYMex24Ls6ENERERUlwm6Dzy9eSTaYkweYo8GRlIc/fsRnmfnYdKgdtCRqL7FjYiIiIhUcQaeapxYJMKInm9jRM+3celWKoJ3XUb2ywKhwyIiIqoSLg0ldVX1b4UJPAmmT8emmDrUAfefZmFJSAxS018KHRIREVGlaGlpo6AgX+gwqI4oKMiHllblF8IwgSdBdbCzxNwR7ZH1Ih9BITF48JRvBSQiorrH0NAU6empyM/P40w8lUoulyM/Pw/p6akwNDStdDsiOf/KKiQtLVuQBy/r+yuvk/7JwYo9l5H9shAfD3OAYytzoUOiOqq+jxUiTeFY0byXL3OQnZ2OoqJCoUMhDRKLxZDJZBprT0tLG4aGptDTMyijTxHMzQ1LPc4EvoKYwFef51l5WBkai8epOfiwny3edXpL6JCoDnoTxgqRJnCsEKlHiLFSXgLPJTRUazQwkiJgtCvaNjfFlqgb2H/2Hn+GJCIiInoNE3iqVfSk2pjl44x3HKyw9+w9bD1yE0Ua/NmKiIiIqK7jPvBU62hriTF+QFuYGUtx8M8HSM/Ow9QhDpDqcK94IiIiIs7AU60kEong9V5rjOlriyt30/DtjovIzOH2XERERERM4KlWe9+lMWZ4OSHpnxwEhUQj+dkLoUMiIiIiEhQTeKr12r/dEJ+NcsHLvCIEhcQg4XGG0CERERERCYYJPNUJrd8yQaC/G/Sl2li+8xIu3U4VOiQiIiIiQTCBpzqjkZk+Pvd3Q2MLA6yNuIJTFxOFDomIiIioxjGBpzrF2EAH80a6wqmVOUKO3kL4mQTuFU9ERERvFMG3kczPz8eqVauwb98+ZGZmws7ODrNnz0bXrl3LrBcXF4eIiAjExcXh1q1bKCgowM2bN0s9/969e1i1ahX++usvvHjxAo0bN4aXlxcmTpyo6UuiaibV0cL04Y7YdvQWDp17gGeZefiovx20tfh9lIiIiOo/wRP4gIAAHD16FGPGjEHz5s0RGRmJiRMnIiQkBC4uLqXWO3PmDEJDQ2Fra4umTZvi7t27pZ577do1jBkzBq1atcLkyZNhYGCAR48e4enTp9VxSVQDtMRijOlrCzMjKSJ/v4eMnDxMG+YIPangf9JERERE1UokF3D9QVxcHHx8fLBgwQKMHTsWAJCXl4eBAwfC0tIS27dvL7XuP//8A0NDQ+jq6iIoKAi//PJLiTPwRUVFGDx4MFq2bInVq1dDLK7aLG1aWjZkspq/ZRYWRkhNzarxfuuCs3FPsPXIDVibG2C2rzMaGEmFDokExLFCpB6OFSL1CDFWxGIRzM0NSz9eg7GoOHLkCCQSCXx8fBRlUqkU3t7eiImJQUpKSql1GzZsCF1d3XL7OHv2LO7cuYPZs2dDLBYjJycHMplMI/FT7eDuZI1Z3k5IzXiJoJBoPP4nR+iQiIiIiKqNoAl8fHw8WrZsCQMDA6VyJycnyOVyxMfHV7mPc+fOwdDQEMnJyejbty9cXV3h6uqKhQsX4uXLl1Vun2oHh1bmCBjliqIiOZaGxODmw+dCh0RERERULQRN4FNTU2FpaalSbmFhAQBlzsCr68GDBygqKsLHH38Md3d3rFmzBiNHjkRYWBg+/fTTKrdPtUdzKyME+rvB2EAH3+2+jL9vVP3vh4iIiKi2EfSJv9zcXEgkEpVyqfTVGua8vLwq9/HixQu8fPkSI0aMwKJFiwAAffr0gUgkwubNm3Hjxg3Y2dmp3V5Z65Gqm4WFkWB91xUWFkb4fnZ3fL35PP637yoK5A4Y8l5rocOiGsaxQqQejhUi9dS2sSJoAq+rq4uCggKV8uLEvTiRr2ofADBw4ECl8sGDB2Pz5s2IiYmpUALPh1jrhlnDHbHxwHVs2ncVD5My4OvRBmKRSOiwqAZwrBCph2OFSD18iPU1FhYWJS6TSU1NBYASl9dUpg8AMDc3Vyov/pyZmVnlPqj20ZFoYepQB/Rya4Kjfz/C//ZdQ0FhkdBhEREREVWZoAm8nZ0d7t27h5wc5V1DYmNjFceryt7eHgCQnJysVF68B7yZmVmV+6DaSSwWYWSvt+Hbow2ib6Tgu92xyMlV/cWHiIiIqC4RNIH39PREQUEBQkNDFWX5+fmIiIiAq6srGjVqBABISkpCQkJCpfrw8PCARCJBWFiYUnloaChEIhG6dOlS+QugWk8kEsGzczNMGtwOCY8zsCQkBmkZuUKHRURERFRpgq6Bd3Z2hqenJ4KDg5GamopmzZohMjISSUlJWLp0qeK8+fPn48KFC0ovanr8+DH27dsHALhy5QoAYN26dQBezdx7eHgAABo1aoRJkybhhx9+QEFBAbp06YJLly5h//79GDVqFJo3b15Tl0sC6tLOCiYGUqyNuIL/hkRjto8zmjWqXQ+kEBEREalD0DexAq8eWF25ciUOHDiAjIwM2NraYs6cOXjnnXcU5/j7+6sk8OfPn8eYMWNKbHPYsGH45ptvFJ/lcjm2bt2KHTt2ICkpCZaWlvDx8cHkyZMr/GZWPsRatyWmZGNFaCxe5hVimpcj7FtwCVV9w7FCpB6OFSL11MaHWAVP4OsaJvB137PMXKwMjcWTtBcY178tujpYCR0SaRDHCpF6OFaI1FMbE3hB18ATCcHMWBcBo93wdhMTbDx4HYfO3Qe/xxIREVFdwQSe3kj6utqY7dsends1QviZu9h29JYgv6wQERERVZSgD7ESCUmiLcbEQe1gZiTF4fMP8TwrD5OH2EMq0RI6NCIiIqJScQae3mhikQg+PdpgdG8bxN75B8E7LyHrRb7QYRERERGVigk8EYCebk3w8TBHPEzJxpKQGKQ8fyF0SEREREQlYgJP9P+52VrgsxEuyH5ZgCUhMbj3JFPokIiIiIhUMIEn+pc2TUzwub8bdCRa+HbHRcQl/CN0SERERERKmMATvcba3ACB/m6wNjPA6rAr+C02SeiQiIiIiBSYwBOVwMRQinmjXNCuRQP8fPgG9v5+l3vFExERUa3ABJ6oFHpSbcz0doK7ozX2/3EfW6JuoLBIJnRYRERE9IbjPvBEZdDWEuOj/nYwM5Zi/x/3kZ6Th4+HOkBXh0OHiIiIhMEZeKJyiEQiDH23Fcb2s8P1e8/x7fZLyMjOEzosIiIiekMxgSdS03vOb2GmtyOePMtBUEgMnqTlCB0SERERvYGYwBNVgFPrhpg/yhV5BUVYEhKD24npQodEREREbxgm8EQV1NLaGIH+bjDUkyB412XE3EwVOiQiIiJ6gzCBJ6oEywb6WODvhqaWhlgXeQUnYhKFDomIiIjeEEzgiSrJWF8Hn410gXObhth+7BZCT92BjHvFExERUTVjAk9UBVKJFqZ5OaCHS2McPv8Qmw5cR0Eh94onIiKi6sPNrImqSEssxgd9bGBmLEX4mbtIz87DdC9H6OtKhA6NiIiI6iHOwBNpgEgkwoCuLTBhYFvcTszA0u0X8SwzV+iwiIiIqB5iAk+kQe84WOMTX2ekZeQiKCQGianZQodERERE9QwTeCINs29hhoDRrpDJ5Vi67SLiHzwXOiQiIiKqR5jAE1WDZo2MsNC/A0wNdbBiz2Wcv54sdEhERERUTwiawOfn52P58uVwd3eHk5MTfH19ce7cuXLrxcXF4csvv4SXlxccHBxga2urVn9RUVGwtbVFhw4dqho6UbnMTXTxub8bWr1lgh/3X8OR8w8h5zaTREREVEWCJvABAQHYunUrBg8ejMDAQIjFYkycOBGXLl0qs96ZM2cQGhoKAGjatKlafeXm5mL58uXQ19evctxE6jLQleBTP2d0tLPEnlN3sPP4bchkTOKJiIio8gRL4OPi4nDo0CHMnTsX8+bNg5+fH7Zu3Qpra2sEBweXWXfkyJGIiYlBREQE3N3d1epv48aN0NHRgYeHhybCJ1KbRFsLk4fYo0/Hpjgek4j1+64iv6BI6LCIiIiojhIsgT9y5AgkEgl8fHwUZVKpFN7e3oiJiUFKSkqpdRs2bAhdXV21+0pKSsKmTZswf/58SCTcm5tqnlgkwoieb2OERxtcvJmK4N2Xkf2yQOiwiIiIqA4SLIGPj49Hy5YtYWBgoFTu5OQEuVyO+Ph4jfX17bffwsXFhbPvJLg+nZphylAH3H+SiSUhMfgn/aXQIREREVEdI9ibWFNTU9GoUSOVcgsLCwAocwa+Ii5cuIBjx44hIiJCI+2ZmxtqpJ3KsLAwEqxv0pz+FkZo9pYJ/rvlApZuv4gvJnRB6yamQodVr3CsEKmHY4VIPbVtrAiWwOfm5pa4nEUqlQIA8vLyqtxHUVER/vvf/8LLywt2dnZVbg8A0tKyBXkI0cLCCKmpWTXeL1WPRsZSBIxywYrQWMz/4SymDXWAQytzocOqFzhWiNTDsUKkHiHGilgsKnPSWLAlNLq6uigoUF0DXJy4FyfyVbF7924kJibik08+qXJbRJrW2MIQgf4dYGmqh1VhcTgb90TokIiIiKgOECyBt7CwKHGZTGpqKgDA0tKySu3n5+dj9erV8PLyQm5uLhITE5GYmIgXL15AJpMhMTERz549q1IfRFXVwEiKgNGusG1mip+i4nHgj3vcK56IiIjKJNgSGjs7O4SEhCAnJ0fpQdbY2FjF8arIzc3F8+fPERISgpCQEJXjPXv2RP/+/bFixYoq9UNUVXpSbXzi44wtUTcQ+fs9pGXmwb+vDbTEfFEyERERqRIsgff09MRPP/2E0NBQjB07FsCrWfOIiAi4uroqHnBNSkrCy5cv0bp16wq1r6enhx9++EGl/JdffkFcXByCg4NLfIiWSAjaWmJMGNgWZsZSHDr3AOnZeZg6xAFSHS2hQyMiIqJaRrAE3tnZGZ6enggODkZqaiqaNWuGyMhIJCUlYenSpYrz5s+fjwsXLuDmzZuKssePH2Pfvn0AgCtXrgAA1q1bB+DVzL2HhwckEgl69eql0u/x48dx/fr1Eo8RCUkkEmF499YwM5Ji27FbWLbzImZ5O8PYQEfo0IiIiKgWESyBB4Bly5Zh5cqV2LdvHzIyMmBra4sNGzbAzc2tzHqJiYlYtWqVUlnx52HDhnG/d6rTerg2gamhFD/uv4YlITGY7eeMRg30hQ6LiIiIagmRnE/MVQi3kaSakvA4A6vC4gAAs3yc0PotE4Ejqhs4VojUw7FCpB5uI0lEamvd2ASB/m7Qk2ph+Y5LuHQ7VeiQiIiIqBZgAk9UizUy08fn/h3wVkMDrI24glOXHgsdEhEREQmMCTxRLWdioIP5o1zh2MocIb/eRPiZBO4VT0RE9AZjAk9UB0h1tDBjuCPec7bGoXMPsPlQPAqLZEKHRURERAIQdBcaIlKflliMDz3tYGaki71n7yEjOw8fD3OEnpTDmIiI6E3CGXiiOkQkEmGwe0t81N8O8Q/S8e32i3ielSd0WERERFSDmMAT1UHvOr2FWT5OSH7+EktCopH0T47QIREREVENYQJPVEc5tjJHwGhXFBTJsXRbDG49Shc6JCIiIqoBTOCJ6rDmVkYI9HeDkb4OgnddRvSNFKFDIiIiomrGBJ6ojrMw1cPn/m5oYWWE9Xuv4ujfj4QOiYiIiKoRE3iiesBQT4K5I9rDxcYCu07cxq4TtyHjXvFERET1EhN4onpCR6KFj4c6oKdrExz9+xE27L+GgkLuFU9ERFTfcANponpELBZhVO+3YWYiReipBGRk52P6cEcY6EqEDo2IiIg0hDPwRPWMSCRCv87NMWlQO9x5nIFvtl1EWkau0GERERGRhjCBJ6qnuthbYY5fezzLykVQSDQeJmcJHRIRERFpABN4onqsbfMGWDDaDSKRCN9sv4jr958JHRIRERFVERN4onquiaUhAv3dYG6sixV7YnHu2lOhQyIiIqIqYAJP9AYwM9bFgg9c8XYTE2w8cB2Hzt2HnNtMEhER1UlM4IneEPq6Esz2bY9ObS0RfuYuth27BZmMSTwREVFdo5FtJAsLC3HixAlkZGSgR48esLCw0ESzRKRhEm0xJg22h5mxLo6cf4j0rDxMGmwPqURL6NCIiIhITRVO4JctW4bz588jPDwcACCXy/HRRx8hOjoacrkcpqam2LNnD5o1a6bxYImo6sQiEXx7tIGZkRQ7j99G8M5LmOntBCN9HaFDIyIiIjVUeAnN77//jg4dOig+nzx5En///TfGjx+P7777DgCwYcMGzUVIRNWiV4emmDrUAQ+Ss7EkJAYp6S+FDomIiIjUUOEZ+KdPn6J58+aKz6dOnUKTJk0wd+5cAMDt27dx4MABtdrKz8/HqlWrsG/fPmRmZsLOzg6zZ89G165dy6wXFxeHiIgIxMXF4datWygoKMDNmzdVzktISEB4eDj++OMPPHz4EAYGBrC3t8fMmTNhb29fgasmqp862FnCxFAHq8PisOSXaMzycUZLa2OhwyIiIqIyVHgGvqCgANra/5f3nz9/Hu+8847ic9OmTZGamqpWWwEBAdi6dSsGDx6MwMBAiMViTJw4EZcuXSqz3pkzZxAaGqrorzRhYWEIDQ2Fg4MDAgICMHbsWNy9exe+vr7466+/1IqRqL57u4kpPvd3g0RbC8t2XEJcQprQIREREVEZKpzAW1lZKRLs27dv49GjR+jYsaPieFpaGvT19cttJy4uDocOHcLcuXMxb948+Pn5YevWrbC2tkZwcHCZdUeOHImYmBhERETA3d291PMGDBiA06dPIygoCH5+fpgwYQL27NkDY2Nj/PDDD2peMVH9Z21ugMAxbmhkpofVYXH4LTZJ6JCIiIioFBVO4AcMGIC9e/di8uTJmDx5MgwNDdG9e3fF8fj4eLUeYD1y5AgkEgl8fHwUZVKpFN7e3oiJiUFKSkqpdRs2bAhdXd1y+3BwcICBgYFSWYMGDdChQwckJCSUW5/oTWJqKMX8Ua5o16IBfj58A3t/v8u94omIiGqhCifwkydPxrBhw3D58mWIRCJ8++23MDZ+tWY2KysLJ0+eLHcNO/Aq0W/ZsqVKgu3k5AS5XI74+PiKhqa21NRUNGjQoNraJ6qr9KTamOnthG6OVtj/x31sOXwDhUUyocMiIiKif6nwQ6w6OjpYsmRJiccMDAxw9uxZtWbHU1NT0ahRI5Xy4j3ky5qBr4ro6GhcvnwZ06dPr5b2ieo6bS0xxvVvCzMjXRz48z7Ss/Pw8VAH6Opo5LURREREVEUa/T9yYWEhjIyM1Do3NzcXEolEpVwqlQIA8vLyNBkagFfr8z/99FM0PbdHQgAAIABJREFUa9YM48aNq1Qb5uaGGo5KfRYW6t1bIk2YNNwZzd4ywfrwWHy/Jxb/mdAFDYzK/3JeG3CsEKmHY4VIPbVtrFQ4gT9z5gzi4uIwY8YMRdn27dvx3XffITc3F/369cM333xTYnL+b7q6uigoKFApL07cixN5TXnx4gUmT56Mly9fYvPmzWo9aFuStLRsQV4/b2FhhNTUrBrvl95sbm3MMX24E/637yrmrDiD2b7OsDY3KL+igDhWiNTDsUKkHiHGilgsKnPSuMJr4Ddv3oy7d+8qPickJGDJkiWwtLTEO++8g6ioKGzfvr3cdiwsLEpcJlO8BaWlpWVFQytVfn4+ZsyYgVu3bmHdunVo06aNxtomqu/at2mIeSNdkVdQhKXbLuLO4wyhQyIiInqjVTiBv3v3LhwcHBSfo6KiIJVKERYWhk2bNqF///7Yu3dvue3Y2dnh3r17yMnJUSqPjY1VHNcEmUyG+fPn49y5c/j++++V3iJLROpp9ZYxPvd3g76uNpbvvISLt9R71wMRERFpXoUT+IyMDKUdXP7880906dIFhoavpvk7deqExMTEctvx9PREQUGB4oVMwKuZ8oiICLi6uioecE1KSqrSlo9ff/01oqKi8MUXX6BXr16VbofoTdeogT4+93dDU0tD/BB5BSdiyh/nREREpHkVXgPfoEEDJCW9eslLdnY2rly5gjlz5iiOFxYWoqioqNx2nJ2d4enpieDg4P/X3p3HR13d++N/zT6TfZsskw0IkABZQYGwBAW8UguCKFJUEGutVu1V+LW/itz2cW97i96KLKXFBdvLclErGIiiooKWYBCoYCYEQpCwJpNlkpB9mUzm8/0jyScZZgIJJPnMJK/n48FjnDPnM58z6mHe5z1ngdlsRlRUFPbs2QOTyYRXXnlFrPeb3/wGx48fR35+vlhWVFSEjIwMAMCpU6cAAJs3bwbQlrmfOXMmAGDr1q149913kZKSAq1WK17TYf78+b39+ERDmo+HGr9ekoK3Mk5j55fnUFnbhAdnxEAuk0ndNCIioiGj1wF8cnIy3n//fYwcORKZmZlobW1FWlqa+Prly5d7PH/9T3/6EzZs2ICMjAxUV1cjNjYWb7/9NiZMmHDD6woLC7Fx40a7so7nDzzwgBjAnz17FgDw/fffi6fHdsUAnqj3NCoFnlsYj51fnMNnR6/gWm0zfnrfGCgVvf5Bj4iIiG6BTOjlUYvnz5/HsmXLUFlZCaAtYO7ImAuCgFmzZmHSpEl2WfTBhLvQELURBAGffHsZ6ZkXMCbaH889kAAPrfR7xbOvEPUM+wpRz7jiLjS9DuABoKqqCidPnoS3tzfuvPNOsby6uhp79+7FpEmT+mwRqqthAE9kL+tUMbZ+dhZhgZ5Y8XAS/L37dgvY3mJfIbqx4yUn8VHBflQ1V8FP44f7Y+ZgYuh4qZtF5LIGTQA/lDGAJ3KUe7ECf92TCw+NEisfTkK4XtoDz9hXiJw7XnIS7579EC22znNYVHIVHol7kEE8UTcGVQB/5coVHDx4EFevXgUAREZGYtasWYiKirq1lroJBvBEzl0prcX6XUZYWmz45cIExEX73/yifsC+QtQ2xc1ia0GjtRENLY1osDai0dqIHWc+QL21waG+h1KHBSPvg1KmhEKugFKmgFLe+c8KubL9sctzuQIKmaL9se25XMa1MDT4DJoAfsOGDdiyZYvDbjNyuRxPP/00Xnjhhd631E0wgCfqXnl1I9Z/YIS5qhFP/ngsJo0NGfA2sK/QYNFqaxUD7wZrIxpbmtBgbUCDtUkMzMXXrE3tdTqftwo33xGur8kgswvoxQBfrrAbHDh7Ll5zgzoOz+XKLoMIZ8+dva8SCpmcgw3qMVcM4Hu94mz37t148803kZKSgp/97GcYNWoUAOCHH37A3/72N7z55puIjIzEwoULb73VROSWgnx1WPXYBPzlwxy89dFpXKttxr0TIyHjNpM0BNkEG5pbm9HQ0tQl0O4aeDc5lHUE4g3WRlhaLTd8f4VMAQ+lDh4qHXRKHTyUOgRpA6BTtf2zh1IHnVILD5VH26NSh7dytqHaUuPwXn4aX/xqwnNoFVphtbW2P1o7n9taYRWs7Y/tz23W9n+2dpYJ19V19l7tzy02C6zW1i73uP592p7bBFu//PeRy+R2vy7Y/+LgbLDgZGDS3fOeDEK6HXTYP5fL5Pw7lBz0OgO/cOFCqFQq7Ny5E0qlffxvtVrx6KOPoqWlBenp6X3aUFfBDDzRzbVYW7Hl4zP4Lt+M2XdE4CczR0EuH5gvIPYV6kstrS1dsuBNaGhp6Mx2i5lx+2C8axZcQPffFzLIoFVq4dEeXOuUOjH4bgu4PaBTabsE4x3BeluZSq7qdWDnjnPgbYINrYLNPsC3taJVsHYZEHQ/UHA6sOjuuV2Z/SCkuwFGx3Orzdovn18G2XUDAOdTmm78a0f306D4q0b3pFzw3ecZ+IKCAqxcudIheAcApVKJ++67D+vWrevt2xLRIKJSKvDMgni8f/AHHPiuENdqm/HzeWOhUiqkbhoNMTbB1hZwd5luYp/1brIvbw/GO8puFpSp5Kq24Lo98PZVeyPUI9guK972qHUo0yo1Ax7wdAQf7rQLjbw9MFTJpd+m9kYEQWgfbNxkQHGjXzWcDCgcByrdPLe1osVmRZO12en7dv2VY6B+1eh+zcRNBgq9HIT0/BeRtut78qvG9YPda81VePfshwDgEv2l171BpVKhocFxAUyH+vp6qFSq22oUEbk/uUyGR2aPRqCPFv/46jzW1mfjlw8mwkvHvx+o5wRBQHOrxX6ud5cseLfBeHvA3tTafMP3l8vkYsa7I7j20/pdNwXFWTDuAa1S6/JBpTMTQ8djYuh4/lrVx2QyGRQyBRRQQO3iuYqB/lWj1UmdJmvTDaZcdbblRr9i3aqe/Kphqi91WEfSYmvBRwX73TOAT0hIwD/+8Q8sWrQIQUFBdq9VVFTggw8+QFJSUp81kIjc270To+DvrcE7+87glf87gRWLkhDkp5O6WTSArDZrZ8Btt/CyY2GmfQa8rW5nkH6zbKFWobGbXhKoDUCEl33g7Ww+uE6pg0ah5vxiGnLc5VcNoG2w4XRwYTeFydrnv2pcrTM5bc+15qoB/jfgXK//yz377LNYvnw57rvvPjz44IMYOXIkgLYTWtPT01FfX4+1a9f2eUOJyH1NHBMCX081Nn14Cn/ccQIvLkpCdKi31M2iHrIJNjRZm8V54I3tO6F0LrzsyHp3vtZ1Yaaly3xrZ5QyRfsUFA94KLXwVHlA7xHYJeuttZum0jlfXAudQguF3MXTnUR0y+QyOdQKOYCB/fX2P7LWOA3W/TV+A9qO7tzSNpJfffUV/vCHP6C4uNiu3GAw4He/+x3uuuuuvmqfyxnoRaw8MY8GkyJzHdbvMqK+yYrnHohH/PDAPr8HpwU4EgQBLTZrZ1b7+vngLZ0Zb2e7pDT1YDGmOAXFLuttX9YRiHuougThSh3UCk6rkgL7ClH3pF7w3W8HOdlsNuTm5qKwsBBA20FO48aNwwcffIDt27fj008/vbUWu7iBDOCl/p+HqD9cq23G+g+MKK6ox/IfxWFqQlifvv9gDUpaba1obG1y2Pu7Y8cTxyko9tsTWm+yJ7haobbPdtsF445lYpCu0kKjGPjFmHT7BmtfIeorg2oXms43liMxMRGJiYl25deuXcPFixdv9W2pi48K9tsF70DbAor08/ug1wVBIZNDJpO3b90kE+e02f1Bxz/LIJcp7OoRScHfW4OXHh2Pv+45hb99kofK2mbMTY0e9POQ2xZjNtvNBRfngd9kYWaDtQHNN9kTvGMxZtdAO6B9MaY4FUXVEYy3bU/YdYqK0g3mwhIRDSRXXvDNv7FdWHcLJWotdVh74i+3/f7XB/qK9m2Vug4Mrn+Uw3EgYP+n/XV093rXel3ve/1j22r+jvZ0DkQ6r+8cvNx8sHKzQY3TNkA26INKqXholVjxcBL+/mke9mRewLWaJjz6b6OhkN/6wHIgMiUtNqvDFJPGli5zvh0Cb/sg/eaLMbV2+3zrdYF2izM7s946+/nhKg+ob2FPcCIick8M4F2Yv8bPaRDvrfLCY2MWQYCAVsEGm8MfATahtf3RBhuc1bF1vt7xB23bSglCx6OAVqG1/bGz3AYbbDYbbGi7T4vN6vz97ep114bO112RXBy03GAwAhnkcmeDDCeDGrmzQYv9YKVzsNTNoKcXv7J0/OkYkDi9j7PPc8NBmv2/k1sNGpUKOX42dywCvLX49OhlVNVZ8PT946C5hf3Xerpfb9tizKb2ud0NaGy58R7g1wfr1/8idj2VXGm33aCX2hPBHkGdmXExOPcQtyfsnAuu5S9jRETUIwzgXdj9MXOczoFfOGou4oPGSNiyvicIgjgg6RxAtA8YejQgcRyM3HBQ4zBocT5YsRu0OLuP08GI431abVa0CDbYrO2vd/NZ7QdPjp/DFcnsBjjXBf+4bhAhc/JLj7cckaktOHOtCS8d+BLDQnygViqcDyK6GawcMR13Ot1sZ95uHLySKQbjTdbmmy7GvH7v7zBPH3HHk45dUjqDcfu9wVVcjElERAOAAbwLc8cT826VTCYTA0Hq3q38ymI3MIANrbb2x/bXuxtEdDcYcWjDzX5h6WiDwy88nYMVf28FlAo5iivrcL6kHCEBWsgVcP5ZnQzSupsfbhWs8Nf6IlwZ1qNdUrQKDaehEBGRy+tRAP+///u/PX7DkydP3nJjyJErL6CggWe/AHnwZXvPF1Xjz7tzYJYBLzyUhBEGnx5dd6P9ep9JfKKvm0lERCSpHm0jGRcX17s3lcmQl5d3y41yZQO9D3wHBvA0VJRUNmDdP7JRU2/BMwvikTwy6KbXcMtVot7j9wpRz0jRV/pkG8nt27f3WYOIiG4kNMADq5fdgQ27jNj0YQ6W3huLu5LDb3jNUJpuRkREdMsHOQ1VzMATDYwmixVv7D2NUxcqMHfKMDwwfXiP5qezrxD1DPsKUc+4YgaeKwaJyCVp1Ur88sEETE8Mw74jl/D3T/JgbXXNnXiIiIgGkqQBvMViwWuvvYZp06YhMTERDz/8ML799tubXpeTk4P//M//xMKFCxEfH4/Y2Nhu69psNmzZsgUzZ85EQkIC5s2bh08//bQvPwYR9ROlQo7lP4rD/GnDkZVbgo27jGhstkrdLCIiIklJGsC/9NJL2LZtG+6//36sXr0acrkcTz31FL7//vsbXnfo0CHs2rULABAZGXnDuuvXr8fatWsxbdo0/Pa3v4XBYMCKFSuwf//+PvscRNR/ZDIZ5k8bjid+FIe8y1X4n50nUVXXLHWziIiIJCPZHPicnBwsWrQIq1atwvLlywEAzc3NmDt3LoKDg7Fz585ury0vL4eXlxe0Wi3++Mc/Yvv27cjPz3eoV1pailmzZmHJkiVYvXo1gLYDgx577DEUFxfjwIEDkPfy6HbOgSeSTk5BBd7YmwsvnQorHk6CIcjToQ77ClHPsK8Q9QznwHexf/9+qFQqLFq0SCzTaDR46KGHcOLECZSVlXV7bVBQELRa7U3vceDAAbS0tOCRRx4Ry2QyGZYsWYKioiLk5OTc3ocgogGVGBOI//+RFLRYW/HK/53AuauOe78TERENdpIF8Hl5eRg+fDg8Pe0zaImJiRAEoU/2kc/Ly4OXlxeGDx/ucA8AOHPmzG3fg4gG1vAwH7y87A546VRY+342vjvb/WCfiIhoMJIsgDebzQgODnYo1+v1AHDDDHxv7hEU5HgITF/eg4gGXrCfDi8vnYDoUC+8sTcXX353VeomERERDZgeHeTUH5qamqBSOR4Fr9FoALTNh++Le6jV6j69x43mI/U3vd5bsnsTuRo9gFefn47Xd57Aewd+wLnCalwpqUV5VSOC/HVY9qMxuGvCjRe5Ew11/F4h6hlX6yuSBfBarRYtLS0O5R1BdUeQfbv3sFgsfXoPLmIlci0/u28MamqbcKLLVBrztUZs+iAbNbVNSB0XKmHriFwXv1eIeoaLWLvQ6/VOp7CYzWYAcDq95lbuUV5e3q/3ICJpyeUylF5rdCi3WG1IP1QgQYuIiIj6l2QBfFxcHC5evIj6+nq7cqPRKL5+u8aMGYO6ujpcvHjR6T3GjBlz2/cgIulV1DifDldR04xjZ0rRYuUJrkRENHhIFsDPmTMHLS0t4oFMQNvJrOnp6Rg/fjxCQkIAACaTCQUFt5ZFmzVrFlQqFd59912xTBAEvP/++zAYDEhKSrq9D0FELiHQx/l0OLkMeOuj0/j//pqF9w/+gOKKeqf1iIiI3Ilkc+CTkpIwZ84crF27FmazGVFRUdizZw9MJhNeeeUVsd5vfvMbHD9+3O6gpqKiImRkZAAATp06BQDYvHkzgLbM/cyZMwEAoaGhWLZsGf7+97+jubkZCQkJOHDgAL777jusX7++14c4EZFrWjgjBts+OwtLl0y7WinHsjmx8PXU4FB2EQ6eKMQX/7qKURG+mJFswB2xwVCrFBK2moiI6NZIdhIr0LaYdMOGDfj4449RXV2N2NhYrFy5ElOmTBHrLF261CGAP3bsGJYtW+b0PR944AG8+uqr4nObzYYtW7bgH//4B8rKyjB8+HA8/fTTmDt37i21mYtYiVzTt6dLkH6oAJU1zQjw0WDhjBi7Baw19RZk5RYjM9uE0muN8NAokTouFGnJBkQGS7e7FJFU+L1C1DOuuIhV0gDeHTGAJ3JtN+srgiAg/0oVMo0mfJdfBmurgBEGH6QlGTBxTDC0asl+mCQaUPxeIeoZBvCDAAN4ItfWm75S19iCI7klyDSaYCqvh1atwOSxIUhLNmBYqE8/t5RIWvxeIeoZVwzgmWoioiHLS6fCv90ZiXvuiEBBUQ0OZRfhSG4J/pltQlSIF2YkGTBpbCg8tPyrkoiIXAcz8L3EDDyRa7vdvtLQ1IKjZ0pxKNuEq2V1UKvkmBjXlpWPMfhAJpP1YWuJpMPvFaKeYQaeiMjFeWhVmDk+AnenhONSSS0OZZtwLK8U35wqRrjeE2lJBqSOC4WXTiV1U4mIaIhiBr6XmIEncm390Vcam604nleKTKMJF4troVTIcWecHmlJBoyO9GNWntwSv1eIeoYZeCIiN6TTKDEjORwzksNxpbQWh4wmHD1dgm9PlyI0wANpSQZMSQiFj4da6qYSEdEQwAx8LzEDT+TaBqqvNLe04ruzZTiUbcL5omoo5DKMH61HWrIBY6L9IWdWnlwcv1eIeoYZeCKiQUKjUmBqQhimJoShyFyHTGMxjuQW419ny6D30yItyYCpCWHw89JI3VQiIhpkmIHvJWbgiVyblH2lxdqKE/lmZBpNOHulCnKZDEkjAzEjORzxwwMglzMrT66D3ytEPcMMPBHRIKZSKjB5XCgmjwtFSWUDMo0mZJ0qxvc/lCPQR4NpiQZMTwxDgI9W6qYSEZEbYwa+l5iBJ3JtrtZXrK02ZP9QjkNGE05frIRMBiSMCMSMJAMSRwZCIZdL3UQaolytrxC5KmbgiYiGGKVCjjvignFHXDDMVY04nGPC4ZxibEo/BV8vNaYlhCEtyQC9n07qphIRkZtgBr6XmIEncm3u0FdabTbkFFQgM9uEnAsVEARg3DB/pCWHI2VUEJQKZuWp/7lDXyFyBczAExERFHI5UkbpkTJKj8qaJnyTU4zDOSa8sTcX3h4qTG3PyocGeEjdVCIickHMwPcSM/BErs1d+4rNJiD3YiUyjSZk/1AOmyAgNtIPM5INmBCrh0qpkLqJNMi4a18hGmjMwBMRkVNyuQyJMYFIjAlEVV0zsk4VI9Nowtsfn4Hnl0qkxodiRpIB4fru/0InIqKhgQE8EZGL8fPS4Mepw/CjydE4e/kaMo0mfH2yCAe+K8TIcF+kJRlw55hgaFTMyhMRDUUM4ImIXJRcJsPYYQEYOywANQ0WHDlVgkyjCX//NA/vHTyHyePasvJRId5SN5WIiAYQA3giIjfg46HGnElRuHdiJM5drUKm0YTDxmJ8fbIIw0K9MSPZgIljQqDT8K91IqLBjotYe4mLWIlc21DqK/VNLfg2twSHjCYUmeuhUSkwaWwwZiSHY1ioN2QymdRNJBc2lPoK0e3gIlYiIuoznloVZt8RiVkTInDBVINDRhOOnilFprEYkcFeSEsyIHVcCDy0KqmbSkREfYgZ+F5iBp7ItQ31vtLYbG0L4rNNuFxaC7VSjjvjgpGWbMDIcF9m5Uk01PsKUU8xA09ERP1Kp1Hi7pRw3J0SjkslNcjMbsvKZ+WWwBDkibTEMExJCIOXjll5IiJ3JWkG3mKxYOPGjcjIyEBNTQ3i4uKwYsUKpKam3vTa0tJSrFmzBllZWbDZbJg8eTJWrVqFyMhIu3q1tbXYvHkzDh48iJKSEgQFBWHatGl47rnnEBIS0us2MwNP5NrYVxw1Waz4V14ZDhlNuGCqgVIhw4TYYKQlGRAX5ces/BDFvkLUM66YgZc0gF+5ciW++OILLFu2DNHR0dizZw9yc3OxY8cOpKSkdHtdfX09Fi5ciPr6eixfvhxKpRJbt26FTCbD3r174evrCwCw2Wz4yU9+gh9++AFLlizB8OHDcfHiRbz33nvQ6/XYt28f1Gp1r9rMAJ7ItbGv3FhhWR0OGU34NrcEDc1WBPvrMCPJgCkJYfD17N3fh+Te2FeIesYVA3jJptDk5OTgk08+wapVq7B8+XIAwIIFCzB37lysXbsWO3fu7Pbad999F5cvX0Z6ejrGjh0LAJg+fTrmzZuHrVu34oUXXgAAnDp1CkajEb/73e/w6KOPitcbDAb84Q9/wMmTJzF58uT++5BERC4mItgLj94zGovuisF3+WXIzDZh1z8LkJ55AcmjgjAj2YCxwwIgZ1aeiMhlSRbA79+/HyqVCosWLRLLNBoNHnroIaxfvx5lZWUIDg52eu3nn3+O5ORkMXgHgJiYGKSmpuKzzz4TA/i6ujoAQGBgoN31QUFBAACtVtunn4mIyF2oVQpMiQ/DlPgwmMrrkWk04UhuCU7kmxHkq8X0xDBMSzTA31sjdVOJiOg6kgXweXl5GD58ODw9Pe3KExMTIQgC8vLynAbwNpsN+fn5WLx4scNrCQkJyMrKQmNjI3Q6HcaNGwcPDw9s3LgRvr6+GDFiBC5cuICNGzdi0qRJSEpK6rfPR0TkLgxBnvjJrFF4cEYMvv/BjEPZJuw5fBF7v7mIpJggpCUbkDAiAAq5XOqmEhERJAzgzWaz00Wker0eAFBWVub0uqqqKlgsFrHe9dcKggCz2YyoqCj4+flh/fr1+I//+A9xmg4A3H333diwYQMXbhERdaFSyjFxTAgmjglB6bUGHDYW45tTxcg+Xw5/b017Vj4MQb46qZtKRDSkSRbANzU1QaVy3MZMo2n7uba5udnpdR3lzhafdlzb1NQklgUEBCA+Ph4pKSmIiYnB2bNn8c477+Dll1/GunXret3uGy0o6G96vbdk9yZyJ+wrt0+v90b86BA8tTARx0+X4PNjl/HxkUv4+MglpMQG495J0Zg4LhRKBbPy7ox9hahnXK2vSBbAa7VatLS0OJR3BOgdwfj1OsotFku313bMbb969SqWLVuGtWvXYvbs2QCA2bNnIzw8HC+99BIefPBBTJ06tVft5i40RK6NfaXvjQrzxqgF8SivbhSz8q9s+xd8PNWYlhCGtKQwBPt7SN1M6iX2FaKe4S40Xej1eqfTZMxmMwB0u4DVz88ParVarHf9tTKZTJxek56eDovFghkzZtjVmzlzJgDg5MmTvQ7giYiGqiBfHR5IG4H7pw3DqQuVyMw24bNjl/Hp0csYE+2PGckGpIzSQ6VkVp6IqD9JFsDHxcVhx44dqK+vt1vIajQaxdedkcvlGD16NHJzcx1ey8nJQXR0NHS6tvmZFRUVEAQB1291b7Va7R6JiKjnFHI5kkcGIXlkEK7VNuObHBMyjcV4M+M0vHQqTIkPxYxkA8ICPW/+ZkRE1GuSpUnmzJmDlpYW7Nq1SyyzWCxIT0/H+PHjxQWuJpMJBQUFdtfee++9yM7OxpkzZ8SyCxcu4OjRo5gzZ45YNmzYMNhsNnz22Wd21+/btw8A7LahJCKi3vP31mDe1OH4n1+kYuXDSYiN8sPBE4VYveUYXv2/EziSWwxLS6vUzSQiGlQkPYn1hRdewMGDB/H4448jKipKPIl127ZtmDBhAgBg6dKlOH78OPLz88Xr6urq8MADD6CxsRFPPPEEFAoFtm7dCkEQsHfvXvj7+wMArl27hnnz5qGqqgpLlizByJEjcfr0aezevRsjR47Ehx9+6HQh7Y1wDjyRa2NfkV51vQVZp4qRaTSh7FojPDRKpMaHYkaSARHB0m0EQPbYV4h6xhXnwEsawDc3N2PDhg34+OOPUV1djdjYWKxcuRJTpkwR6zgL4AGgpKQEa9asQVZWFmw2GyZNmoTVq1cjMjLSrl5paSk2btyIY8eOobS0FH5+fpg5cyZWrFghBvq9wQCeyLWxr7gOmyAg/0oVMo0mnMgvg7VVwAiDD9KSDJg4JhhatWSzOAnsK0Q9xQB+EGAAT+Ta2FdcU22DBd/mluCQ0YTiigZo1QpMHhuCtGQDhoX6SN28IYl9hahnXDGAZ/qDiIj6nbeHGv82MQr33BmJHwqrkWk0ISu3BP/MNiE6xBtpyQZMHhsCnYZfS0REN8MMfC8xA0/k2thX3EdDUwu+PV2KQ9kmFJrroFbJMTEuBDOSDRhh8OFp2f2MfYWoZ5iBJyIiauehVWHWhAjMHB+Oi8W1yDQW4diZMnxzqhjhek+kJRkwJT4UntrebTZARDTYMQPfS8zAE7k29hX31thsxbG8UmRmm3CppBYqpRx3xOqRlmTA6Eg/ZuX7EPsKUc8wA09ERHQDOo0SdyWH467kcFwprcUhowlHT5fg29OlCA3Q7YpiAAAgAElEQVTwaMvKJ4TCx0MtdVOJiCTDDHwvMQNP5NrYVwafZksr/nW2DJlGE84XVUMhl2H8aD1mJBsQF+0PObPyt4R9hahnmIEnIiLqJY1agWmJYZiWGIYicx0OGU34NrcE/zpbBr2fFmlJBkxLCIOvl0bqphIRDQhm4HuJGXgi18a+MjS0WFtxIt+MQ9km5F+tgkIuQ9LIIKQlGRA/PAByObPyN8O+QtQzzMATERH1AZVSgcnjQjF5XChKKhva9pU/VYyT58wI9NFgeqIB0xLDEOCjlbqpRER9jhn4XmIGnsi1sa8MXdZWG77/oRyZ2UU4fekaZDIgYUQgZiQbkBgTCIVcLnUTXQr7ClHPMANPRETUT5QKOe6MC8adccEoq2rEYaMJ35wqxqYPT8HPS41piWGYnmiA3k8ndVOJiG4LM/C9xAw8kWtjX6GuWm025JyvwCGjCacuVAACMHZ4AGYkGZA8KghKxdDNyrOvEPUMM/BEREQDSCGXI2W0Himj9aisacLhnGIczjFh895c+HioMCUhDGlJBoQGeEjdVCKiHmMGvpeYgSdybewrdDM2m4DcixU4lG2C8XwFbIKAuCg/pCUZMCFWD5VSIXUTBwT7ClHPMANPREQkMblchsSYICTGBKGqrhnf5BQj02jC2x+fgeeXSkyJD0NasgHhQZ5SN5WIyCkG8ERENGT5eWkwd8ow3JcajbzL13Ao24SvThbiy++uYmS4L2YkG3BHXDA0qqGRlSci98AAnoiIhjy5TIZxwwIwblgAauotOJJbgkNGE/72SR7ePfADJo8LwYwkA6JCvKVuKhERA3giIqKufDzVmDMpCvdOjMS5q1U4ZDThsLEYX58swvAwb6QlGTBxTAh0Gn6FEpE0uIi1l7iIlci1sa9Qf6hrbMG3uSXINJpQVF4PjVqBSWNCMCPZgGGh3pDJZFI3sdfYV4h6hotYiYiI3JCXToV77ozE7DsiUGCqwaHsIhw93RbQRwZ7YUayAZPHhsJDy69VIup/zMD3EjPwRK6NfYUGSkOTFcfOlOBQtglXyuqgVradBJuWbMDIcF+Xz8qzrxD1DDPwREREg4SHVom7x0fgrpRwXCqpRabRhKNnSpGVWwJDkCfSkgyYEh8KL51K6qYS0SAjaQbeYrFg48aNyMjIQE1NDeLi4rBixQqkpqbe9NrS0lKsWbMGWVlZsNlsmDx5MlatWoXIyEiHumVlZdi4cSMOHTqE6upqhISEYNasWVi1alWv28wMPJFrY18hKTVZrDieV4ZD2SZcLK6BUiHHHbF6pCUZEBvl51JZefYVop5xxQy8pAH8ypUr8cUXX2DZsmWIjo7Gnj17kJubix07diAlJaXb6+rr67Fw4ULU19dj+fLlUCqV2Lp1K2QyGfbu3QtfX1+xblFREZYsWQIvLy8sWLAA/v7+KCkpwcWLF7Fu3bpet5kBPJFrY18hV3G1rA6Z2SYcOV2CxmYrQvx1SEsyYGpCGHw81VI3j32FqIcYwHeRk5ODRYsWYdWqVVi+fDkAoLm5GXPnzkVwcDB27tzZ7bVbtmzB66+/jvT0dIwdOxYAUFBQgHnz5uHpp5/GCy+8INZ98sknUVtbi+3bt0Or1d52uxnAE7k29hVyNc0trfjubBkyjSb8UFgNhVyGlFFBSEs2YOywAMglysqzrxD1jCsG8JLNgd+/fz9UKhUWLVoklmk0Gjz00ENYv349ysrKEBwc7PTazz//HMnJyWLwDgAxMTFITU3FZ599JgbwBQUF+Oabb/D2229Dq9WisbERKpUKSiWn/hMR0cDQqBSYmhCGqQlhKCqvx2GjCUdyS/BdvhlBvlpMTzJgWkIY/L01UjeViNyEXKob5+XlYfjw4fD09LQrT0xMhCAIyMvLc3qdzWZDfn4+4uPjHV5LSEjApUuX0NjYCAA4cuQIAECtVmPhwoVITk5GcnIy/v3f/x2VlZV9/ImIiIhuLDzIEz+ZNQqvPzcVT98/DkG+WuzJvIBfbz6CP+/OQfb5ckl+5SUi9yJZKtpsNiMkJMShXK/XA2hbeOpMVVUVLBaLWO/6awVBgNlsRlRUFC5fvgwAePHFFzFt2jQ8/fTTOH/+PN58800UFhZi165dUCgUffipiIiIbk6llGPS2BBMGhuC0soGZOaYkJVTjOzz5fD31mB6YhimJxoQ6Hv7Uz+JaPCRLIBvamqCSuW4tZZG0/YTYnNzs9PrOsrVascFQB3XNjU1AQAaGhoAtGXmX3/9dQDAvffeCz8/P/z+97/H119/jdmzZ/eq3Teaj9Tf9Hpvye5N5E7YV8id6PXeiI8NwVMPJOH4mRJ8cfQyPj5yCR8fuYTxscG4d3I07hwbCqWi7380Z18h6hlX6yuSBfBarRYtLS0O5R0Bekcwfr2OcovF0u21HYtVOx7nzp1rV+/+++/H73//e5w8ebLXATwXsRK5NvYVcmejw7wx+oF4lFc14nBOMQ7nmLBmaxl8PdWYmhCGtKQwBPt79Mm92FeIeoaLWLvQ6/VOp8mYzWYA6HYBq5+fH9RqtVjv+mtlMpk4vabjMTAw0K6et7c31Go1ampqbuszEBER9YcgPx0eSBuB+6cNw6mCSmQaTfjs2GV8evQyxkT7Y0ayASmj9FApJVvKRkQSkiyAj4uLw44dO1BfX2+3kNVoNIqvOyOXyzF69Gjk5uY6vJaTk4Po6GjodDoAwLhx4wC0HfrUVWVlJSwWCwICAvrksxAREfUHhVyO5FFBSB4VhMqaJnxzqhiHjcV4M+M0vHQqTE0IRVqSAWGBnjd/MyIaNCQbus+ZMwctLS3YtWuXWGaxWJCeno7x48eLC1xNJhMKCgrsrr333nuRnZ2NM2fOiGUXLlzA0aNHMWfOHLFs0qRJ8Pf3R3p6Omw2m1jecc+enPhKRETkCgJ8tLh/6nD8zzOpWPlwEmIj/XDgu0Ks3nIMr/7fCXybWwJLS6vUzSSiASDpSawvvPACDh48iMcffxxRUVHiSazbtm3DhAkTAABLly7F8ePHkZ+fL15XV1eHBx54AI2NjXjiiSegUCiwdetWCIKAvXv3wt/fX6y7e/durF69GlOmTMHs2bNRUFCA9957D2lpaXjrrbd63WbOgSdybewrNJRU1zUjK7cEmdkmlFU1wkOjRGp8KGYkGRARfONNF9hXiHrGFefASxrANzc3Y8OGDfj4449RXV2N2NhYrFy5ElOmTBHrOAvgAaCkpARr1qxBVlYWbDYbJk2ahNWrVyMyMtLhPhkZGXjnnXdw8eJF+Pn5Ye7cuXjxxRdv6WRWBvBEro19hYYimyAg//I1HDKacPKcGdZWATEGH6QlGTBxTAg0asctk9lXiHqGAfwgwACeyLWxr9BQV9tgwZHcEmQaTSiuaIBWrcDkcW1Z+ehQb3x7ugTphwpQWdOMAB8NFs6IQeq4UKmbTeSyGMAPAgzgiVwb+wpRG0EQ8ENhNQ5lm/BdfhlarDYE+mhQVWdBa5fvMbVSjsd/FMcgnqgbrhjAS7YLDREREfUfmUyG0ZF+GB3ph0fuGYWjp0vx/sEf7IJ3ALBYbfjgq/OYMFoPtYqnkxO5AwbwREREg5ynVoVZEyKw88tzTl+vrrfgF+sOITTAA5HBXojQeyEi2AuRei8E+Gggk8kGuMVEdCMM4ImIiIaIQB8NKmqaHcq9dCrcnRKOQnMdLphqcDyv86BFD41SDOYjgj0REeyFiCAvpwtjiWhgMIAnIiIaIhbOiMG2z87CYu08G0WtlGPJ7FF2c+AbmqwoKq9DYVkdrprrUVhWh29yi9FsadtnXgZA769DpBjYt/0J8tVCzmw9Ub9jAE9ERDREdATpN9uFxkOrxKgIP4yK8BPLbIKA8uomFJZ1BPZtjyfzzeiYVa9VK7pMv2nP1uu9oNMw3CDqS9yFppe4Cw2Ra2NfIeqZvuorTRYrisrr2wP7ejGwb2i2inWCfLXi3PrI9mx9sJ8Ocjmz9eT6uAsNERERDSpatRIxBl/EGHzFMkEQUFnTLAbzheY6XC2rQ/b5cnSkDdVKOcL1nnaBfbjeC146lUSfhMh9MIAnIiKiPiWTyRDoq0WgrxbJI4PEcktLK4orGnClrBaFZfUoNNfh5LlyZBqLxTr+3pq2ufVddsMJDdBBIZdL8VGIXBIDeCIiIhoQapUC0aHeiA71FssEQUB1vQVXr5tbf/pipbhnvVIhhyHIA5FdpuBEBHvBx0Mt1UchkhQDeCIiIpKMTCaDn5cGfl4aJIwIFMutrTYUVzS0BfXtgX3uxUpk5ZaIdXw91eIWlx2BfVigB5QKZutpcGMAT0RERC5HqZCLU2lSu5TX1FtQ2J6l7wjsD5y4CmtrW7ZeIZchLNDDIbD39VTzQCoaNBjAExERkdvw8VRjrGcAxg4LEMusrTaUXmu0WzCbf6UKR0+XinW8dKou8+o9ERXsDUOQB1RKHkhF7ocBPBEREbk1pUKO8CBPhAd5YhJCxPK6xhYUtQf0bYF9PQ5lF4kHWcllMoQE6Ox2wokM9oK/t4bZenJpDOCJiIhoUPLSqRAb5Y/YKH+xzGYTUFbVKE7BKTTX4YKpBsfzysQ6HhqlOAUnItgTkcHeCA/yhEbNbD25BgbwRERENGTI5TKEBnggNMADd8QFi+UNTVYUlXfshNN2MNU3ucVotrQCAGQAgv11XQL7tmx9oK8WcmbraYAxgCciIqIhz0OrxKgIP4yK8BPLbIKA8uqm9lNmO7e4PJlvRseZ7Fq1QtyvPlLv2bbFpd4LOg1DLOo//L+LiIiIyAm5TIZgPx2C/XQYP1ovljdbWlHYnq0vLKvHVXMdjp8pxT+brWKdIF+t3dz6iGAvBPvpIJczW0+3jwE8ERERUS9o1ArEGHwRY/AVywRBQGVNs5il79gNJ/t8OYT2dL1aJUd4kBcigz3tAntPrUqiT0LuigE8ERER0W2SyWQI9NUi0FeL5JFBYrmlpRXFFQ24UlaLwrJ6FJrrcPJcOTKNxWKdAB9NZ0DfPh0nNEAHhZwHUpFzDOCJiIiI+olapUB0qDeiQ73FMkEQUF1vsTuMqrCsDqcvVqLV1pau79gaMyLYU1w0GxHsBR8PtVQfhVwIA3giIiKiASSTyeDnpYGflwbxIwLFcmurDcUVDXaBfe6FSmSdKhHr+Hqqxak3HYF9WKAHlApm64cSBvBERERELkCpkIuHSaV2Ka+pt6DQ3LkTztWyOhz47iqsrW3ZeoVchrBAD4fA3tdTzQOpBilJA3iLxYKNGzciIyMDNTU1iIuLw4oVK5CamnrTa0tLS7FmzRpkZWXBZrNh8uTJWLVqFSIjI7u9xmg0YvHixRAEAf/617/g4+PTlx+HiIiIqM/5eKox1jMAY4cFiGWtNhtKKhvtFsyevVKFb0+XinW8dCpxQNAxx94Q5AGVkgdSuTuZIHSsjR54K1euxBdffIFly5YhOjoae/bsQW5uLnbs2IGUlJRur6uvr8fChQtRX1+P5cuXQ6lUYuvWrZDJZNi7dy98fX0drhEEAQ8//DDOnz+PhoaGWw7gKyrqYLMN/L8yvd4bZnPtgN+XyN2wrxD1DPvK4FTX2IIic+cps1fL6lFkroPFagPQtjVmSIDOIbD399YwW98NKfqKXC5DYKBXt69LloHPycnBJ598glWrVmH58uUAgAULFmDu3LlYu3Ytdu7c2e217777Li5fvoz09HSMHTsWADB9+nTMmzcPW7duxQsvvOBwzZ49e3DlyhU8+OCD2LFjR798JiIiIiIpeelUiI3yR2yUv1hmswkoq2oU59YXmutwwVSD43llYh0PjVI8XbYjsA8P8oRGzWy9K5IsgN+/fz9UKhUWLVoklmk0Gjz00ENYv349ysrKEBwc7PTazz//HMnJyWLwDgAxMTFITU3FZ5995hDA19XVYd26dXj++edRVVXVPx+IiIiIyAXJ5TKEBnggNMADd8R1xlYNTVYUlXfMra9HYVkdvjlVjGZLKwBABiDYX9cZ2LfPrQ/01ULObL2kJAvg8/LyMHz4cHh6etqVJyYmQhAE5OXlOQ3gbTYb8vPzsXjxYofXEhISkJWVhcbGRuh0OrF88+bN8PLywpIlS/DGG2/0/YchIiIicjMeWiVGRfhhVISfWGYTBJRXN7WfMtu5xeXJfDM6JhBr1Qpxv/qOwD5c7wmdhnujDBTJ/k2bzWaEhIQ4lOv1bUcVl5WVObwGAFVVVbBYLGK9668VBAFmsxlRUVEAgEuXLmH79u3YtGkTlEr+j0VERETUHblMhmA/HYL9dBg/ujPWara0orA9W19YVo+r5jocP1OKf35fJNYJ8tXazauPDPaC3k8HuZzZ+r4mWUTb1NQElcrx6GCNRgMAaG5udnpdR7la7XiQQce1TU1NYtkrr7yCO++8E3ffffdttxnADRcU9De93vvmlYiIfYWoh9hXqDciwv3snguCAHNVIy4V1+CSqabtsbgaxvPl6NjvQ6NuO8hqWJgvhht8MCys7Y+Xmx1I5Wp9RbIAXqvVoqWlxaG8I0DvCMav11FusVi6vVar1QIAMjMzcfjwYezZs6dP2gxwFxoiV8e+QtQz7CvUF2QAhus9MVzvCSSFAQAsLa0ormjAlbJaFJbVo9BchyM5Jnxx7LJ4XYCPxi5TH6H3QkiADgq56x1IxV1outDr9U6nyZjNZgDodgGrn58f1Gq1WO/6a2UymTi95rXXXsPMmTPh6emJwsJCAEBNTQ0AwGQyoampqdv7EBEREVHvqVVtWffo0M6stSAIqK632J0yW1hWh9MXK9HanhhVKuQID/JERLAnItuD+4hgL3i7WbZ+IEgWwMfFxWHHjh2or6+3W8hqNBrF152Ry+UYPXo0cnNzHV7LyclBdHS0uIC1uLgY586dw5dffulQd/78+UhKSsIHH3zQFx+HiIiIiLohk8ng56WBn5cG8SMCxXJrqw3FFQ12gX3uhUpknSoR6/h6qcUdcDoC+9BADygVrpetHyiSBfBz5szB3//+d+zatUvcB95isSA9PR3jx48XF7iaTCY0NjYiJiZGvPbee+/FunXrcObMGXEryQsXLuDo0aN46qmnxHpr166F1Wq1u+8nn3yCTz/9FK+99hrCwsL6+VMSERERUXeUCrk4jSa1S3lNvQWF5s6dcK6W1eHAd1dhbW3L1ivkMoQFeiIy2NMusPfxVA+JA6kkC+CTkpIwZ84crF27Vtw1Zs+ePTCZTHjllVfEer/5zW9w/Phx5Ofni2WPPPIIdu3ahZ///Od44oknoFAosHXrVuj1enEwAAB33XWXw33z8vLE127lJFYiIiIi6l8+nmqM9QzA2GEBYlmrzYaSyrYDqQrbg/qzV6rw7elSsY63h0qcW9/xaAjygEo5uA6kknRfxT/96U/YsGEDMjIyUF1djdjYWLz99tuYMGHCDa/z8vLCjh07sGbNGmzevBk2mw2TJk3C6tWr4e/vf8NriYiIiMj9KORtc+TDgzwxCZ1bkdc1tqDI3HnK7NWyevzz+yJYrDYAbVtjhgZ6IELvaRfY+3trbpit//Z0CdIPFaCyphkBPhosnBGD1HGh/f45e0ImCMLAb6nixrgLDZFrY18h6hn2FRrMbDYBZVWN4tz6jox9eXXnVuOeWqXdgVQRei+EB3lCo1bg29Ml2PbZWXEQAABqpRyP/yhuQIJ4l92FhoiIiIioP8jlMoQGeCA0wAN3xHXuONjQZEVRecfc+noUltXhm1PFaLa0AmjbFjM4wAPXaprsgncAsFhtSD9U4BJZeAbwRERERDQkeGiVGBXhh1ERnYdS2QQB5dVN7afMti2aLa1scHp9RY3zg0YHGgN4IiIiIhqy5DIZgv10CPbTYfzotrOEfr05y2mwHujj/KDRgTZ0N9AkIiIiInJi4YwYqJX2YbJaKcfCGTHdXDGwmIEnIiIiIuqiY567q+5CwwCeiIiIiOg6qeNCkTou1CV3bOIUGiIiIiIiN8IAnoiIiIjIjTCAJyIiIiJyIwzgiYiIiIjcCAN4IiIiIiI3wgCeiIiIiMiNMIAnIiIiInIjDOCJiIiIiNwIA3giIiIiIjfCk1h7SS6XDcl7E7kT9hWinmFfIeqZge4rN7ufTBAEYYDaQkREREREt4lTaIiIiIiI3AgDeCIiIiIiN8IAnoiIiIjIjTCAJyIiIiJyIwzgiYiIiIjcCAN4IiIiIiI3wgCeiIiIiMiNMIAnIiIiInIjDOCJiIiIiNwIA3giIiIiIjeilLoB5FxZWRm2b98Oo9GI3NxcNDQ0YPv27Zg0aZLUTSNyKTk5OdizZw+OHTsGk8kEPz8/pKSk4MUXX0R0dLTUzSNyGadOncKbb76JM2fOoKKiAt7e3oiLi8Nzzz2H8ePHS908Ipe1ZcsWrF27FnFxccjIyJC6OQAYwLusixcvYsuWLYiOjkZsbCy+//57qZtE5JLeeecdnDx5EnPmzEFsbCzMZjN27tyJBQsWYPfu3YiJiZG6iUQu4erVq2htbcWiRYug1+tRW1uLjz/+GI899hi2bNmCqVOnSt1EIpdjNpvxxhtvwMPDQ+qm2JEJgiBI3QhyVFdXh5aWFvj7++PAgQN47rnnmIEncuLkyZOIj4+HWq0Wyy5duoR58+bhxz/+MV599VUJW0fk2hobGzF79mzEx8fjrbfekro5RC7npZdegslkgiAIqKmpcZkMPOfAuygvLy/4+/tL3Qwilzd+/Hi74B0Ahg0bhlGjRqGgoECiVhG5B51Oh4CAANTU1EjdFCKXk5OTg48++girVq2SuikOGMAT0aAjCALKy8s5CCZyoq6uDpWVlbhw4QLWrVuHc+fOITU1VepmEbkUQRDwhz/8AQsWLMCYMWOkbo4DzoEnokHno48+QmlpKVasWCF1U4hczssvv4zPP/8cAKBSqfCTn/wEzzzzjMStInIte/fuxfnz5/HXv/5V6qY4xQCeiAaVgoIC/P73v8eECRMwf/58qZtD5HKee+45LF68GCUlJcjIyIDFYkFLS4vDVDSioaqurg6vv/46fv7znyM4OFjq5jjFKTRENGiYzWY8/fTT8PX1xcaNGyGX8684ouvFxsZi6tSpePDBB/G3v/0Np0+fdsk5vkRSeeONN6BSqfDEE09I3ZRu8duNiAaF2tpaPPXUU6itrcU777wDvV4vdZOIXJ5KpcKsWbPwxRdfoKmpSermEEmurKwM27ZtwyOPPILy8nIUFhaisLAQzc3NaGlpQWFhIaqrq6VuJqfQEJH7a25uxjPPPINLly5h69atGDFihNRNInIbTU1NEAQB9fX10Gq1UjeHSFIVFRVoaWnB2rVrsXbtWofXZ82ahaeeegq/+tWvJGhdJwbwROTWWltb8eKLLyI7OxubN29GcnKy1E0ickmVlZUICAiwK6urq8Pnn3+OsLAwBAYGStQyItcRERHhdOHqhg0b0NDQgJdffhnDhg0b+IZdhwG8C9u8eTMAiHtZZ2Rk4MSJE/Dx8cFjjz0mZdOIXMarr76Kr776CnfffTeqqqrsDtnw9PTE7NmzJWwdket48cUXodFokJKSAr1ej+LiYqSnp6OkpATr1q2TunlELsHb29vp98a2bdugUChc5juFJ7G6sNjYWKfl4eHh+Oqrrwa4NUSuaenSpTh+/LjT19hXiDrt3r0bGRkZOH/+PGpqauDt7Y3k5GT89Kc/xcSJE6VuHpFLW7p0qUudxMoAnoiIiIjIjXAXGiIiIiIiN8IAnoiIiIjIjTCAJyIiIiJyIwzgiYiIiIjcCAN4IiIiIiI3wgCeiIiIiMiNMIAnIiIiInIjDOCJiMjlLV26FDNnzpS6GURELkEpdQOIiEgax44dw7Jly7p9XaFQ4MyZMwPYIiIi6gkG8EREQ9zcuXORlpbmUC6X80daIiJXxACeiGiIGzt2LObPny91M4iIqIeYXiEiohsqLCxEbGwsNm3ahH379mHevHlISEjAXXfdhU2bNsFqtTpcc/bsWTz33HOYNGkSEhIScN9992HLli1obW11qGs2m/Hf//3fmDVrFuLj45GamoonnngCWVlZDnVLS0uxcuVK3HnnnUhKSsKTTz6Jixcv9svnJiJyVczAExENcY2NjaisrHQoV6vV8PLyEp9/9dVXuHr1Kh599FEEBQXhq6++wl/+8heYTCa88sorYr1Tp05h6dKlUCqVYt2vv/4aa9euxdmzZ/H666+LdQsLC7FkyRJUVFRg/vz5iI+PR2NjI4xGI44cOYKpU6eKdRsaGvDYY48hKSkJK1asQGFhIbZv345nn30W+/btg0Kh6Kd/Q0REroUBPBHRELdp0yZs2rTJofyuu+7CW2+9JT4/e/Ysdu/ejXHjxgEAHnvsMTz//PNIT0/H4sWLkZycDAD44x//CIvFgvfffx9xcXFi3RdffBH79u3DQw89hNTUVADAf/3Xf6GsrAzvvPMOpk+fbnd/m81m9/zatWt48skn8dRTT4llAQEBeO2113DkyBGH64mIBisG8EREQ9zixYsxZ84ch/KAgAC751OmTBGDdwCQyWT42c9+hgMHDuDLL79EcnIyKioq8P333+Oee+4Rg/eOur/4xS+wf/9+fPnll0hNTUVVVRUOHz6M6dOnOw2+r19EK5fLHXbNmTx5MgDg8uXLDOCJaMhgAE9ENMRFR0djypQpN60XExPjUDZy5EgAwNWrVwG0TYnpWt7ViBEjIJfLxbpXrlyBIAgYO3Zsj9oZHBwMjUZjV+bn5wcAqKqq6tF7EBENBlzESkREbuFGc9wFQRjAlhARSYsBPBER9UhBQYFD2fnz5wEAkZGRAICIiAi78q4uXLgAm80m1o2KioJMJkNeXl5/NZmIaFBiAE9ERD1y5MgRnD59WnwuCALeeecdAMDs2bMBAIGBgUhJScHXX3+Nc+fO2dV9++23AQD33HMPgLbpL2lpacjMzMSRI0cc7sesOhGRc5wDT0Q0xJ05c6DIQ+wAAAFpSURBVAYZGRlOX+sIzAEgLi4Ojz/+OB599FHo9XocPHgQR44cwfz585GSkiLWW716NZYuXYpHH30UjzzyCPR6Pb7++mt88803mDt3rrgDDQD89re/xZkzZ/DUU09hwYIFGDduHJqbm2E0GhEeHo5f//rX/ffBiYjcFAN4IqIhbt++fdi3b5/T17744gtx7vnMmTMxfPhwvPXWW7h48SICAwPx7LPP4tlnn7W7JiEhAe+//z7+/Oc/47333kNDQwMiIyPxq1/9Cj/96U/t6kZGRuLDDz/EX//6V2RmZiIjIwM+Pj6Ii4vD4sWL++cDExG5OZnA3yiJiOgGCgsLMWvWLDz//PP45S9/KXVziIiGPM6BJyIiIiJyIwzgiYiIiIjcCAN4IiIiIiI3wjnwRERERERuhBl4IiIiIiI3wgCeiIiIiMiNMIAnIiIiInIjDOCJiIiIiNwIA3giIiIiIjfCAJ6IiIiIyI38Pyp9rl4F+bQ1AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWeYo84kDYZM",
        "outputId": "cb49faa3-5e96-4943-ca66-381f7b3a4559"
      },
      "source": [
        "total_test_loss = []\n",
        "total_test_accuracy = []\n",
        "\n",
        "\n",
        "\n",
        "for batch in validation_dataloader:\n",
        "\n",
        "        \n",
        "  # Unpack this training batch from our dataloader. \n",
        "  #\n",
        "  # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "  # the `to` method.\n",
        "  #\n",
        "  # `batch` contains three pytorch tensors:\n",
        "  #   [0]: input ids \n",
        "  #   [1]: attention masks\n",
        "  #   [2]: labels \n",
        "  b_input_ids = batch[0].to(device)\n",
        "  b_input_mask = batch[1].to(device)\n",
        "  b_labels = batch[2].to(device)\n",
        "        \n",
        "  # Tell pytorch not to bother with constructing the compute graph during\n",
        "  # the forward pass, since this is only needed for backprop (training).\n",
        "  #with torch.no_grad():        \n",
        "\n",
        "  # Forward pass, calculate logit predictions.\n",
        "  # token_type_ids is the same as the \"segment ids\", which \n",
        "  # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "  result = model(b_input_ids, \n",
        "                       token_type_ids=None, \n",
        "                       attention_mask=b_input_mask, \n",
        "                       labels=b_labels,\n",
        "                       return_dict=True)\n",
        "        # Get the loss and \"logits\" output by the model. The \"logits\" are the \n",
        "        # output values prior to applying an activation function like the \n",
        "        # softmax.\n",
        "  loss = result.loss\n",
        "  logits = result.logits\n",
        "        \n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "  total_test_loss = loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "  total_test_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "print(\"The total test accuracy is: \")\n",
        "print(total_test_accuracy)\n",
        "print(\"Testing complete!\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The total test accuracy is: \n",
            "1.0\n",
            "Testing complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkyubuJSOzg3"
      },
      "source": [
        "##Performance On Test Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tg42jJqqM68F"
      },
      "source": [
        "### Data Preparation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVuaPBtNDlj1"
      },
      "source": [
        "\n",
        "combinedDF['Label'] = combinedDF['Label'].astype(int, errors = 'raise')\n",
        "sentences3 = combinedDF.Sentence.values\n",
        "labels3 = combinedDF.Label.values"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESDPcLjNDmKi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19c09416-3d12-4f68-96d4-a38e884e44cb"
      },
      "source": [
        "max_len3 = 0\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences3:\n",
        "\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    input_ids3 = tokenizer.encode(sent, add_special_tokens=True)\n",
        "\n",
        "    # Update the maximum sentence length.\n",
        "    max_len3 = max(max_len3, len(input_ids3))\n",
        "\n",
        "print('Max sentence length: ', max_len3)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1321 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  2141\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOzFdf7EDn3j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc9b58dc-a4c3-48b7-9a39-f01471ab3957"
      },
      "source": [
        "input_ids3 = []\n",
        "attention_masks3 = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences3:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict3 = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 64,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids3.append(encoded_dict3['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks3.append(encoded_dict3['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids3 = torch.cat(input_ids3, dim=0)\n",
        "attention_masks3 = torch.cat(attention_masks3, dim=0)\n",
        "labels3 = torch.tensor(labels3)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences3[0])\n",
        "print('Token IDs:', input_ids3[0])\n",
        "\n",
        "\n",
        "print(len(sentences3))\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:  A very, very, very slow-moving, aimless movie about a distressed, drifting young man.  \n",
            "Token IDs: tensor([    1,   250,   182,     6,   182,     6,   182,  2635,    12, 19838,\n",
            "            6,  4374,  1672,  1569,    59,    10, 21460,     6, 29392,   664,\n",
            "          313,     4,  1437,  1437,     2,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0])\n",
            "2748\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEFlEYwZDp_D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48d1efbe-cddb-4b25-d69a-b8da1a7f8b83"
      },
      "source": [
        "test_dataset = TensorDataset(input_ids3, attention_masks3, labels3)\n",
        "\n",
        "print(type(input_ids3))        \n",
        "print(type(attention_masks3))\n",
        "print(type(labels3))\n",
        "\n",
        "\n",
        "\n",
        "test_dataloader = DataLoader(        \n",
        "            test_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(test_dataset), # Pull out batches sequentially.\n",
        "            batch_size = 32 \n",
        "        )\n",
        "\n",
        "\n",
        "print(len(test_dataset))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "2748\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAS6R3FEDrys",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "238d46e3-91e7-4235-8c61-23b1b19d92fd"
      },
      "source": [
        "torch.cuda.memory_summary(device=None, abbreviated=False)\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |    2726 MB |    4255 MB |    3220 GB |    3217 GB |\\n|       from large pool |    2715 MB |    4253 MB |    3190 GB |    3187 GB |\\n|       from small pool |      11 MB |      40 MB |      29 GB |      29 GB |\\n|---------------------------------------------------------------------------|\\n| Active memory         |    2726 MB |    4255 MB |    3220 GB |    3217 GB |\\n|       from large pool |    2715 MB |    4253 MB |    3190 GB |    3187 GB |\\n|       from small pool |      11 MB |      40 MB |      29 GB |      29 GB |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |    4540 MB |    4540 MB |    4540 MB |       0 B  |\\n|       from large pool |    4496 MB |    4496 MB |    4496 MB |       0 B  |\\n|       from small pool |      44 MB |      44 MB |      44 MB |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |     939 MB |    1011 MB |    3106 GB |    3105 GB |\\n|       from large pool |     932 MB |    1004 MB |    3073 GB |    3072 GB |\\n|       from small pool |       6 MB |      10 MB |      32 GB |      32 GB |\\n|---------------------------------------------------------------------------|\\n| Allocations           |    1119    |    1435    |    1441 K  |    1440 K  |\\n|       from large pool |     544    |     815    |     841 K  |     841 K  |\\n|       from small pool |     575    |     707    |     599 K  |     599 K  |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |    1119    |    1435    |    1441 K  |    1440 K  |\\n|       from large pool |     544    |     815    |     841 K  |     841 K  |\\n|       from small pool |     575    |     707    |     599 K  |     599 K  |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |     231    |     231    |     231    |       0    |\\n|       from large pool |     209    |     209    |     209    |       0    |\\n|       from small pool |      22    |      22    |      22    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |     123    |     204    |     902 K  |     902 K  |\\n|       from large pool |      78    |     156    |     588 K  |     588 K  |\\n|       from small pool |      45    |      55    |     314 K  |     314 K  |\\n|===========================================================================|\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPQD0agDDtRH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51002bba-1663-40d3-9950-6056055d08e3"
      },
      "source": [
        "total_test_loss = []\n",
        "total_test_accuracy = []\n",
        "\n",
        "\n",
        "\n",
        "for batch in test_dataloader:\n",
        "\n",
        "        \n",
        "  # Unpack this training batch from our dataloader. \n",
        "  #\n",
        "  # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "  # the `to` method.\n",
        "  #\n",
        "  # `batch` contains three pytorch tensors:\n",
        "  #   [0]: input ids \n",
        "  #   [1]: attention masks\n",
        "  #   [2]: labels \n",
        "  b_input_ids = batch[0].to(device)\n",
        "  b_input_mask = batch[1].to(device)\n",
        "  b_labels = batch[2].to(device)\n",
        "        \n",
        "  # Tell pytorch not to bother with constructing the compute graph during\n",
        "  # the forward pass, since this is only needed for backprop (training).\n",
        "  #with torch.no_grad():        \n",
        "\n",
        "  # Forward pass, calculate logit predictions.\n",
        "  # token_type_ids is the same as the \"segment ids\", which \n",
        "  # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "  result = model(b_input_ids, \n",
        "                       token_type_ids=None, \n",
        "                       attention_mask=b_input_mask, \n",
        "                       labels=b_labels,\n",
        "                       return_dict=True)\n",
        "        # Get the loss and \"logits\" output by the model. The \"logits\" are the \n",
        "        # output values prior to applying an activation function like the \n",
        "        # softmax.\n",
        "  loss = result.loss\n",
        "  logits = result.logits\n",
        "        \n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "  total_test_loss = loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "  total_test_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "print(\"The total test accuracy is: \")\n",
        "print(total_test_accuracy)\n",
        "print(\"Testing complete!\")"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The total test accuracy is: \n",
            "0.9642857142857143\n",
            "Testing complete!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}